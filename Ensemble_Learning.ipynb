{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Theoretical Question**"
      ],
      "metadata": {
        "id": "Ax6s7nPxtSFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Can we use Bagging for regression problems ?"
      ],
      "metadata": {
        "id": "OgBlxSJXthqO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85e06deb"
      },
      "source": [
        "Yes, Bagging can indeed be used for regression problems. While it's commonly associated with classification (e.g., Random Forests), the underlying principle of combining multiple models to reduce variance is also very effective in regression tasks. For regression, instead of taking a majority vote (as in classification), the predictions of individual models (often decision trees) are averaged to produce the final output."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.What is the difference between multiple model training and single model training ?"
      ],
      "metadata": {
        "id": "gKQ1_x8Fvh2P"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26c87f7d"
      },
      "source": [
        "\n",
        "The core difference between multiple model training and single model training lies in their approach to learning and prediction:\n",
        "\n",
        "**Single Model Training:**\n",
        "*   Involves training one individual machine learning model (e.g., one decision tree, one neural network) on the entire dataset.\n",
        "*   The prediction is made solely by this single, optimized model.\n",
        "*   Often simpler to implement and interpret.\n",
        "*   Can be prone to overfitting if the model is too complex for the data, or underfitting if it's too simple.\n",
        "*   Its performance is limited by the capabilities of that single algorithm and its specific training.\n",
        "\n",
        "**Multiple Model Training (Ensemble Methods):**\n",
        "*   Involves training several models (often of the same type, but sometimes different) on the data. These models can be trained on different subsets of the data or with different initializations.\n",
        "*   The final prediction is derived by combining the predictions of these multiple individual models (e.g., averaging their outputs for regression, or majority voting for classification).\n",
        "*   **Bagging (Bootstrap Aggregating)**, as discussed earlier, is a common multiple model training technique. It trains multiple models independently on different bootstrap samples of the training data and then averages their predictions.\n",
        "*   **Boosting** (e.g., AdaBoost, Gradient Boosting) is another, where models are trained sequentially, with each new model trying to correct the errors of the previous ones.\n",
        "*   **Stacking** trains a 'meta-model' to learn how to best combine the predictions of several base models.\n",
        "*   **Benefits:** Generally leads to higher accuracy, better generalization, and increased robustness to noise and overfitting compared to single models, especially when the individual models are diverse."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Explain the concept of feature randomness in Random Forest."
      ],
      "metadata": {
        "id": "MyNHS72fwlqR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3af9f41d"
      },
      "source": [
        "**Feature Randomness (or Feature Subsampling) in Random Forests:**\n",
        "\n",
        "In a Random Forest, two primary sources of randomness are introduced during the tree-building process to enhance diversity and reduce overfitting:\n",
        "\n",
        "1.  **Bootstrap Aggregating (Bagging):** This involves training each tree on a different random subset of the *data* (samples) with replacement. This is the 'Bagging' part of Random Forests.\n",
        "2.  **Feature Randomness:** This is the second crucial layer of randomness, specifically applied when deciding *which features to consider* at each split point within a decision tree.\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "*   **At each split point:** When a decision tree in a Random Forest is being built, instead of considering *all* available features to find the best split, it only considers a random subset of these features. This random subset is typically of a fixed size, commonly `sqrt(number_of_features)` for classification tasks or `number_of_features / 3` for regression tasks, though these are tunable hyperparameters.\n",
        "*   **Why is it important?**\n",
        "    *   **Decorrelation of Trees:** If there are one or a few very strong predictor features in the dataset, standard decision trees would tend to choose these features at the top splits of many trees, making the trees highly correlated. This reduces the benefit of ensembling. By introducing feature randomness, even these strong predictors might not be available at every split for every tree. This forces the trees to explore other features and creates more diverse, less correlated trees.\n",
        "    *   **Reduced Overfitting:** By limiting the features available at each split, the individual trees are intentionally made 'weaker' or less prone to overfitting the training data. When these diverse, weaker trees are combined, they generalize better to unseen data.\n",
        "    *   **Increased Robustness:** It makes the model more robust to noisy or irrelevant features, as these are less likely to be consistently chosen across all trees.\n",
        "\n",
        "In essence, feature randomness ensures that each tree in the forest sees a slightly different perspective of the feature space when making its splitting decisions, leading to a more robust and accurate ensemble model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  What is OOB (Out-of-Bag) Score ?"
      ],
      "metadata": {
        "id": "iZUVMtDsxkOv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fea19cfa"
      },
      "source": [
        "The **Out-of-Bag (OOB) Score** is a method for estimating the generalization error of a Bagging-based ensemble model, such as a Random Forest, *without the need for a separate validation set*.\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "1.  **Bagging Process:** In Bagging (Bootstrap Aggregating), each individual model (e.g., decision tree) in the ensemble is trained on a bootstrap sample of the original training data. A bootstrap sample is created by randomly drawing observations from the original dataset *with replacement*.\n",
        "2.  **Out-of-Bag Samples:** Because sampling is done with replacement, each bootstrap sample will, on average, contain about 63.2% of the unique original observations, leaving approximately 36.8% of the observations *out of the sample*. These unselected observations for a given tree are called its \"out-of-bag\" (OOB) samples.\n",
        "3.  **OOB Error Estimation:** For each observation in the original training set, it will be OOB for some subset of the trees in the ensemble. To calculate the OOB score:\n",
        "    *   For each observation, predict its value using *only* the trees for which that observation was OOB (i.e., not used in their training).\n",
        "    *   Aggregate these predictions (e.g., average for regression, majority vote for classification).\n",
        "    *   Compare this aggregate OOB prediction to the actual value of the observation.\n",
        "4.  **Final OOB Score:** The OOB score is the average of these errors (or accuracy for classification) across all observations in the training set. It serves as an internal, unbiased estimate of the model's performance on unseen data.\n",
        "\n",
        "**Why is it useful?**\n",
        "\n",
        "*   **Efficiency:** It allows for concurrent model training and validation without needing to split the data into explicit training and validation sets, thus utilizing all available data for model training.\n",
        "*   **Unbiased Estimate:** Because OOB samples are not used to train the trees that predict them, the OOB error provides an almost unbiased estimate of the true generalization error, similar to cross-validation.\n",
        "*   **Hyperparameter Tuning:** It can be used effectively for hyperparameter tuning in Random Forests, as it quickly provides a reliable estimate of model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.  How can you measure the importance of features in a Random Forest model ?"
      ],
      "metadata": {
        "id": "Ese4CWxUyD_p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee076cbb"
      },
      "source": [
        "Random Forests provide a very convenient and widely used mechanism for measuring the importance of features. There are two primary methods:\n",
        "\n",
        "1.  **Mean Decrease in Impurity (MDI) / Gini Importance:**\n",
        "    *   **How it works:** This method calculates the total decrease in node impurity (e.g., Gini impurity for classification, mean squared error for regression) averaged over all trees in the ensemble. When a feature is used to split a node, the impurity of the child nodes is less than the parent node. The larger the decrease, the more important the feature is considered.\n",
        "    *   **Calculation:** For each feature, the impurity decrease from each split where that feature is used is accumulated across all trees. This sum is then normalized across all features.\n",
        "    *   **Pros:** It's readily available as an attribute (`feature_importances_`) in most Random Forest implementations (e.g., scikit-learn).\n",
        "    *   **Cons:** It can be biased towards features that have many unique values or are continuous. It also tends to overestimate the importance of correlated features, as it will randomly pick one of them at a split.\n",
        "\n",
        "2.  **Permutation Importance (or Mean Decrease in Accuracy):**\n",
        "    *   **How it works:** This method is often preferred because it's less biased. After a Random Forest model is trained, the permutation importance is calculated by randomly permuting (shuffling) the values of a single feature for the out-of-bag samples (or a separate validation set) and then observing how much the model's performance (e.g., accuracy for classification, R-squared for regression) decreases.\n",
        "    *   **Calculation:**\n",
        "        1.  Train the Random Forest and record the baseline performance on a dataset (e.g., OOB samples).\n",
        "        2.  For each feature:\n",
        "            *   Randomly shuffle the values of that feature in the dataset.\n",
        "            *   Measure the model's performance again.\n",
        "            *   The importance of the feature is the difference between the baseline performance and the performance after shuffling.\n",
        "    *   **Pros:** It's more reliable and less biased than MDI, especially with correlated features or features with many categories. It directly measures the impact of a feature on the model's predictive power.\n",
        "    *   **Cons:** It is computationally more expensive than MDI, as it requires re-evaluating the model's performance multiple times.\n",
        "\n",
        "**Which one to use?**\n",
        "While MDI is faster and often a good first look, **Permutation Importance** is generally considered more robust and reliable for understanding the true predictive power of features, especially when interpretability is crucial or when dealing with complex datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.  Explain the working principle of a Bagging Classifier ?"
      ],
      "metadata": {
        "id": "CsbDvkhYyj0Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb076774"
      },
      "source": [
        "A **Bagging Classifier** (Bootstrap Aggregating Classifier) is an ensemble meta-algorithm primarily designed to improve the stability and accuracy of machine learning algorithms. It works by reducing variance and helping to avoid overfitting.\n",
        "\n",
        "Here's a breakdown of its working principle:\n",
        "\n",
        "1.  **Bootstrap Sampling:**\n",
        "    *   From the original training dataset (which has `N` samples), Bagging creates `k` new subsets of the data. Each subset is generated by randomly sampling `N` observations *with replacement* from the original dataset. This means that some original observations may appear multiple times in a single subset, while others may not appear at all (these are the 'out-of-bag' samples).\n",
        "    *   These `k` subsets are called **bootstrap samples**.\n",
        "\n",
        "2.  **Base Classifier Training:**\n",
        "    *   For each of the `k` bootstrap samples, an independent base classifier is trained. These base classifiers are typically of the same type (e.g., decision trees, but could be any other classifier).\n",
        "    *   Crucially, each base classifier is trained independently of the others.\n",
        "\n",
        "3.  **Parallel Training:**\n",
        "    *   Because each base classifier is trained on an independent bootstrap sample, the training process for all `k` classifiers can be done in parallel.\n",
        "\n",
        "4.  **Prediction Aggregation (Voting):**\n",
        "    *   Once all `k` base classifiers are trained, when a new, unseen data point needs to be classified, each of the `k` classifiers makes its own prediction.\n",
        "    *   For classification tasks, the predictions from all `k` base classifiers are then combined through a **majority voting** scheme. The class that receives the most votes among the `k` classifiers is chosen as the final prediction of the Bagging classifier.\n",
        "\n",
        "**Key Characteristics and Benefits:**\n",
        "\n",
        "*   **Variance Reduction:** The primary goal of Bagging is to reduce the variance of the base models. By averaging (or voting) the predictions of many models trained on slightly different data, the impact of noise or specific characteristics of any single training set is smoothed out.\n",
        "*   **Overfitting Reduction:** By making individual models less sensitive to specific training data points, Bagging helps to mitigate overfitting.\n",
        "*   **Stability:** The ensemble model becomes more stable and less prone to changes in the training data.\n",
        "*   **Diversity:** The bootstrap sampling ensures that the base models are diverse, as they are trained on different (though overlapping) subsets of the data. This diversity is crucial for the ensemble to perform better than any single base model.\n",
        "\n",
        "Random Forests are a well-known extension of Bagging, which add an additional layer of randomness (feature randomness) to the tree-building process."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.  How do you evaluate a Bagging Classifier’s performance ?"
      ],
      "metadata": {
        "id": "gaG03qUAy9Ia"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "186c6448"
      },
      "source": [
        "Evaluating the performance of a Bagging Classifier involves using standard classification metrics, along with specific techniques suitable for ensemble methods. Here are the primary ways to evaluate its performance:\n",
        "\n",
        "1.  **Out-of-Bag (OOB) Score:**\n",
        "    *   **Principle:** As discussed in Question 4, OOB samples are those data points not included in the bootstrap sample used to train a particular base learner. For each original training instance, predictions can be made by *only* the trees for which that instance was OOB.\n",
        "    *   **Evaluation:** The OOB score aggregates these predictions and compares them to the true labels, providing an internal, unbiased estimate of the model's generalization performance *without the need for a separate validation set*. This is a highly efficient and reliable metric for Bagging models.\n",
        "\n",
        "2.  **Standard Classification Metrics on a Test Set:**\n",
        "    *   **Data Split:** The most common approach is to split your dataset into a training set and an independent test set (e.g., 70/30, 80/20 split).\n",
        "    *   **Metrics:** After training the Bagging Classifier on the training data, its performance is evaluated on the unseen test data using common classification metrics:\n",
        "        *   **Accuracy:** The proportion of correctly classified instances.\n",
        "        *   **Precision:** The proportion of positive identifications that were actually correct.\n",
        "        *   **Recall (Sensitivity):** The proportion of actual positives that were identified correctly.\n",
        "        *   **F1-Score:** The harmonic mean of precision and recall, providing a balance between the two.\n",
        "        *   **ROC AUC (Receiver Operating Characteristic - Area Under the Curve):** Measures the ability of the classifier to distinguish between classes. A higher AUC indicates better performance.\n",
        "        *   **Confusion Matrix:** A table that describes the performance of a classification model on a set of test data for which the true values are known. It helps visualize true positives, true negatives, false positives, and false negatives.\n",
        "\n",
        "3.  **Cross-Validation:**\n",
        "    *   **Method:** K-fold cross-validation can be applied. The dataset is divided into 'k' folds, and the model is trained 'k' times, each time using a different fold as the validation set and the remaining folds as the training set.\n",
        "    *   **Use:** This provides a more robust estimate of model performance by averaging the metrics across multiple folds, reducing the impact of a particular train-test split. While OOB is often sufficient for Bagging, cross-validation can still be useful for direct comparison with other types of models or for hyperparameter tuning.\n",
        "\n",
        "4.  **Learning Curves:**\n",
        "    *   **Purpose:** Plotting learning curves (training score vs. training set size and validation score vs. training set size) can help diagnose whether the model is suffering from high bias (underfitting) or high variance (overfitting), or if adding more data would be beneficial.\n",
        "\n",
        "5.  **Comparison with Baseline Models:**\n",
        "    *   It's always good practice to compare the Bagging Classifier's performance against simpler models (e.g., a single decision tree, Logistic Regression) or other ensemble methods to ensure it provides a significant improvement.\n",
        "\n",
        "In summary, the OOB score provides a convenient and accurate internal estimate, while standard test set evaluation with metrics like accuracy, precision, recall, F1-score, and ROC AUC, possibly bolstered by cross-validation, offers a comprehensive view of a Bagging Classifier's generalization capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  How does a Bagging Regressor work ?"
      ],
      "metadata": {
        "id": "vuvaCFQHzlFi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9e8b844"
      },
      "source": [
        "A **Bagging Regressor** operates on the same core principles as a Bagging Classifier, but it is adapted for regression tasks where the goal is to predict a continuous numerical value rather than a categorical class label.\n",
        "\n",
        "Here's a breakdown of its working principle:\n",
        "\n",
        "1.  **Bootstrap Sampling:**\n",
        "    *   Similar to the classifier, the Bagging Regressor starts by creating multiple (e.g., `k`) bootstrap samples from the original training dataset (which has `N` samples). Each bootstrap sample is generated by randomly drawing `N` observations *with replacement* from the original dataset. This ensures diversity among the training sets for each base model.\n",
        "\n",
        "2.  **Base Regressor Training:**\n",
        "    *   For each of the `k` bootstrap samples, an independent base regressor is trained. These base regressors are typically of the same type (e.g., decision trees, but can be other regression models).\n",
        "    *   Each base regressor learns to map input features to a continuous output value based on its specific bootstrap sample.\n",
        "\n",
        "3.  **Parallel Training:**\n",
        "    *   Since each base regressor is trained on an independent bootstrap sample, the training process for all `k` regressors can be performed in parallel, which can be computationally efficient.\n",
        "\n",
        "4.  **Prediction Aggregation (Averaging):**\n",
        "    *   Once all `k` base regressors are trained, when a new, unseen data point needs a prediction, each of the `k` regressors makes its own individual prediction (a continuous numerical value).\n",
        "    *   For regression tasks, these individual predictions are then combined by **averaging** them. The simple mean of all the individual predictions from the base regressors becomes the final prediction of the Bagging Regressor.\n",
        "\n",
        "**Key Characteristics and Benefits (similar to Bagging Classifier, but for regression):**\n",
        "\n",
        "*   **Variance Reduction:** The primary benefit is a significant reduction in the variance of the overall model. By averaging predictions from multiple models, the impact of noise and the specific quirks of any single training set (which might lead an individual model to overfit) are smoothed out.\n",
        "*   **Improved Stability and Robustness:** The ensemble model becomes more stable and less sensitive to small variations in the training data or outliers, leading to more robust predictions.\n",
        "*   **Reduced Overfitting:** Averaging predictions from diverse models helps to mitigate overfitting, especially if the base regressors (like deep decision trees) are prone to overfitting the training data.\n",
        "*   **Diversity:** The bootstrap sampling ensures that the base regressors are diverse, as they are trained on different (though overlapping) subsets of the data. This diversity is crucial for the ensemble to perform better than any single base regressor.\n",
        "\n",
        "Random Forests for regression are a prime example of a Bagging Regressor, where the base regressors are decision trees, with an added layer of feature randomness during tree construction."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  What is the main advantage of ensemble techniques ?"
      ],
      "metadata": {
        "id": "5K7UuhQH0CP8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c693c31"
      },
      "source": [
        "The main advantage of ensemble techniques lies in their ability to significantly **improve the overall predictive performance, robustness, and generalization capabilities of a model** compared to using a single model.\n",
        "\n",
        "Here's a breakdown of the key benefits that contribute to this main advantage:\n",
        "\n",
        "1.  **Reduced Variance (Overfitting Mitigation):** By combining predictions from multiple models, ensemble methods average out the errors and biases of individual models. This effectively reduces the overall variance, making the ensemble less prone to overfitting the training data and thus generalizing better to unseen data.\n",
        "    *   *Example:* Bagging (like Random Forests) primarily reduces variance by training diverse models on different subsets of data.\n",
        "\n",
        "2.  **Reduced Bias (Underfitting Mitigation):** Some ensemble techniques can help reduce bias, especially when combining weak learners. By sequentially training models to correct the errors of previous ones, the ensemble can learn more complex patterns that a single weak learner might miss.\n",
        "    *   *Example:* Boosting (like AdaBoost or Gradient Boosting Machines) primarily focuses on reducing bias.\n",
        "\n",
        "3.  **Increased Stability and Robustness:** Ensemble models are generally more stable and less sensitive to small changes in the training data, outliers, or noise. If one base model makes a mistake, others can compensate, leading to more reliable predictions.\n",
        "\n",
        "4.  **Higher Accuracy:** As a result of reduced variance and/or bias, ensemble methods frequently achieve higher accuracy than their individual base models.\n",
        "\n",
        "5.  **Handling Complex Relationships:** Ensembles can capture complex, non-linear relationships in data more effectively by combining various perspectives from different models.\n",
        "\n",
        "In essence, ensemble techniques leverage the"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.  What is the main challenge of ensemble methods ?"
      ],
      "metadata": {
        "id": "prbrl16R0Vg3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37d617f5"
      },
      "source": [
        "While ensemble methods offer significant advantages in terms of performance and robustness, they also come with certain challenges:\n",
        "\n",
        "1.  **Increased Computational Cost:** Training multiple models and combining their predictions is inherently more computationally expensive and time-consuming than training a single model. This can be a significant drawback for very large datasets or real-time applications where prediction latency is critical.\n",
        "\n",
        "2.  **Increased Complexity and Reduced Interpretability:** As you combine more models, the overall ensemble becomes more complex, making it harder to understand *why* a particular prediction was made. This 'black box' nature can be a disadvantage in fields where model interpretability and explainability are crucial (e.g., healthcare, finance).\n",
        "\n",
        "3.  **Storage Requirements:** Storing multiple trained models can require significantly more memory and disk space compared to a single model.\n",
        "\n",
        "4.  **Careful Hyperparameter Tuning:** Ensemble methods often have their own set of hyperparameters (e.g., number of estimators, learning rate in boosting) in addition to the hyperparameters of the base learners. Tuning these effectively can be a complex and time-consuming process.\n",
        "\n",
        "5.  **Risk of Overfitting (especially with Boosting):** While ensemble methods generally reduce overfitting, certain techniques like Boosting can still overfit if not carefully tuned. If too many weak learners are added, or if the learning rate is too high, the model can start to memorize the training data, leading to poor generalization.\n",
        "\n",
        "6.  **Diminishing Returns:** Beyond a certain point, adding more base learners to an ensemble may yield only marginal improvements in performance, while significantly increasing computational and storage costs.\n",
        "\n",
        "In summary, the primary challenges revolve around the **increased computational resources, complexity, and reduced interpretability** that come with managing and deploying multiple models instead of a single one."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Explain the key idea behind ensemble techniques."
      ],
      "metadata": {
        "id": "Mq9UYBCw0y6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble techniques in machine learning are based on the idea that combining multiple models can produce better results than relying on a single model. Instead of depending on one predictor, ensembles aggregate the outputs of several models to reduce errors, improve accuracy, and enhance generalization. This works because different models may capture different patterns in the data, and when their predictions are combined—through methods like bagging, boosting, or stacking—the overall system becomes more robust and less prone to overfitting or bias. In essence, ensemble learning leverages the “wisdom of the crowd,” where the collective decision of diverse models is more reliable and powerful than any individual model alone"
      ],
      "metadata": {
        "id": "x5UPWuqa1wLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.What is a Random Forest Classifier ?"
      ],
      "metadata": {
        "id": "cKINLdfR1zcP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b8ac832"
      },
      "source": [
        "A **Random Forest Classifier** is an ensemble machine learning algorithm specifically designed for classification tasks. It operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n",
        "\n",
        "It is an extension of the Bagging (Bootstrap Aggregating) ensemble method, incorporating two key sources of randomness to enhance its performance and prevent overfitting:\n",
        "\n",
        "1.  **Bootstrap Aggregating (Bagging):** Each individual decision tree in the Random Forest is trained on a different random subset of the training data, sampled *with replacement*. This means that some data points may be used multiple times in a single tree's training, while others may not be used at all.\n",
        "\n",
        "2.  **Feature Randomness (Feature Subsampling):** When each decision tree is being constructed, at every split point, it doesn't consider all available features to find the best split. Instead, it considers only a random subset of the features. This forces diversity among the trees and prevents strong predictor features from dominating all trees, leading to more decorrelated trees.\n",
        "\n",
        "**How it works for classification:**\n",
        "\n",
        "1.  **Build Multiple Trees:** A large number of decision trees are built. Each tree is trained on a different bootstrap sample of the training data and, at each split, considers only a random subset of features.\n",
        "2.  **Individual Predictions:** When a new data point needs to be classified, each decision tree in the forest makes its own prediction (i.e., outputs a class label).\n",
        "3.  **Majority Voting:** The final classification output of the Random Forest is determined by taking a **majority vote** among the predictions of all the individual trees. The class that receives the most votes is chosen as the final prediction.\n",
        "\n",
        "**Key Characteristics and Benefits:**\n",
        "\n",
        "*   **High Accuracy:** Often achieves very high accuracy compared to single decision trees or other classification algorithms.\n",
        "*   **Reduces Overfitting:** The combination of bagging and feature randomness effectively reduces the variance of the model, making it less prone to overfitting the training data.\n",
        "*   **Handles High-Dimensional Data:** Can effectively work with datasets containing a large number of features.\n",
        "*   **Implicit Feature Importance:** Provides a way to estimate the importance of features (e.g., using Mean Decrease in Impurity or Permutation Importance).\n",
        "*   **Robustness to Noise and Outliers:** The ensemble nature makes it more robust to noisy data and outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What are the main types of ensemble techniques ?"
      ],
      "metadata": {
        "id": "b4E0BPk62ODA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1449370"
      },
      "source": [
        "\n",
        "Ensemble techniques combine multiple machine learning models to achieve better predictive performance than could be obtained from any of the constituent models alone. The main types of ensemble techniques are:\n",
        "\n",
        "1.  **Bagging (Bootstrap Aggregating):**\n",
        "    *   **Key Idea:** Training multiple instances of the same base learning algorithm on different random subsets (bootstrap samples) of the training data, and then aggregating their predictions.\n",
        "    *   **How it works:** Each model is trained independently on a bootstrap sample (sampling with replacement) of the original data. For classification, predictions are combined by majority vote; for regression, they are averaged.\n",
        "    *   **Primary Benefit:** Reduces variance and helps to prevent overfitting.\n",
        "    *   **Examples:** Random Forest (which adds feature randomness to Bagging of decision trees), Bagging Classifier/Regressor.\n",
        "\n",
        "2.  **Boosting:**\n",
        "    *   **Key Idea:** Sequentially training models, where each new model is designed to correct the errors of the previous ones. It focuses on misclassified or high-error instances from prior models.\n",
        "    *   **How it works:** Models are added one by one, and each new model learns from the mistakes of the preceding models. Weights are often assigned to data points, with misclassified points receiving higher weights for subsequent models.\n",
        "    *   **Primary Benefit:** Reduces bias and converts weak learners into strong learners.\n",
        "    *   **Examples:** AdaBoost, Gradient Boosting Machines (GBM), XGBoost, LightGBM, CatBoost.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.  What is ensemble learning in machine learning ?"
      ],
      "metadata": {
        "id": "a6lPAaAR20OU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6ad2027"
      },
      "source": [
        "Ensemble learning in machine learning is a powerful technique that combines the predictions from multiple machine learning models (often called \"base learners\" or \"weak learners\") to achieve a more robust, accurate, and generalized predictive model than any single base model could achieve on its own.\n",
        "\n",
        "The core idea behind ensemble learning is rooted in the concept of \"wisdom of the crowd,\" where the collective decision of diverse individuals tends to be more accurate and reliable than the decision of any single expert.\n",
        "\n",
        "**Key Principles and Benefits:**\n",
        "\n",
        "*   **Improved Accuracy:** By combining multiple models, ensemble methods can reduce both bias and variance, leading to higher predictive accuracy. Different models might capture different aspects of the data, and by aggregating their insights, a more comprehensive understanding is formed.\n",
        "*   **Robustness:** Ensembles are generally more robust to noise, outliers, and small fluctuations in the training data. If one base model makes an error or is sensitive to a particular data point, other models in the ensemble can compensate, leading to more stable predictions.\n",
        "*   **Better Generalization:** Ensemble models are less prone to overfitting than individual complex models. By averaging or voting across diverse models, the ensemble tends to generalize better to unseen data.\n",
        "*   **Diversity is Key:** For an ensemble to be effective, its base models should ideally be diverse. This diversity can come from:\n",
        "    *   **Different Training Data Subsets:** (e.g., Bagging, where models are trained on bootstrap samples).\n",
        "    *   **Different Learning Algorithms:** (e.g., Stacking, where various types of models are combined).\n",
        "    *   **Different Feature Subsets:** (e.g., Random Forests, which use feature randomness).\n",
        "    *   **Sequential Learning on Errors:** (e.g., Boosting, where subsequent models focus on correcting errors of previous ones).\n",
        "\n",
        "**Common Ensemble Techniques:**\n",
        "\n",
        "*   **Bagging (Bootstrap Aggregating):** Builds multiple models independently on different bootstrap samples of the training data and then averages (regression) or votes (classification) their predictions (e.g., Random Forest).\n",
        "*   **Boosting:** Builds models sequentially, where each new model tries to correct the errors made by the previous models, focusing more on misclassified instances (e.g., AdaBoost, Gradient Boosting Machines, XGBoost).\n",
        "*   **Stacking (Stacked Generalization):** Trains multiple base models and then trains a meta-model (or 'blender') to learn how to best combine the predictions of these base models.\n",
        "\n",
        "In essence, ensemble learning leverages the collective intelligence of multiple models to produce a superior predictive performance, making it a cornerstone technique in modern machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.  When should we avoid using ensemble methods?"
      ],
      "metadata": {
        "id": "4NUPMATbCRlK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b6e7d71"
      },
      "source": [
        "While ensemble methods are powerful, there are situations where you might want to avoid or reconsider using them:\n",
        "\n",
        "1.  **When Interpretability is Paramount:** Ensemble methods, especially complex ones like Random Forests or Gradient Boosting, are often considered 'black box' models. If understanding *why* a specific prediction was made (e.g., in medical diagnosis, legal decisions, or financial risk assessment) is more critical than predictive accuracy, a simpler, more interpretable model (like a single decision tree, linear regression, or logistic regression) might be preferred.\n",
        "\n",
        "2.  **When Computational Resources are Highly Constrained:** Training and deploying multiple models requires significantly more computational power (CPU/GPU, memory) and time compared to a single model. If you have limited resources or strict latency requirements for predictions, the overhead of ensembles might be prohibitive.\n",
        "\n",
        "3.  **When Training Data is Very Small:** Ensemble methods often benefit from a large and diverse training dataset to create diverse base models. With very small datasets, the bootstrapping in bagging might not generate sufficiently different subsets, or boosting might quickly overfit.\n",
        "\n",
        "4.  **When the Base Model is Already Performing Very Well and is Simple:** If a single, simple model (e.g., logistic regression) already achieves satisfactory performance and you value simplicity, interpretability, or speed, the marginal gain from an ensemble might not justify the increased complexity.\n",
        "\n",
        "5.  **When the Problem is Trivial or Easily Solvable:** For very simple problems where a basic algorithm provides excellent results, introducing an ensemble might be overkill, adding unnecessary complexity without proportional benefits.\n",
        "\n",
        "6.  **When Base Models are Highly Correlated:** If the base models in your ensemble are not diverse and make very similar errors, combining them will not lead to significant improvements. Diversity among base models is key to the success of ensemble methods.\n",
        "\n",
        "In essence, the decision to avoid ensemble methods often comes down to a trade-off between predictive performance and factors like interpretability, computational cost, and data availability."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How does Bagging help in reducing overfitting ?"
      ],
      "metadata": {
        "id": "GUZOIBeEDUMe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba71c477"
      },
      "source": [
        "Bagging (Bootstrap Aggregating) is a powerful ensemble technique that primarily helps in reducing overfitting by addressing the **variance** component of a model's error. Here's a breakdown of how it works:\n",
        "\n",
        "1.  **Creates Diverse Base Models:**\n",
        "    *   Bagging trains multiple base models (e.g., decision trees) on different **bootstrap samples** of the original training data. A bootstrap sample is created by sampling the original data *with replacement*. This means each base model sees a slightly different subset of the training data.\n",
        "    *   Because each model is trained on a different data subset, they learn different patterns and make different errors, leading to a diverse set of models.\n",
        "\n",
        "2.  **Reduces Variance by Averaging/Voting:**\n",
        "    *   Individual, complex models (like deep decision trees) are often prone to overfitting because they can learn the noise and specific quirks of their training data, leading to high variance. They perform very well on the training data but poorly on unseen data.\n",
        "    *   Bagging combines the predictions of these multiple diverse base models: by **averaging** their predictions for regression tasks, or by taking a **majority vote** for classification tasks.\n",
        "    *   The act of averaging or voting effectively *smooths out* the individual idiosyncrasies and errors of the base models. The errors made by one model might be cancelled out by correct predictions or different errors made by other models. This reduces the overall variance of the ensemble model.\n",
        "\n",
        "3.  **Stabilizes Predictions:**\n",
        "    *   An overfit model is very sensitive to small changes in the training data. Bagging makes the overall model more stable because it's not relying on a single model trained on one specific dataset. Instead, it aggregates insights from multiple models trained on various data perspectives.\n",
        "\n",
        "In essence, Bagging works on the principle that while individual models might overfit their specific training subsets, the collective decision, when aggregated, will be more robust and generalize better to unseen data, thus mitigating the problem of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.  Why is Random Forest better than a single Decision Tree ?"
      ],
      "metadata": {
        "id": "2G0Bc7i2Ds3o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97c07edb"
      },
      "source": [
        "A **Random Forest** is generally better than a single **Decision Tree** due to several key advantages stemming from its ensemble nature:\n",
        "\n",
        "1.  **Reduces Overfitting (Primary Advantage):**\n",
        "    *   **Single Decision Tree:** A single, unconstrained decision tree can easily overfit the training data by growing too deep and learning noise or specific idiosyncrasies in the data. This leads to high variance and poor generalization to unseen data.\n",
        "    *   **Random Forest:** By combining multiple decision trees (typically hundreds or thousands), each trained on a different bootstrap sample of the data and considering only a random subset of features at each split, the Random Forest significantly reduces variance and overfitting. The errors of individual trees tend to cancel each other out when their predictions are aggregated.\n",
        "\n",
        "2.  **Higher Accuracy:**\n",
        "    *   **Single Decision Tree:** Can be less accurate, especially if the data is complex or noisy, as it's prone to local optima in its greedy splitting approach.\n",
        "    *   **Random Forest:** The aggregation of many diverse trees often leads to much higher predictive accuracy. It leverages the 'wisdom of the crowd' principle, where the collective decision is more robust and accurate than any individual tree's decision.\n",
        "\n",
        "3.  **Handles High-Dimensional Data:**\n",
        "    *   **Single Decision Tree:** Can struggle with very high-dimensional data, as the greedy splitting might not find the optimal features efficiently.\n",
        "    *   **Random Forest:** The feature randomness (subsampling features at each split) helps manage high-dimensional data by forcing trees to explore different feature combinations, making it more robust to irrelevant features.\n",
        "\n",
        "4.  **Robustness to Noise and Outliers:**\n",
        "    *   **Single Decision Tree:** Can be very sensitive to noise and outliers, which can lead to skewed splits and poor generalization.\n",
        "    *   **Random Forest:** The ensemble approach makes it more robust. Outliers or noisy data points might affect a few trees, but their impact is diluted across the entire forest.\n",
        "\n",
        "5.  **Implicit Feature Importance:**\n",
        "    *   **Single Decision Tree:** Provides some measure of feature importance based on how much a feature reduces impurity.\n",
        "    *   **Random Forest:** Offers a more reliable and robust measure of feature importance (e.g., Mean Decrease in Impurity, Permutation Importance) by aggregating insights across many trees, helping to identify the most impactful features for the overall model.\n",
        "\n",
        "6.  **Better Generalization:** Because of reduced overfitting and higher accuracy, Random Forests generally generalize much better to new, unseen data compared to a single decision tree.\n",
        "\n",
        "In summary, while a single decision tree is interpretable and fast, a Random Forest trades some of that simplicity for significant improvements in predictive performance, robustness, and generalization by employing multiple, diverse trees."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.  What is the role of bootstrap sampling in Bagging ?"
      ],
      "metadata": {
        "id": "soUMowAuD3aY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60741359"
      },
      "source": [
        "**The Role of Bootstrap Sampling in Bagging (Bootstrap Aggregating):**\n",
        "\n",
        "Bootstrap sampling is the foundational mechanism that gives Bagging its name and is critical for its effectiveness in improving model performance, particularly in reducing variance and mitigating overfitting.\n",
        "\n",
        "Here's its role explained:\n",
        "\n",
        "1.  **Creating Diverse Training Subsets:**\n",
        "    *   **Process:** From the original training dataset (which has `N` samples), bootstrap sampling involves repeatedly drawing `N` samples *with replacement*. This means that in each bootstrap sample:\n",
        "        *   Some original observations will appear multiple times.\n",
        "        *   Some original observations will not appear at all (these are the 'out-of-bag' samples, approximately 36.8% of the original data).\n",
        "    *   **Outcome:** This process generates multiple (e.g., `k`) distinct, yet overlapping, training subsets. Each of these subsets is slightly different from the original dataset and from each other.\n",
        "\n",
        "2.  **Inducing Model Diversity (Decorrelation):**\n",
        "    *   When an independent base model (e.g., a decision tree) is trained on each of these `k` bootstrap samples, they learn slightly different patterns and make different errors. This diversity is crucial.\n",
        "    *   If all base models were trained on the exact same data, they would likely make similar errors, and aggregating their predictions wouldn't offer much benefit. Bootstrap sampling ensures that each model gets a unique perspective of the data, leading to models that are decorrelated to some extent.\n",
        "\n",
        "3.  **Reducing Variance:**\n",
        "    *   Individual, complex models (like unpruned decision trees) tend to have high variance, meaning they are very sensitive to the specific training data they see. They might overfit to the noise in their particular training sample.\n",
        "    *   By training multiple such high-variance models on different bootstrap samples, and then averaging or voting their predictions, Bagging effectively *reduces the overall variance* of the ensemble. The errors and idiosyncratic biases of individual models tend to cancel each other out in the aggregation process, leading to a more stable and robust final prediction.\n",
        "\n",
        "4.  **Mitigating Overfitting:**\n",
        "    *   Because the ensemble's prediction is an average or majority vote of diverse, high-variance models, it doesn't get overly fixated on the noise or specific patterns of any single training dataset. This makes the Bagging ensemble less prone to overfitting the training data and better at generalizing to unseen data.\n",
        "\n",
        "5.  **Enabling Out-of-Bag (OOB) Evaluation:**\n",
        "    *   As a side benefit, the out-of-bag samples (those not used to train a particular tree) can be used as an internal, unbiased validation set. This allows for performance estimation without needing a separate cross-validation split, making the evaluation process more efficient.\n",
        "\n",
        "In essence, bootstrap sampling is the engine of Bagging, creating the necessary diversity among base learners that allows the ensemble to effectively reduce variance and produce a more generalized and accurate predictive model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What are some real-world applications of ensemble techniques ?"
      ],
      "metadata": {
        "id": "akpG0_28EIMw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b26c43b"
      },
      "source": [
        "Ensemble techniques are widely used across various industries due to their ability to achieve higher accuracy, robustness, and better generalization compared to single models. Here are some real-world applications:\n",
        "\n",
        "1.  **Finance and Banking:**\n",
        "    *   **Fraud Detection:** Identifying fraudulent transactions in credit card usage, loan applications, or insurance claims. Ensemble methods can combine different models to detect subtle patterns indicative of fraud.\n",
        "    *   **Credit Scoring:** Predicting the creditworthiness of individuals or companies to approve loans or set interest rates. Ensembles help in making more accurate risk assessments.\n",
        "    *   **Algorithmic Trading:** Forecasting stock prices, market trends, or currency exchange rates to inform trading strategies.\n",
        "\n",
        "2.  **Healthcare and Medicine:**\n",
        "    *   **Disease Diagnosis:** Assisting doctors in diagnosing diseases like cancer, diabetes, or heart conditions by analyzing medical images, patient records, and lab results. Ensembles can improve the accuracy of diagnostic predictions.\n",
        "    *   **Drug Discovery:** Predicting the efficacy and potential side effects of new drug compounds.\n",
        "    *   **Patient Outcome Prediction:** Forecasting patient recovery rates, readmission risks, or the likelihood of adverse events.\n",
        "\n",
        "3.  **E-commerce and Retail:**\n",
        "    *   **Recommendation Systems:** Suggesting products to customers based on their past behavior and preferences (e.g., \"Customers who bought this also bought...\"). Ensembles combine various user and item features for more personalized recommendations.\n",
        "    *   **Demand Forecasting:** Predicting future sales for inventory management and supply chain optimization.\n",
        "    *   **Customer Churn Prediction:** Identifying customers who are likely to stop using a service or buying products, allowing businesses to implement retention strategies.\n",
        "\n",
        "4.  **Image and Speech Recognition:**\n",
        "    *   **Object Detection:** Identifying and localizing objects within images or video streams (e.g., self-driving cars, security surveillance).\n",
        "    *   **Facial Recognition:** Used in security, authentication, and surveillance.\n",
        "    *   **Speech Recognition:** Converting spoken language into text (e.g., virtual assistants, transcription services).\n",
        "\n",
        "5.  **Marketing and Advertising:**\n",
        "    *   **Targeted Advertising:** Identifying specific customer segments most likely to respond to certain advertisements.\n",
        "    *   **Sentiment Analysis:** Analyzing customer reviews, social media posts, and feedback to understand public opinion about products or brands.\n",
        "    *   **Campaign Optimization:** Predicting the best channels and content for marketing campaigns to maximize ROI.\n",
        "\n",
        "6.  **Weather Forecasting and Environmental Monitoring:**\n",
        "    *   **Predicting Weather Patterns:** Combining various meteorological models to improve the accuracy of short-term and long-term weather forecasts.\n",
        "    *   **Pollution Prediction:** Forecasting air quality or pollution levels based on environmental factors.\n",
        "\n",
        "7.  **Cybersecurity:**\n",
        "    *   **Intrusion Detection:** Identifying malicious activities or anomalies in network traffic that indicate cyber-attacks.\n",
        "    *   **Spam Detection:** Classifying emails as legitimate or spam.\n",
        "\n",
        "These examples highlight the versatility and effectiveness of ensemble techniques in solving complex predictive problems across diverse domains, where high accuracy and reliability are crucial."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What is the difference between Bagging and Boosting ?"
      ],
      "metadata": {
        "id": "6jg5jTJSEk9L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f9c7a94"
      },
      "source": [
        "Both Bagging (Bootstrap Aggregating) and Boosting are powerful ensemble techniques designed to improve the performance of machine learning models. However, they differ significantly in their approach, goals, and how they build and combine base learners.\n",
        "\n",
        "Here's a breakdown of their key differences:\n",
        "\n",
        "**Bagging (e.g., Random Forest)**\n",
        "\n",
        "1.  **Training Process:**\n",
        "    *   **Parallel:** Base learners are trained **independently and in parallel** on different subsets of the data.\n",
        "    *   **Data Sampling:** Each base learner is trained on a **bootstrap sample** (sampling with replacement) of the original training data. This means each base learner sees a slightly different, random subset of the data.\n",
        "\n",
        "2.  **Focus/Goal:**\n",
        "    *   **Reduces Variance:** Primarily aims to reduce the **variance** of high-variance, low-bias base models (like deep decision trees). It makes the model less sensitive to the specific training data.\n",
        "    *   **Mitigates Overfitting:** By averaging or voting predictions from diverse, often overfit, individual models, it smooths out their errors, leading to better generalization.\n",
        "\n",
        "3.  **Base Learners:**\n",
        "    *   Typically uses **strong learners** (e.g., deep, unpruned decision trees) that are prone to overfitting. The ensemble helps to temper this overfitting.\n",
        "    *   The base learners are often of the same type.\n",
        "\n",
        "4.  **Weighting:**\n",
        "    *   All base learners are typically given **equal weight** in the final prediction.\n",
        "    *   Data points in the training set are also typically given equal weight, though their presence in bootstrap samples varies.\n",
        "\n",
        "5.  **Prediction Aggregation:**\n",
        "    *   **Averaging** for regression tasks.\n",
        "    *   **Majority Voting** for classification tasks.\n",
        "\n",
        "6.  **Error Correction:**\n",
        "    *   Does not explicitly focus on correcting errors of previous models. Diversity is achieved through data sampling.\n",
        "\n",
        "7.  **Example:**\n",
        "    *   **Random Forest** is a prime example, which combines Bagging with an additional layer of feature randomness.\n",
        "\n",
        "**Boosting (e.g., AdaBoost, Gradient Boosting, XGBoost)**\n",
        "\n",
        "1.  **Training Process:**\n",
        "    *   **Sequential:** Base learners are trained **sequentially**, with each new model attempting to correct the errors made by the previous models.\n",
        "    *   **Data Sampling/Weighting:** Subsequent models focus more on the data points that were **misclassified or had high errors** by the preceding models. This can involve re-weighting misclassified samples or fitting new models to the residuals (errors).\n",
        "\n",
        "2.  **Focus/Goal:**\n",
        "    *   **Reduces Bias:** Primarily aims to reduce the **bias** of weak learners. It tries to convert a collection of weak learners into a strong learner.\n",
        "    *   **Improves Accuracy:** By iteratively improving upon errors, it can achieve very high accuracy.\n",
        "\n",
        "3.  **Base Learners:**\n",
        "    *   Typically uses **weak learners** (e.g., shallow decision trees, often called 'stumps' for AdaBoost) that individually perform slightly better than random guessing.\n",
        "    *   The base learners are often of the same type.\n",
        "\n",
        "4.  **Weighting:**\n",
        "    *   Base learners are often assigned **different weights** in the final prediction, with better-performing models (or those added later in the sequence) contributing more.\n",
        "    *   Data points are also re-weighted, with misclassified points getting higher weights for subsequent learners.\n",
        "\n",
        "5.  **Prediction Aggregation:**\n",
        "    *   Typically a **weighted sum** for both regression and classification, where each base model's contribution is scaled by its performance.\n",
        "\n",
        "6.  **Error Correction:**\n",
        "    *   **Explicitly corrects errors** by giving more attention to previously misclassified or poorly predicted samples.\n",
        "\n",
        "7.  **Example:**\n",
        "    *   **AdaBoost** (Adaptive Boosting), **Gradient Boosting Machines (GBM)**, **XGBoost**, **LightGBM**, **CatBoost**.\n",
        "\n",
        "In summary, Bagging builds diverse models independently to reduce variance, while Boosting builds models sequentially, with each new model correcting the errors of its predecessors, primarily to reduce bias. Bagging thrives on diversity and parallelism, whereas Boosting relies on a corrective, iterative process."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical Question**"
      ],
      "metadata": {
        "id": "GNnC2p24E5F9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.  Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy."
      ],
      "metadata": {
        "id": "Uafs0KyOFFCf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4d2571e"
      },
      "source": [
        "### 1. Generate a sample dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae504c88",
        "outputId": "f9e9f6c3-1fde-419f-ad6e-88c3e4d36fd7"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a synthetic dataset for classification\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_redundant=5,           # Number of redundant features\n",
        "    n_classes=2,             # Number of target classes\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Dataset shape: X={X.shape}, y={y.shape}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: X=(1000, 20), y=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6763e02"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "799f2ab8",
        "outputId": "0fa79609-df33-4fa0-b84b-be31dd2eac6f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Testing data shape: X_test={X_test.shape}, y_test={y_test.shape}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train=(700, 20), y_train=(700,)\n",
            "Testing data shape: X_test=(300, 20), y_test=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5caf1b10"
      },
      "source": [
        "### 3. Initialize and train a Bagging Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ddb2f4",
        "outputId": "ebd8b12b-54fe-453e-fdbc-848dabe343b4"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize a Decision Tree Classifier as the base estimator\n",
        "base_estimator = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Initialize the Bagging Classifier\n",
        "# n_estimators: number of base estimators (decision trees) in the ensemble\n",
        "# random_state: for reproducibility\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1 # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "# Train the Bagging Classifier\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "print(\"Bagging Classifier trained successfully.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2f1bf93"
      },
      "source": [
        "### 4. Make predictions and print model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fb426b8",
        "outputId": "18e1c0ad-729a-47d8-f414-29bfbf78a096"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy:.4f}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.9133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)."
      ],
      "metadata": {
        "id": "fDFnRuHKFcAL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1f2a076"
      },
      "source": [
        "### 1. Generate a sample dataset for regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92800059",
        "outputId": "7a70107a-feb0-432b-8e14-fb609b7e6181"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a synthetic dataset for regression\n",
        "X_reg, y_reg = make_regression(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_targets=1,             # Number of target variables\n",
        "    noise=0.5,               # Standard deviation of the gaussian noise\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Regression Dataset shape: X_reg={X_reg.shape}, y_reg={y_reg.shape}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Dataset shape: X_reg=(1000, 20), y_reg=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "484af215"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bc61df0",
        "outputId": "1165d29a-f85b-4566-dd81-cf1b31291123"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Regression Training data shape: X_train_reg={X_train_reg.shape}, y_train_reg={y_train_reg.shape}\")\n",
        "print(f\"Regression Testing data shape: X_test_reg={X_test_reg.shape}, y_test_reg={y_test_reg.shape}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Training data shape: X_train_reg=(700, 20), y_train_reg=(700,)\n",
            "Regression Testing data shape: X_test_reg=(300, 20), y_test_reg=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87e63fa6"
      },
      "source": [
        "### 3. Initialize and train a Bagging Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "637e3c70",
        "outputId": "4f83593b-3d9a-4f60-8b79-9289c6dbe6ec"
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Initialize a Decision Tree Regressor as the base estimator\n",
        "base_estimator_reg = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Initialize the Bagging Regressor\n",
        "# n_estimators: number of base estimators (decision trees) in the ensemble\n",
        "# random_state: for reproducibility\n",
        "bagging_reg = BaggingRegressor(\n",
        "    estimator=base_estimator_reg,\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1 # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "# Train the Bagging Regressor\n",
        "bagging_reg.fit(X_train_reg, y_train_reg)\n",
        "print(\"Bagging Regressor trained successfully.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6620e00b"
      },
      "source": [
        "### 4. Make predictions and evaluate using Mean Squared Error (MSE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e60af186",
        "outputId": "3ae44bbe-34f0-45f9-eabf-c26c7e02965e"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_reg = bagging_reg.predict(X_test_reg)\n",
        "\n",
        "# Calculate the Mean Squared Error\n",
        "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "\n",
        "print(f\"Bagging Regressor Mean Squared Error (MSE): {mse:.4f}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor Mean Squared Error (MSE): 7367.6923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores.\n"
      ],
      "metadata": {
        "id": "EqWpEVhdF4uA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5121f27"
      },
      "source": [
        "### 1. Load the Breast Cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0613bee8",
        "outputId": "67fd8220-66f4-4150-c92f-b1a0a7f70aac"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X_bc = data.data\n",
        "y_bc = data.target\n",
        "\n",
        "print(f\"Breast Cancer Dataset shape: X={X_bc.shape}, y={y_bc.shape}\")\n",
        "print(f\"Feature names: {data.feature_names}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast Cancer Dataset shape: X=(569, 30), y=(569,)\n",
            "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03e2d176"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5338f46c",
        "outputId": "fd2cc0fd-d7a3-4f42-93af-083f32134f2d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(X_bc, y_bc, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_bc={X_train_bc.shape}, y_train_bc={y_train_bc.shape}\")\n",
        "print(f\"Testing data shape: X_test_bc={X_test_bc.shape}, y_test_bc={y_test_bc.shape}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_bc=(398, 30), y_train_bc=(398,)\n",
            "Testing data shape: X_test_bc=(171, 30), y_test_bc=(171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2883438b"
      },
      "source": [
        "### 3. Initialize and train a Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e4ff9de",
        "outputId": "0af05935-83c2-4821-8efd-a958326dcfc5"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "# n_estimators: number of trees in the forest\n",
        "# random_state: for reproducibility\n",
        "# n_jobs: use all available CPU cores for parallel training\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf.fit(X_train_bc, y_train_bc)\n",
        "print(\"Random Forest Classifier trained successfully.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c84d213"
      },
      "source": [
        "### 4. Print feature importance scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cee8dc9b",
        "outputId": "023f1984-61e3-4a8c-898a-414f95c12a9c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Get feature importances from the trained model\n",
        "feature_importances = rf_clf.feature_importances_\n",
        "\n",
        "# Get feature names from the dataset\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Create a DataFrame for better visualization of feature importances\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort the features by importance in descending order\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"Feature Importances (Mean Decrease in Impurity):\")\n",
        "print(importance_df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances (Mean Decrease in Impurity):\n",
            "                    Feature  Importance\n",
            "7       mean concave points    0.141934\n",
            "27     worst concave points    0.127136\n",
            "23               worst area    0.118217\n",
            "6            mean concavity    0.080557\n",
            "20             worst radius    0.077975\n",
            "22          worst perimeter    0.074292\n",
            "2            mean perimeter    0.060092\n",
            "3                 mean area    0.053810\n",
            "26          worst concavity    0.041080\n",
            "0               mean radius    0.032312\n",
            "13               area error    0.029538\n",
            "21            worst texture    0.018786\n",
            "25        worst compactness    0.017539\n",
            "10             radius error    0.016435\n",
            "28           worst symmetry    0.012929\n",
            "12          perimeter error    0.011770\n",
            "24         worst smoothness    0.011769\n",
            "1              mean texture    0.011064\n",
            "5          mean compactness    0.009216\n",
            "19  fractal dimension error    0.007135\n",
            "29  worst fractal dimension    0.006924\n",
            "4           mean smoothness    0.006223\n",
            "14         smoothness error    0.005881\n",
            "16          concavity error    0.005816\n",
            "15        compactness error    0.004596\n",
            "18           symmetry error    0.004001\n",
            "17     concave points error    0.003382\n",
            "8             mean symmetry    0.003278\n",
            "11            texture error    0.003172\n",
            "9    mean fractal dimension    0.003140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Train a Random Forest Regressor and compare its performance with a single Decision Tree."
      ],
      "metadata": {
        "id": "64qE38w4GFis"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ce98e9"
      },
      "source": [
        "### 1. Generate a sample dataset for regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10c75a21",
        "outputId": "cba6b5cd-e4bd-4e7d-deb8-7a27a615a334"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a synthetic dataset for regression\n",
        "X_comp, y_comp = make_regression(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_targets=1,             # Number of target variables\n",
        "    noise=50,                # Standard deviation of the gaussian noise\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Regression Dataset shape: X_comp={X_comp.shape}, y_comp={y_comp.shape}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Dataset shape: X_comp=(1000, 20), y_comp=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9906ecdf"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c270478c",
        "outputId": "715d0e06-0a87-4276-ddd2-e08c23aab226"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_comp, X_test_comp, y_train_comp, y_test_comp = train_test_split(X_comp, y_comp, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_comp={X_train_comp.shape}, y_train_comp={y_train_comp.shape}\")\n",
        "print(f\"Testing data shape: X_test_comp={X_test_comp.shape}, y_test_comp={y_test_comp.shape}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_comp=(700, 20), y_train_comp=(700,)\n",
            "Testing data shape: X_test_comp=(300, 20), y_test_comp=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08876276"
      },
      "source": [
        "### 3. Train a single Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ec2dc1e",
        "outputId": "13cbebc3-8f9c-476d-b536-125899eeda43"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Initialize and train a single Decision Tree Regressor\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "dt_reg.fit(X_train_comp, y_train_comp)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred_dt = dt_reg.predict(X_test_comp)\n",
        "mse_dt = mean_squared_error(y_test_comp, y_pred_dt)\n",
        "\n",
        "print(f\"Single Decision Tree Regressor MSE: {mse_dt:.4f}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Decision Tree Regressor MSE: 25597.4799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "835537cb"
      },
      "source": [
        "### 4. Train a Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b992c12",
        "outputId": "60c55ed5-17fa-4f99-da40-347e863ff90b"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize and train a Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_reg.fit(X_train_comp, y_train_comp)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred_rf = rf_reg.predict(X_test_comp)\n",
        "mse_rf = mean_squared_error(y_test_comp, y_pred_rf)\n",
        "\n",
        "print(f\"Random Forest Regressor MSE: {mse_rf:.4f}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor MSE: 9615.9364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1024db76"
      },
      "source": [
        "### 5. Compare the performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76641ff0",
        "outputId": "7aafd518-43d6-42eb-c608-7f813696f548"
      },
      "source": [
        "print(f\"Comparison of MSE:\")\n",
        "print(f\"  Single Decision Tree Regressor: {mse_dt:.4f}\")\n",
        "print(f\"  Random Forest Regressor:        {mse_rf:.4f}\")\n",
        "\n",
        "if mse_rf < mse_dt:\n",
        "    print(\"\\nAs expected, the Random Forest Regressor generally performs better (has lower MSE) than a single Decision Tree Regressor due to its ensemble nature, which reduces variance and overfitting.\")\n",
        "elif mse_rf > mse_dt:\n",
        "    print(\"\\nIn this specific case, the single Decision Tree Regressor performed better. This can sometimes happen with very simple datasets or if the Random Forest hyperparameters are not optimally tuned, but generally, Random Forest is expected to outperform a single tree.\")\n",
        "else:\n",
        "    print(\"\\nThe performance (MSE) of both models is identical.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of MSE:\n",
            "  Single Decision Tree Regressor: 25597.4799\n",
            "  Random Forest Regressor:        9615.9364\n",
            "\n",
            "As expected, the Random Forest Regressor generally performs better (has lower MSE) than a single Decision Tree Regressor due to its ensemble nature, which reduces variance and overfitting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.  Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier."
      ],
      "metadata": {
        "id": "iPqs7Ca2GTCK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbf0da8c"
      },
      "source": [
        "### 1. Load the Breast Cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b8319e8",
        "outputId": "dc14bb50-6931-46fe-db17-b435e4dd399b"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data_oob = load_breast_cancer()\n",
        "X_oob = data_oob.data\n",
        "y_oob = data_oob.target\n",
        "\n",
        "print(f\"Breast Cancer Dataset shape: X={X_oob.shape}, y={y_oob.shape}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast Cancer Dataset shape: X=(569, 30), y=(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cee8586"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24aeac2e",
        "outputId": "01ae47e7-2051-49b1-b064-8287896c3333"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_oob, X_test_oob, y_train_oob, y_test_oob = train_test_split(X_oob, y_oob, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_oob={X_train_oob.shape}, y_train_oob={y_train_oob.shape}\")\n",
        "print(f\"Testing data shape: X_test_oob={X_test_oob.shape}, y_test_oob={y_test_oob.shape}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_oob=(398, 30), y_train_oob=(398,)\n",
            "Testing data shape: X_test_oob=(171, 30), y_test_oob=(171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21d7b34d"
      },
      "source": [
        "### 3. Initialize and train a Random Forest Classifier with OOB score enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "488429db",
        "outputId": "cbd2b66c-b88b-4758-97d4-89fccda3ddd9"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest Classifier with oob_score=True\n",
        "# oob_score=True enables the calculation of the out-of-bag score\n",
        "rf_oob_clf = RandomForestClassifier(\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    oob_score=True,   # Enable OOB score calculation\n",
        "    random_state=42,\n",
        "    n_jobs=-1         # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_oob_clf.fit(X_train_oob, y_train_oob)\n",
        "print(\"Random Forest Classifier trained successfully with OOB score enabled.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier trained successfully with OOB score enabled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb678447"
      },
      "source": [
        "### 4. Print the Out-of-Bag (OOB) Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8017ccd0",
        "outputId": "324cf412-63ef-4398-e137-3055b33d9c3e"
      },
      "source": [
        "# The oob_score_ attribute contains the computed OOB score\n",
        "oob_score = rf_oob_clf.oob_score_\n",
        "\n",
        "print(f\"Random Forest Classifier Out-of-Bag (OOB) Score: {oob_score:.4f}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Out-of-Bag (OOB) Score: 0.9548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "26.Train a Bagging Classifier using SVM as a base estimator and print accuracy."
      ],
      "metadata": {
        "id": "ngdY3z5QGxr4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78cf39f3"
      },
      "source": [
        "### 1. Generate a sample dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02a24ae6",
        "outputId": "e497fddf-aa75-4348-af72-887ed81ba865"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a synthetic dataset for classification\n",
        "X_svm, y_svm = make_classification(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_redundant=5,           # Number of redundant features\n",
        "    n_classes=2,             # Number of target classes\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Dataset shape for SVM: X={X_svm.shape}, y={y_svm.shape}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape for SVM: X=(1000, 20), y=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6771b814"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d90e674",
        "outputId": "e0202202-46f7-437a-8e98-3c34188aa12b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_svm, y_svm, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape for SVM: X_train={X_train_svm.shape}, y_train={y_train_svm.shape}\")\n",
        "print(f\"Testing data shape for SVM: X_test={X_test_svm.shape}, y_test={y_test_svm.shape}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape for SVM: X_train=(700, 20), y_train=(700,)\n",
            "Testing data shape for SVM: X_test=(300, 20), y_test=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1a56df2"
      },
      "source": [
        "### 3. Initialize and train a Bagging Classifier with SVM as base estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cc866b5",
        "outputId": "630b9af5-d253-4747-b6f2-5c1865170f8b"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize an SVC (Support Vector Classifier) as the base estimator\n",
        "# It's often beneficial to use a kernel like 'linear' or 'rbf' and tune C.\n",
        "# For demonstration, we'll start with default, but could tune further.\n",
        "base_estimator_svm = SVC(random_state=42, kernel='rbf', probability=True) # probability=True is needed for some internal Bagging methods, though not strictly for simple voting\n",
        "\n",
        "# Initialize the Bagging Classifier\n",
        "# n_estimators: number of base estimators (SVMs) in the ensemble\n",
        "# random_state: for reproducibility\n",
        "# n_jobs: use all available CPU cores for parallel training (important for SVMs)\n",
        "bagging_svm_clf = BaggingClassifier(\n",
        "    estimator=base_estimator_svm,\n",
        "    n_estimators=10, # Using a smaller number of estimators for SVMs due to higher computational cost\n",
        "    random_state=42,\n",
        "    n_jobs=-1, # Use all available CPU cores for parallel training\n",
        "    max_samples=0.8 # Use 80% of samples for each base estimator to introduce more diversity\n",
        ")\n",
        "\n",
        "# Train the Bagging Classifier\n",
        "print(\"Training Bagging Classifier with SVM base estimators... This might take a moment.\")\n",
        "bagging_svm_clf.fit(X_train_svm, y_train_svm)\n",
        "print(\"Bagging Classifier with SVM base estimators trained successfully.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bagging Classifier with SVM base estimators... This might take a moment.\n",
            "Bagging Classifier with SVM base estimators trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d339ee8"
      },
      "source": [
        "### 4. Make predictions and print model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dc52b30",
        "outputId": "fc714e3f-180f-411a-ed0f-e7a3b4e0dfb5"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_svm = bagging_svm_clf.predict(X_test_svm)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy_svm = accuracy_score(y_test_svm, y_pred_svm)\n",
        "\n",
        "print(f\"Bagging Classifier (with SVM base) Accuracy: {accuracy_svm:.4f}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (with SVM base) Accuracy: 0.9567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "27.  Train a Random Forest Classifier with different numbers of trees and compare accuracy."
      ],
      "metadata": {
        "id": "h2WLJ0foHGP5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79d61d1a"
      },
      "source": [
        "### 1. Load the Breast Cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd7f42e3",
        "outputId": "2906d9ea-8263-41c6-815e-5f618c7d4326"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data_rf_comp = load_breast_cancer()\n",
        "X_rf_comp = data_rf_comp.data\n",
        "y_rf_comp = data_rf_comp.target\n",
        "\n",
        "print(f\"Breast Cancer Dataset shape: X={X_rf_comp.shape}, y={y_rf_comp.shape}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast Cancer Dataset shape: X=(569, 30), y=(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c416307"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d64daf4d",
        "outputId": "fbf2cd49-a722-4d81-e2e3-89cc2a21c640"
      },
      "source": [
        "X_train_rf_comp, X_test_rf_comp, y_train_rf_comp, y_test_rf_comp = train_test_split(X_rf_comp, y_rf_comp, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train={X_train_rf_comp.shape}, y_train={y_train_rf_comp.shape}\")\n",
        "print(f\"Testing data shape: X_test={X_test_rf_comp.shape}, y_test={y_test_rf_comp.shape}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train=(398, 30), y_train=(398,)\n",
            "Testing data shape: X_test=(171, 30), y_test=(171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8f7b2e8"
      },
      "source": [
        "### 3. Train Random Forest Classifiers with different numbers of trees and compare accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43b80823",
        "outputId": "70ea4b31-7ce3-4959-8400-e36b81dec1dc"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a list of n_estimators values to test\n",
        "n_estimators_list = [10, 50, 100, 200, 500]\n",
        "accuracies = []\n",
        "\n",
        "for n_estimators in n_estimators_list:\n",
        "    print(f\"Training Random Forest Classifier with {n_estimators} trees...\")\n",
        "    rf_clf_var = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        random_state=42,\n",
        "        n_jobs=-1 # Use all available CPU cores\n",
        "    )\n",
        "    rf_clf_var.fit(X_train_rf_comp, y_train_rf_comp)\n",
        "    y_pred_rf_var = rf_clf_var.predict(X_test_rf_comp)\n",
        "    accuracy_rf_var = accuracy_score(y_test_rf_comp, y_pred_rf_var)\n",
        "    accuracies.append(accuracy_rf_var)\n",
        "    print(f\"  Accuracy with {n_estimators} trees: {accuracy_rf_var:.4f}\")\n",
        "\n",
        "print(\"\\n--- Comparison --- \")\n",
        "for i, n_estimators in enumerate(n_estimators_list):\n",
        "    print(f\"Number of Trees: {n_estimators}, Accuracy: {accuracies[i]:.4f}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest Classifier with 10 trees...\n",
            "  Accuracy with 10 trees: 0.9649\n",
            "Training Random Forest Classifier with 50 trees...\n",
            "  Accuracy with 50 trees: 0.9708\n",
            "Training Random Forest Classifier with 100 trees...\n",
            "  Accuracy with 100 trees: 0.9708\n",
            "Training Random Forest Classifier with 200 trees...\n",
            "  Accuracy with 200 trees: 0.9708\n",
            "Training Random Forest Classifier with 500 trees...\n",
            "  Accuracy with 500 trees: 0.9708\n",
            "\n",
            "--- Comparison --- \n",
            "Number of Trees: 10, Accuracy: 0.9649\n",
            "Number of Trees: 50, Accuracy: 0.9708\n",
            "Number of Trees: 100, Accuracy: 0.9708\n",
            "Number of Trees: 200, Accuracy: 0.9708\n",
            "Number of Trees: 500, Accuracy: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c2fb711"
      },
      "source": [
        "### 4. Visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "d2c8bb6b",
        "outputId": "59c97b1d-844c-4b9f-f376-72b70b0fbcba"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(n_estimators_list, accuracies, marker='o', linestyle='-')\n",
        "plt.title('Random Forest Classifier Accuracy vs. Number of Trees')\n",
        "plt.xlabel('Number of Trees (n_estimators)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(n_estimators_list)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "28.  Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score."
      ],
      "metadata": {
        "id": "3TjrUyS9HWxN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aecad2cf"
      },
      "source": [
        "### 1. Generate a sample dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c976174",
        "outputId": "c6fe0e62-dcba-42f5-d885-3196a8b604ef"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a synthetic dataset for classification\n",
        "X_lr, y_lr = make_classification(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_redundant=5,           # Number of redundant features\n",
        "    n_classes=2,             # Number of target classes\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Dataset shape for Logistic Regression Bagging: X={X_lr.shape}, y={y_lr.shape}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape for Logistic Regression Bagging: X=(1000, 20), y=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13dff7a8"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5978c4fa",
        "outputId": "787a1eed-decd-4eb1-b7f6-40c9c61ef764"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X_lr, y_lr, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape for Logistic Regression Bagging: X_train={X_train_lr.shape}, y_train={y_train_lr.shape}\")\n",
        "print(f\"Testing data shape for Logistic Regression Bagging: X_test={X_test_lr.shape}, y_test={y_test_lr.shape}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape for Logistic Regression Bagging: X_train=(700, 20), y_train=(700,)\n",
            "Testing data shape for Logistic Regression Bagging: X_test=(300, 20), y_test=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcf89e55"
      },
      "source": [
        "### 3. Initialize and train a Bagging Classifier with Logistic Regression as base estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06b99445",
        "outputId": "016ea39e-0469-4a3c-97a4-caaaef016031"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize a Logistic Regression model as the base estimator\n",
        "# max_iter is increased to ensure convergence\n",
        "base_estimator_lr = LogisticRegression(random_state=42, solver='liblinear', max_iter=500)\n",
        "\n",
        "# Initialize the Bagging Classifier\n",
        "# n_estimators: number of base estimators (Logistic Regression models) in the ensemble\n",
        "# random_state: for reproducibility\n",
        "# n_jobs: use all available CPU cores for parallel training\n",
        "bagging_lr_clf = BaggingClassifier(\n",
        "    estimator=base_estimator_lr,\n",
        "    n_estimators=10, # Using 10 Logistic Regression models\n",
        "    random_state=42,\n",
        "    n_jobs=-1, # Use all available CPU cores for parallel training\n",
        "    max_samples=0.8 # Use 80% of samples for each base estimator to introduce more diversity\n",
        ")\n",
        "\n",
        "# Train the Bagging Classifier\n",
        "print(\"Training Bagging Classifier with Logistic Regression base estimators...\")\n",
        "bagging_lr_clf.fit(X_train_lr, y_train_lr)\n",
        "print(\"Bagging Classifier with Logistic Regression base estimators trained successfully.\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bagging Classifier with Logistic Regression base estimators...\n",
            "Bagging Classifier with Logistic Regression base estimators trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27001aa7"
      },
      "source": [
        "### 4. Make predictions and print AUC score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99c19c6b",
        "outputId": "866267d5-a20d-4925-80b5-7dca59fc4692"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Make probability predictions on the test set (needed for AUC score)\n",
        "y_pred_proba_lr = bagging_lr_clf.predict_proba(X_test_lr)[:, 1]\n",
        "\n",
        "# Calculate the AUC score\n",
        "auc_score = roc_auc_score(y_test_lr, y_pred_proba_lr)\n",
        "\n",
        "print(f\"Bagging Classifier (with Logistic Regression base) AUC Score: {auc_score:.4f}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (with Logistic Regression base) AUC Score: 0.9133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. Train a Random Forest Regressor and analyze feature importance scores."
      ],
      "metadata": {
        "id": "10EI3kDdHrsF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af05725f"
      },
      "source": [
        "### 1. Generate a sample dataset for regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d0b8847",
        "outputId": "1a2bdb32-efeb-4d8e-b937-d996269cf783"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a synthetic dataset for regression\n",
        "X_rf_reg, y_rf_reg = make_regression(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_targets=1,             # Number of target variables\n",
        "    noise=50,                # Standard deviation of the gaussian noise\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Regression Dataset shape: X_rf_reg={X_rf_reg.shape}, y_rf_reg={y_rf_reg.shape}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Dataset shape: X_rf_reg=(1000, 20), y_rf_reg=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "115cc09a"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "678d9627",
        "outputId": "58606d64-4147-4211-bf96-0a39bd89df3a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_rf_reg, X_test_rf_reg, y_train_rf_reg, y_test_rf_reg = train_test_split(X_rf_reg, y_rf_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_rf_reg={X_train_rf_reg.shape}, y_train_rf_reg={y_train_rf_reg.shape}\")\n",
        "print(f\"Testing data shape: X_test_rf_reg={X_test_rf_reg.shape}, y_test_rf_reg={y_test_rf_reg.shape}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_rf_reg=(700, 20), y_train_rf_reg=(700,)\n",
            "Testing data shape: X_test_rf_reg=(300, 20), y_test_rf_reg=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51bbfdd1"
      },
      "source": [
        "### 3. Initialize and train a Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2ca1a01",
        "outputId": "33259200-0594-4454-f7a0-acf8e239c423"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize the Random Forest Regressor\n",
        "# n_estimators: number of trees in the forest\n",
        "# random_state: for reproducibility\n",
        "# n_jobs: use all available CPU cores for parallel training\n",
        "rf_reg_importance = RandomForestRegressor(\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train the Random Forest Regressor\n",
        "rf_reg_importance.fit(X_train_rf_reg, y_train_rf_reg)\n",
        "print(\"Random Forest Regressor trained successfully.\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d06f6011"
      },
      "source": [
        "### 4. Analyze feature importance scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "243fe48e",
        "outputId": "b1852b04-c736-42c4-d0d9-bda183ebe8ad"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Get feature importances from the trained model\n",
        "feature_importances_reg = rf_reg_importance.feature_importances_\n",
        "\n",
        "# For synthetic datasets, feature names are not directly available.\n",
        "# We can create generic names (e.g., 'Feature 0', 'Feature 1', ...)\n",
        "feature_names_reg = [f'Feature {i}' for i in range(X_rf_reg.shape[1])]\n",
        "\n",
        "# Create a DataFrame for better visualization of feature importances\n",
        "importance_df_reg = pd.DataFrame({\n",
        "    'Feature': feature_names_reg,\n",
        "    'Importance': feature_importances_reg\n",
        "})\n",
        "\n",
        "# Sort the features by importance in descending order\n",
        "importance_df_reg = importance_df_reg.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"Feature Importances (Mean Decrease in Impurity) for Random Forest Regressor:\")\n",
        "print(importance_df_reg)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances (Mean Decrease in Impurity) for Random Forest Regressor:\n",
            "       Feature  Importance\n",
            "1    Feature 1    0.230329\n",
            "17  Feature 17    0.184639\n",
            "4    Feature 4    0.165189\n",
            "0    Feature 0    0.127123\n",
            "6    Feature 6    0.111161\n",
            "11  Feature 11    0.025657\n",
            "15  Feature 15    0.019459\n",
            "16  Feature 16    0.013616\n",
            "10  Feature 10    0.011839\n",
            "5    Feature 5    0.011539\n",
            "19  Feature 19    0.011481\n",
            "8    Feature 8    0.011318\n",
            "18  Feature 18    0.010493\n",
            "13  Feature 13    0.010346\n",
            "14  Feature 14    0.010016\n",
            "12  Feature 12    0.009729\n",
            "9    Feature 9    0.009116\n",
            "7    Feature 7    0.009016\n",
            "3    Feature 3    0.008977\n",
            "2    Feature 2    0.008960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 30. Train an ensemble model using both Bagging and Random Forest and compare accuracy."
      ],
      "metadata": {
        "id": "humD1AE1H99m"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a3d3ab5"
      },
      "source": [
        "### 1. Generate a sample dataset for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99780da0",
        "outputId": "6f7b1e93-e311-4d7f-9ac0-ef80ff3a56f5"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a synthetic dataset for classification\n",
        "X_ensemble, y_ensemble = make_classification(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_redundant=5,           # Number of redundant features\n",
        "    n_classes=2,             # Number of target classes\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Ensemble Comparison Dataset shape: X={X_ensemble.shape}, y={y_ensemble.shape}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Comparison Dataset shape: X=(1000, 20), y=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "927dbff1"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be5a9d97",
        "outputId": "812f52f2-02dd-4d00-b00c-0c76cc8ea0cd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_ensemble, X_test_ensemble, y_train_ensemble, y_test_ensemble = train_test_split(X_ensemble, y_ensemble, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_ensemble={X_train_ensemble.shape}, y_train_ensemble={y_train_ensemble.shape}\")\n",
        "print(f\"Testing data shape: X_test_ensemble={X_test_ensemble.shape}, y_test_ensemble={y_test_ensemble.shape}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_ensemble=(700, 20), y_train_ensemble=(700,)\n",
            "Testing data shape: X_test_ensemble=(300, 20), y_test_ensemble=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0101623d"
      },
      "source": [
        "### 3. Train a Bagging Classifier (using Decision Trees)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a1fecde",
        "outputId": "f27b1202-d2f5-435b-f000-8c95d89f9085"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize a Decision Tree Classifier as the base estimator for Bagging\n",
        "bagging_base_estimator = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Initialize the Bagging Classifier\n",
        "bagging_clf_comp = BaggingClassifier(\n",
        "    estimator=bagging_base_estimator,\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train the Bagging Classifier\n",
        "bagging_clf_comp.fit(X_train_ensemble, y_train_ensemble)\n",
        "\n",
        "# Make predictions and evaluate accuracy\n",
        "y_pred_bagging = bagging_clf_comp.predict(X_test_ensemble)\n",
        "accuracy_bagging = accuracy_score(y_test_ensemble, y_pred_bagging)\n",
        "\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy_bagging:.4f}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.9133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7160e919"
      },
      "source": [
        "### 4. Train a Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01c7933f",
        "outputId": "01cc04d1-0223-4a53-8a6d-8239cfe8bb28"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_clf_comp = RandomForestClassifier(\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf_comp.fit(X_train_ensemble, y_train_ensemble)\n",
        "\n",
        "# Make predictions and evaluate accuracy\n",
        "y_pred_rf_comp = rf_clf_comp.predict(X_test_ensemble)\n",
        "accuracy_rf_comp = accuracy_score(y_test_ensemble, y_pred_rf_comp)\n",
        "\n",
        "print(f\"Random Forest Classifier Accuracy: {accuracy_rf_comp:.4f}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Accuracy: 0.9167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a555732"
      },
      "source": [
        "### 5. Compare the performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91479ef1",
        "outputId": "0b57bc51-5e8b-47b6-a5c3-1aed5595c638"
      },
      "source": [
        "print(f\"\\n--- Ensemble Model Accuracy Comparison ---\")\n",
        "print(f\"Bagging Classifier Accuracy:   {accuracy_bagging:.4f}\")\n",
        "print(f\"Random Forest Classifier Accuracy: {accuracy_rf_comp:.4f}\")\n",
        "\n",
        "if accuracy_rf_comp > accuracy_bagging:\n",
        "    print(\"\\nIn this comparison, the Random Forest Classifier performed slightly better than the Bagging Classifier.\")\n",
        "elif accuracy_bagging > accuracy_rf_comp:\n",
        "    print(\"\\nIn this comparison, the Bagging Classifier performed slightly better than the Random Forest Classifier.\")\n",
        "else:\n",
        "    print(\"\\nBoth Bagging Classifier and Random Forest Classifier achieved the same accuracy.\")\n",
        "\n",
        "print(\"\\nThis difference often arises because Random Forests add an extra layer of randomness (feature subsampling at each split) which further decorrelates the trees, potentially leading to better generalization than pure Bagging with Decision Trees.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Ensemble Model Accuracy Comparison ---\n",
            "Bagging Classifier Accuracy:   0.9133\n",
            "Random Forest Classifier Accuracy: 0.9167\n",
            "\n",
            "In this comparison, the Random Forest Classifier performed slightly better than the Bagging Classifier.\n",
            "\n",
            "This difference often arises because Random Forests add an extra layer of randomness (feature subsampling at each split) which further decorrelates the trees, potentially leading to better generalization than pure Bagging with Decision Trees.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV."
      ],
      "metadata": {
        "id": "kGk5TLAHIgiW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ea73c70"
      },
      "source": [
        "### 1. Load the Breast Cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd8c3bbd",
        "outputId": "e942f0f2-be6a-4a2d-a85d-55368e26739d"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data_grid = load_breast_cancer()\n",
        "X_grid = data_grid.data\n",
        "y_grid = data_grid.target\n",
        "\n",
        "print(f\"Breast Cancer Dataset shape: X={X_grid.shape}, y={y_grid.shape}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast Cancer Dataset shape: X=(569, 30), y=(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "403fbe1e"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebfefcfa",
        "outputId": "619c2061-1b65-4ace-e918-836ac7cca095"
      },
      "source": [
        "X_train_grid, X_test_grid, y_train_grid, y_test_grid = train_test_split(X_grid, y_grid, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_grid={X_train_grid.shape}, y_train_grid={y_train_grid.shape}\")\n",
        "print(f\"Testing data shape: X_test_grid={X_test_grid.shape}, y_test_grid={y_test_grid.shape}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_grid=(398, 30), y_train_grid=(398,)\n",
            "Testing data shape: X_test_grid=(171, 30), y_test_grid=(171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8569a0a3"
      },
      "source": [
        "### 3. Define the parameter grid and run GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c5fbf09",
        "outputId": "53045e96-98b5-443b-9e95-ae8e9d35ae00"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_clf_grid = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150], # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20],   # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5],   # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2]     # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "# estimator: The model to tune\n",
        "# param_grid: The dictionary of hyperparameters to search\n",
        "# cv: Number of folds for cross-validation\n",
        "# scoring: Metric to optimize (e.g., 'accuracy' for classification)\n",
        "# n_jobs: Number of jobs to run in parallel (-1 means use all available processors)\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_clf_grid,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1 # To see progress\n",
        ")\n",
        "\n",
        "print(\"Starting GridSearchCV to find the best hyperparameters...\")\n",
        "grid_search.fit(X_train_grid, y_train_grid)\n",
        "print(\"GridSearchCV completed.\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting GridSearchCV to find the best hyperparameters...\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
            "GridSearchCV completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "826e867c"
      },
      "source": [
        "### 4. Print the best parameters and best score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d888e1a",
        "outputId": "0dac827e-8742-431c-a4c9-1f635494152b"
      },
      "source": [
        "print(\"Best parameters found by GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found by GridSearchCV:\n",
            "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}\n",
            "Best cross-validation accuracy: 0.9572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac2bb1a6"
      },
      "source": [
        "### 5. Evaluate the best model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd3ffbae",
        "outputId": "a95670ed-0b97-4313-cef4-8c16a8f2a80e"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Get the best model found by GridSearchCV\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "y_pred_best_rf = best_rf_model.predict(X_test_grid)\n",
        "\n",
        "# Calculate the accuracy on the test set\n",
        "test_accuracy = accuracy_score(y_test_grid, y_pred_best_rf)\n",
        "\n",
        "print(f\"Test set accuracy with the best Random Forest model: {test_accuracy:.4f}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy with the best Random Forest model: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "32.  Train a Bagging Regressor with different numbers of base estimators and compare performance."
      ],
      "metadata": {
        "id": "dpbLptcBJDtr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31d1d4d6"
      },
      "source": [
        "# Task\n",
        "Generate a synthetic regression dataset with 1000 samples and 20 features, including some noise, then split it into training and testing sets. Train multiple `BaggingRegressor` models with varying numbers of base estimators (Decision Trees). For each model, calculate the Mean Squared Error (MSE) on the test set and plot the MSE against the number of estimators. Finally, summarize the relationship between the number of estimators and the `BaggingRegressor`'s performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ff150b0"
      },
      "source": [
        "## Generate Regression Dataset\n",
        "\n",
        "### Subtask:\n",
        "Generate a synthetic regression dataset using `make_regression` with 1000 samples, 20 features, and some noise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3302c4a6"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask asks to generate a synthetic regression dataset using `make_regression` with specific parameters and then print its shape. This code block directly addresses these requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb150c0c",
        "outputId": "7317b1e6-2972-4b56-90b7-fa7876aee0df"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a synthetic dataset for regression\n",
        "X_reg_comp, y_reg_comp = make_regression(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_targets=1,             # Number of target variables\n",
        "    noise=50,                # Standard deviation of the gaussian noise\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Regression Dataset shape: X_reg_comp={X_reg_comp.shape}, y_reg_comp={y_reg_comp.shape}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Dataset shape: X_reg_comp=(1000, 20), y_reg_comp=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc973c89"
      },
      "source": [
        "## Split Data into Training and Testing Sets\n",
        "\n",
        "### Subtask:\n",
        "Split the generated regression dataset (`X_reg_comp`, `y_reg_comp`) into training and testing sets.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `train_test_split` from `sklearn.model_selection`.\n",
        "2. Split the `X_reg_comp` and `y_reg_comp` into `X_train_reg_comp`, `X_test_reg_comp`, `y_train_reg_comp`, and `y_test_reg_comp` using a `test_size` of 0.3 and `random_state=42`.\n",
        "3. Print the shapes of the training and testing sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d397d15"
      },
      "source": [
        "**Reasoning**:\n",
        "This code block directly addresses the subtask's instructions to split the data into training and testing sets using `train_test_split` and print their shapes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2151f3ac",
        "outputId": "80f93ebd-af88-47fb-ee09-81620550b5e0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_reg_comp, X_test_reg_comp, y_train_reg_comp, y_test_reg_comp = train_test_split(X_reg_comp, y_reg_comp, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Regression Training data shape: X_train_reg_comp={X_train_reg_comp.shape}, y_train_reg_comp={y_train_reg_comp.shape}\")\n",
        "print(f\"Regression Testing data shape: X_test_reg_comp={X_test_reg_comp.shape}, y_test_reg_comp={y_test_reg_comp.shape}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Training data shape: X_train_reg_comp=(700, 20), y_train_reg_comp=(700,)\n",
            "Regression Testing data shape: X_test_reg_comp=(300, 20), y_test_reg_comp=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08f86e60"
      },
      "source": [
        "## Train Bagging Regressors with Varying `n_estimators` and Evaluate Performance\n",
        "\n",
        "### Subtask:\n",
        "Train multiple `BaggingRegressor` models with different numbers of base estimators (Decision Trees) and calculate the Mean Squared Error (MSE) for each on the test set.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `BaggingRegressor` from `sklearn.ensemble` and `DecisionTreeRegressor` from `sklearn.tree`.\n",
        "2. Import `mean_squared_error` from `sklearn.metrics`.\n",
        "3. Define a list of `n_estimators` values to test (e.g., `[10, 50, 100, 200, 500]`).\n",
        "4. Initialize an empty list to store MSE values.\n",
        "5. Loop through the `n_estimators_list`:\n",
        "    a. For each `n_estimators` value, initialize a `BaggingRegressor` with `DecisionTreeRegressor` as the `estimator`, `n_estimators=current_n_estimators`, `random_state=42`, and `n_jobs=-1`.\n",
        "    b. Train the `BaggingRegressor` on the training data (`X_train_reg_comp`, `y_train_reg_comp`).\n",
        "    c. Make predictions on the test set (`X_test_reg_comp`).\n",
        "    d. Calculate the Mean Squared Error (MSE) between the predictions and the true test labels (`y_test_reg_comp`).\n",
        "    e. Store the calculated MSE.\n",
        "    f. Print the `n_estimators` value and its corresponding MSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8594f7e2"
      },
      "source": [
        "**Reasoning**:\n",
        "This code block directly addresses the subtask's instructions to train multiple `BaggingRegressor` models with varying numbers of estimators, calculate their MSE, and print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59fb74e7",
        "outputId": "c7ca65f4-3f13-43dd-dbcd-6de35f59c0bc"
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define a list of n_estimators values to test\n",
        "n_estimators_list = [10, 50, 100, 200, 500]\n",
        "mse_values = []\n",
        "\n",
        "for n_estimators in n_estimators_list:\n",
        "    print(f\"Training Bagging Regressor with {n_estimators} estimators...\")\n",
        "    # Initialize a Decision Tree Regressor as the base estimator\n",
        "    base_estimator_br = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "    # Initialize the Bagging Regressor\n",
        "    bagging_reg_comp = BaggingRegressor(\n",
        "        estimator=base_estimator_br,\n",
        "        n_estimators=n_estimators,\n",
        "        random_state=42,\n",
        "        n_jobs=-1 # Use all available CPU cores for parallel training\n",
        "    )\n",
        "\n",
        "    # Train the Bagging Regressor\n",
        "    bagging_reg_comp.fit(X_train_reg_comp, y_train_reg_comp)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_br = bagging_reg_comp.predict(X_test_reg_comp)\n",
        "\n",
        "    # Calculate the Mean Squared Error\n",
        "    mse = mean_squared_error(y_test_reg_comp, y_pred_br)\n",
        "    mse_values.append(mse)\n",
        "    print(f\"  MSE with {n_estimators} estimators: {mse:.4f}\")\n",
        "\n",
        "print(\"\\nAll Bagging Regressors trained and evaluated successfully.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bagging Regressor with 10 estimators...\n",
            "  MSE with 10 estimators: 11537.4632\n",
            "Training Bagging Regressor with 50 estimators...\n",
            "  MSE with 50 estimators: 9752.0874\n",
            "Training Bagging Regressor with 100 estimators...\n",
            "  MSE with 100 estimators: 9617.3688\n",
            "Training Bagging Regressor with 200 estimators...\n",
            "  MSE with 200 estimators: 9295.5479\n",
            "Training Bagging Regressor with 500 estimators...\n",
            "  MSE with 500 estimators: 9259.7100\n",
            "\n",
            "All Bagging Regressors trained and evaluated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "130242d3"
      },
      "source": [
        "## Plot MSE vs. Number of Estimators\n",
        "\n",
        "### Subtask:\n",
        "Plot the Mean Squared Error (MSE) against the number of estimators (`n_estimators`) to visualize the Bagging Regressor's performance trend.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `matplotlib.pyplot` as `plt`.\n",
        "2. Create a plot with `n_estimators_list` on the x-axis and `mse_values` on the y-axis.\n",
        "3. Add a title, x-label, and y-label to the plot.\n",
        "4. Add a grid for better readability.\n",
        "5. Display the plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34b19d8b"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step calculated and stored the MSE values for different numbers of estimators. The next logical step is to visualize this relationship as described in the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "6071a918",
        "outputId": "a6c1b9fa-4e9f-4129-d97e-61d77ee25ddc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the MSE values against the number of estimators\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(n_estimators_list, mse_values, marker='o', linestyle='-')\n",
        "plt.title('Bagging Regressor Performance (MSE) vs. Number of Estimators')\n",
        "plt.xlabel('Number of Estimators (n_estimators)')\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.xticks(n_estimators_list)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "33. Train a Random Forest Classifier and analyze misclassified samples.\n"
      ],
      "metadata": {
        "id": "G9NNaEKZKI9p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb7276f1"
      },
      "source": [
        "## Load Breast Cancer Dataset\n",
        "\n",
        "### Subtask:\n",
        "Load the Breast Cancer dataset from `sklearn.datasets`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ee76e8a"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires loading the Breast Cancer dataset, storing features and target in specified variables, and printing their shapes. This code block directly addresses these instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49d24b0d",
        "outputId": "d82b15c2-4e74-46f4-edee-b89773487de1"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data_misc = load_breast_cancer()\n",
        "X_bc_misc = data_misc.data\n",
        "y_bc_misc = data_misc.target\n",
        "\n",
        "print(f\"Breast Cancer Dataset shape: X_bc_misc={X_bc_misc.shape}, y_bc_misc={y_bc_misc.shape}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast Cancer Dataset shape: X_bc_misc=(569, 30), y_bc_misc=(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9106b1a8"
      },
      "source": [
        "## Split Data into Training and Testing Sets\n",
        "\n",
        "### Subtask:\n",
        "Split the loaded Breast Cancer dataset (`X_bc_misc`, `y_bc_misc`) into training and testing sets.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `train_test_split` from `sklearn.model_selection`.\n",
        "2. Split the `X_bc_misc` and `y_bc_misc` into `X_train_bc_misc`, `X_test_bc_misc`, `y_train_bc_misc`, and `y_test_bc_misc` using a `test_size` of 0.3 and `random_state=42`.\n",
        "3. Print the shapes of the training and testing sets to verify the split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b99325e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for splitting the dataset. This code block will now perform the actual splitting of the Breast Cancer dataset into training and testing sets, as well as printing their shapes, as per the subtask requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e5132d2",
        "outputId": "f3b37e13-2867-4df7-8d83-6ca9904e857f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_bc_misc, X_test_bc_misc, y_train_bc_misc, y_test_bc_misc = train_test_split(X_bc_misc, y_bc_misc, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_bc_misc={X_train_bc_misc.shape}, y_train_bc_misc={y_train_bc_misc.shape}\")\n",
        "print(f\"Testing data shape: X_test_bc_misc={X_test_bc_misc.shape}, y_test_bc_misc={y_test_bc_misc.shape}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_bc_misc=(398, 30), y_train_bc_misc=(398,)\n",
            "Testing data shape: X_test_bc_misc=(171, 30), y_test_bc_misc=(171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dea7a7e"
      },
      "source": [
        "## Train Random Forest Classifier\n",
        "\n",
        "### Subtask:\n",
        "Initialize and train a `RandomForestClassifier` on the training data.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `RandomForestClassifier` from `sklearn.ensemble`.\n",
        "2. Initialize a `RandomForestClassifier` with `n_estimators=100`, `random_state=42`, and `n_jobs=-1`.\n",
        "3. Train the classifier on `X_train_bc_misc` and `y_train_bc_misc`.\n",
        "4. Print a confirmation message that the classifier has been trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89a4cba5"
      },
      "source": [
        "## Train Random Forest Classifier\n",
        "\n",
        "### Subtask:\n",
        "Initialize and train a `RandomForestClassifier` on the training data.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `RandomForestClassifier` from `sklearn.ensemble`.\n",
        "2. Initialize a `RandomForestClassifier` with `n_estimators=100`, `random_state=42`, and `n_jobs=-1`.\n",
        "3. Train the classifier on `X_train_bc_misc` and `y_train_bc_misc`.\n",
        "4. Print a confirmation message that the classifier has been trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2351dfe5"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for training a Random Forest Classifier. This code block will now implement those instructions by initializing and training the classifier on the prepared training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c43f27b9",
        "outputId": "1c74d595-4a0f-475e-e3ab-4652e41bd4e0"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_clf_misc = RandomForestClassifier(\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1         # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf_misc.fit(X_train_bc_misc, y_train_bc_misc)\n",
        "print(\"Random Forest Classifier trained successfully.\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cf4de0e"
      },
      "source": [
        "## Analyze Misclassified Samples\n",
        "\n",
        "### Subtask:\n",
        "Make predictions on the test set, identify the misclassified samples, and print their count.\n",
        "\n",
        "#### Instructions\n",
        "1. Make predictions on `X_test_bc_misc` using the trained `rf_clf_misc`.\n",
        "2. Compare these predictions with the true labels `y_test_bc_misc` to find misclassified samples.\n",
        "3. Print the total number of test samples and the number of misclassified samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee9f6b3e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for analyzing misclassified samples. This code block will now make predictions on the test set, identify the misclassified samples, and print their count as per the subtask requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9854a80f",
        "outputId": "0da5ae82-48fc-41d9-b7eb-748e39866759"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_bc_misc = rf_clf_misc.predict(X_test_bc_misc)\n",
        "\n",
        "# Identify misclassified samples\n",
        "misclassified_samples = np.where(y_pred_bc_misc != y_test_bc_misc)[0]\n",
        "\n",
        "# Count the number of misclassified samples\n",
        "num_misclassified = len(misclassified_samples)\n",
        "\n",
        "# Get the total number of test samples\n",
        "total_test_samples = len(y_test_bc_misc)\n",
        "\n",
        "print(f\"Total number of test samples: {total_test_samples}\")\n",
        "print(f\"Number of misclassified samples: {num_misclassified}\")\n",
        "print(f\"Accuracy on test set: {(total_test_samples - num_misclassified) / total_test_samples:.4f}\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of test samples: 171\n",
            "Number of misclassified samples: 5\n",
            "Accuracy on test set: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7dcd173"
      },
      "source": [
        "## Display Misclassified Samples\n",
        "\n",
        "### Subtask:\n",
        "Display relevant information (e.g., true label, predicted label, and feature values) for a few of the identified misclassified samples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c1daa4f"
      },
      "source": [
        "**Reasoning**:\n",
        "This code block will iterate through the identified misclassified samples, retrieve their true labels, predicted labels, and feature values, then display them in a human-readable format, as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2f17fdf",
        "outputId": "f5a0d766-4199-4454-c76b-5d27220c39d1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Get feature names\n",
        "feature_names_misc = data_misc.feature_names\n",
        "\n",
        "print(\"\\n--- Analysis of Misclassified Samples ---\")\n",
        "\n",
        "# Display details for a few misclassified samples (e.g., first 5)\n",
        "num_to_display = min(len(misclassified_samples), 5)\n",
        "\n",
        "if num_misclassified == 0:\n",
        "    print(\"No misclassified samples found in the test set. The model performed perfectly on the test set!\")\n",
        "else:\n",
        "    for i, sample_idx in enumerate(misclassified_samples[:num_to_display]):\n",
        "        print(f\"\\nMisclassified Sample {i + 1} (Original Test Index: {sample_idx}):\")\n",
        "        print(f\"  True Label: {data_misc.target_names[y_test_bc_misc[sample_idx]]}\")\n",
        "        print(f\"  Predicted Label: {data_misc.target_names[y_pred_bc_misc[sample_idx]]}\")\n",
        "\n",
        "        # Display feature values\n",
        "        features = pd.Series(X_test_bc_misc[sample_idx], index=feature_names_misc)\n",
        "        print(\"  Feature Values:\")\n",
        "        print(features.to_string())\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Analysis of Misclassified Samples ---\n",
            "\n",
            "Misclassified Sample 1 (Original Test Index: 8):\n",
            "  True Label: benign\n",
            "  Predicted Label: malignant\n",
            "  Feature Values:\n",
            "mean radius                 13.340000\n",
            "mean texture                15.860000\n",
            "mean perimeter              86.490000\n",
            "mean area                  520.000000\n",
            "mean smoothness              0.107800\n",
            "mean compactness             0.153500\n",
            "mean concavity               0.116900\n",
            "mean concave points          0.069870\n",
            "mean symmetry                0.194200\n",
            "mean fractal dimension       0.069020\n",
            "radius error                 0.286000\n",
            "texture error                1.016000\n",
            "perimeter error              1.535000\n",
            "area error                  12.960000\n",
            "smoothness error             0.006794\n",
            "compactness error            0.035750\n",
            "concavity error              0.039800\n",
            "concave points error         0.013830\n",
            "symmetry error               0.021340\n",
            "fractal dimension error      0.004603\n",
            "worst radius                15.530000\n",
            "worst texture               23.190000\n",
            "worst perimeter             96.660000\n",
            "worst area                 614.900000\n",
            "worst smoothness             0.153600\n",
            "worst compactness            0.479100\n",
            "worst concavity              0.485800\n",
            "worst concave points         0.170800\n",
            "worst symmetry               0.352700\n",
            "worst fractal dimension      0.101600\n",
            "\n",
            "Misclassified Sample 2 (Original Test Index: 20):\n",
            "  True Label: malignant\n",
            "  Predicted Label: benign\n",
            "  Feature Values:\n",
            "mean radius                 13.800000\n",
            "mean texture                15.790000\n",
            "mean perimeter              90.430000\n",
            "mean area                  584.100000\n",
            "mean smoothness              0.100700\n",
            "mean compactness             0.128000\n",
            "mean concavity               0.077890\n",
            "mean concave points          0.050690\n",
            "mean symmetry                0.166200\n",
            "mean fractal dimension       0.065660\n",
            "radius error                 0.278700\n",
            "texture error                0.620500\n",
            "perimeter error              1.957000\n",
            "area error                  23.350000\n",
            "smoothness error             0.004717\n",
            "compactness error            0.020650\n",
            "concavity error              0.017590\n",
            "concave points error         0.009206\n",
            "symmetry error               0.012200\n",
            "fractal dimension error      0.003130\n",
            "worst radius                16.570000\n",
            "worst texture               20.860000\n",
            "worst perimeter            110.300000\n",
            "worst area                 812.400000\n",
            "worst smoothness             0.141100\n",
            "worst compactness            0.354200\n",
            "worst concavity              0.277900\n",
            "worst concave points         0.138300\n",
            "worst symmetry               0.258900\n",
            "worst fractal dimension      0.103000\n",
            "\n",
            "Misclassified Sample 3 (Original Test Index: 77):\n",
            "  True Label: malignant\n",
            "  Predicted Label: benign\n",
            "  Feature Values:\n",
            "mean radius                 13.960000\n",
            "mean texture                17.050000\n",
            "mean perimeter              91.430000\n",
            "mean area                  602.400000\n",
            "mean smoothness              0.109600\n",
            "mean compactness             0.127900\n",
            "mean concavity               0.097890\n",
            "mean concave points          0.052460\n",
            "mean symmetry                0.190800\n",
            "mean fractal dimension       0.061300\n",
            "radius error                 0.425000\n",
            "texture error                0.809800\n",
            "perimeter error              2.563000\n",
            "area error                  35.740000\n",
            "smoothness error             0.006351\n",
            "compactness error            0.026790\n",
            "concavity error              0.031190\n",
            "concave points error         0.013420\n",
            "symmetry error               0.020620\n",
            "fractal dimension error      0.002695\n",
            "worst radius                16.390000\n",
            "worst texture               22.070000\n",
            "worst perimeter            108.100000\n",
            "worst area                 826.000000\n",
            "worst smoothness             0.151200\n",
            "worst compactness            0.326200\n",
            "worst concavity              0.320900\n",
            "worst concave points         0.137400\n",
            "worst symmetry               0.306800\n",
            "worst fractal dimension      0.079570\n",
            "\n",
            "Misclassified Sample 4 (Original Test Index: 82):\n",
            "  True Label: malignant\n",
            "  Predicted Label: benign\n",
            "  Feature Values:\n",
            "mean radius                 14.480000\n",
            "mean texture                21.460000\n",
            "mean perimeter              94.250000\n",
            "mean area                  648.200000\n",
            "mean smoothness              0.094440\n",
            "mean compactness             0.099470\n",
            "mean concavity               0.120400\n",
            "mean concave points          0.049380\n",
            "mean symmetry                0.207500\n",
            "mean fractal dimension       0.056360\n",
            "radius error                 0.420400\n",
            "texture error                2.220000\n",
            "perimeter error              3.301000\n",
            "area error                  38.870000\n",
            "smoothness error             0.009369\n",
            "compactness error            0.029830\n",
            "concavity error              0.053710\n",
            "concave points error         0.017610\n",
            "symmetry error               0.024180\n",
            "fractal dimension error      0.003249\n",
            "worst radius                16.210000\n",
            "worst texture               29.250000\n",
            "worst perimeter            108.400000\n",
            "worst area                 808.900000\n",
            "worst smoothness             0.130600\n",
            "worst compactness            0.197600\n",
            "worst concavity              0.334900\n",
            "worst concave points         0.122500\n",
            "worst symmetry               0.302000\n",
            "worst fractal dimension      0.068460\n",
            "\n",
            "Misclassified Sample 5 (Original Test Index: 164):\n",
            "  True Label: malignant\n",
            "  Predicted Label: benign\n",
            "  Feature Values:\n",
            "mean radius                 15.130000\n",
            "mean texture                29.810000\n",
            "mean perimeter              96.710000\n",
            "mean area                  719.500000\n",
            "mean smoothness              0.083200\n",
            "mean compactness             0.046050\n",
            "mean concavity               0.046860\n",
            "mean concave points          0.027390\n",
            "mean symmetry                0.185200\n",
            "mean fractal dimension       0.052940\n",
            "radius error                 0.468100\n",
            "texture error                1.627000\n",
            "perimeter error              3.043000\n",
            "area error                  45.380000\n",
            "smoothness error             0.006831\n",
            "compactness error            0.014270\n",
            "concavity error              0.024890\n",
            "concave points error         0.009087\n",
            "symmetry error               0.031510\n",
            "fractal dimension error      0.001750\n",
            "worst radius                17.260000\n",
            "worst texture               36.910000\n",
            "worst perimeter            110.100000\n",
            "worst area                 931.400000\n",
            "worst smoothness             0.114800\n",
            "worst compactness            0.098660\n",
            "worst concavity              0.154700\n",
            "worst concave points         0.065750\n",
            "worst symmetry               0.323300\n",
            "worst fractal dimension      0.061650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "34.  Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier."
      ],
      "metadata": {
        "id": "cQ4WBIBTK-5D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f95c91f"
      },
      "source": [
        "# Task\n",
        "The user wants to compare the performance of a Bagging Classifier against a single Decision Tree Classifier. To achieve this, I will:\n",
        "\n",
        "1.  Generate a synthetic classification dataset.\n",
        "2.  Split the dataset into training and testing sets.\n",
        "3.  Train a single `DecisionTreeClassifier` and evaluate its accuracy.\n",
        "4.  Train a `BaggingClassifier` (using `DecisionTreeClassifier` as base estimators) and evaluate its accuracy.\n",
        "5.  Compare and print the accuracies of both models.\n",
        "\n",
        "This will demonstrate how bagging can improve performance over a single base estimator.\n",
        "```python\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Generate a synthetic classification dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=20,\n",
        "    n_informative=10,\n",
        "    n_redundant=5,\n",
        "    n_classes=2,\n",
        "    random_state=42\n",
        ")\n",
        "print(f\"Dataset shape: X={X.shape}, y={y.shape}\")\n",
        "\n",
        "# 2. Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(f\"Training data shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Testing data shape: X_test={X_test.shape}, y_test={y_test.shape}\\n\")\n",
        "\n",
        "# 3. Train a single Decision Tree Classifier\n",
        "print(\"Training Single Decision Tree Classifier...\")\n",
        "single_dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "single_dt_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_dt = single_dt_clf.predict(X_test)\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "print(f\"Single Decision Tree Classifier Accuracy: {accuracy_dt:.4f}\\n\")\n",
        "\n",
        "# 4. Train a Bagging Classifier (with Decision Trees as base estimators)\n",
        "print(\"Training Bagging Classifier...\")\n",
        "bagging_dt_clf = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    n_estimators=100, # Number of base estimators\n",
        "    random_state=42,\n",
        "    n_jobs=-1 # Use all available CPU cores for parallel training\n",
        ")\n",
        "bagging_dt_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_bagging = bagging_dt_clf.predict(X_test)\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy_bagging:.4f}\\n\")\n",
        "\n",
        "# 5. Compare the performances\n",
        "print(\"--- Performance Comparison ---\")\n",
        "print(f\"Single Decision Tree Accuracy: {accuracy_dt:.4f}\")\n",
        "print(f\"Bagging Classifier Accuracy:   {accuracy_bagging:.4f}\")\n",
        "\n",
        "# 6. Summarize and explain the differences\n",
        "if accuracy_bagging > accuracy_dt:\n",
        "    print(\"\\nObservation: The Bagging Classifier achieved higher accuracy than the single Decision Tree Classifier.\")\n",
        "    print(\"Explanation: Bagging reduces variance by training multiple base estimators on different bootstrap samples of the data and then aggregating their predictions. This process smooths out individual errors and reduces the impact of overfitting from any single tree, leading to better generalization and often higher accuracy.\")\n",
        "elif accuracy_dt > accuracy_bagging:\n",
        "    print(\"\\nObservation: The Single Decision Tree Classifier achieved higher accuracy than the Bagging Classifier in this instance.\")\n",
        "    print(\"Explanation: While Bagging typically outperforms a single decision tree, there might be cases, especially with very simple datasets or specific random states, where a single tree happens to perform marginally better. However, in general, Bagging is designed to be more robust.\")\n",
        "else:\n",
        "    print(\"\\nObservation: Both the Single Decision Tree Classifier and Bagging Classifier achieved the same accuracy.\")\n",
        "    print(\"Explanation: This can happen if the dataset is very easy to classify or if the inherent variability reduced by Bagging is minimal in this specific scenario.\")\n",
        "\n",
        "# Optional: Plot for visualization\n",
        "labels = ['Single Decision Tree', 'Bagging Classifier']\n",
        "accuracies = [accuracy_dt, accuracy_bagging]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(labels, accuracies, color=['skyblue', 'lightcoral'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Classifier Accuracy Comparison')\n",
        "plt.ylim(min(accuracies) * 0.9, 1.0) # Adjust y-axis limits for better visualization\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "731ffb0a"
      },
      "source": [
        "## Generate Classification Dataset\n",
        "\n",
        "### Subtask:\n",
        "Generate a synthetic classification dataset using `make_classification`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f710580a"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask asks to generate a synthetic classification dataset using `make_classification` with specific parameters and then print its shape. This code block directly addresses these requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ab93f91",
        "outputId": "870a462f-1045-4f08-c12e-9cf7e048ec66"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a synthetic dataset for classification\n",
        "X_compare, y_compare = make_classification(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_redundant=5,           # Number of redundant features\n",
        "    n_classes=2,             # Number of target classes\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Classification Dataset shape: X_compare={X_compare.shape}, y_compare={y_compare.shape}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Dataset shape: X_compare=(1000, 20), y_compare=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "347d96f5"
      },
      "source": [
        "## Split Data into Training and Testing Sets\n",
        "\n",
        "### Subtask:\n",
        "Split the generated classification dataset (`X_compare`, `y_compare`) into training and testing sets.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `train_test_split` from `sklearn.model_selection`.\n",
        "2. Split the `X_compare` and `y_compare` into `X_train_compare`, `X_test_compare`, `y_train_compare`, and `y_test_compare` using a `test_size` of 0.3 and `random_state=42`.\n",
        "3. Print the shapes of the training and testing sets to verify the split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52cbded9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for splitting the dataset. This code block will now perform the actual splitting of the classification dataset into training and testing sets, as well as printing their shapes, as per the subtask requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e2295e2",
        "outputId": "4c5ae883-98a2-428b-857d-a16ca7030e16"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_compare, X_test_compare, y_train_compare, y_test_compare = train_test_split(X_compare, y_compare, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape for comparison: X_train={X_train_compare.shape}, y_train={y_train_compare.shape}\")\n",
        "print(f\"Testing data shape for comparison: X_test={X_test_compare.shape}, y_test={y_test_compare.shape}\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape for comparison: X_train=(700, 20), y_train=(700,)\n",
            "Testing data shape for comparison: X_test=(300, 20), y_test=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02fc789a"
      },
      "source": [
        "## Train Single Decision Tree Classifier\n",
        "\n",
        "### Subtask:\n",
        "Train a single `DecisionTreeClassifier` on the training data and evaluate its accuracy.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `DecisionTreeClassifier` from `sklearn.tree`.\n",
        "2. Import `accuracy_score` from `sklearn.metrics`.\n",
        "3. Initialize a `DecisionTreeClassifier` with `random_state=42`.\n",
        "4. Train the classifier on `X_train_compare` and `y_train_compare`.\n",
        "5. Make predictions on `X_test_compare`.\n",
        "6. Calculate the accuracy score between `y_test_compare` and the predictions.\n",
        "7. Print the accuracy of the single Decision Tree Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c32293e1"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for training a single Decision Tree Classifier. This code block will now implement those instructions by initializing and training the classifier on the prepared training data and then evaluating its accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c00aedf",
        "outputId": "d1ed9597-daae-454f-9cdc-3714f1af8451"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize a single Decision Tree Classifier\n",
        "single_dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "single_dt_clf.fit(X_train_compare, y_train_compare)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_dt_compare = single_dt_clf.predict(X_test_compare)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy_dt_compare = accuracy_score(y_test_compare, y_pred_dt_compare)\n",
        "\n",
        "print(f\"Single Decision Tree Classifier Accuracy: {accuracy_dt_compare:.4f}\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Decision Tree Classifier Accuracy: 0.8167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3780245c"
      },
      "source": [
        "## Train Bagging Classifier\n",
        "\n",
        "### Subtask:\n",
        "Train a `BaggingClassifier` using `DecisionTreeClassifier` as base estimators and evaluate its accuracy.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `BaggingClassifier` from `sklearn.ensemble`.\n",
        "2. Initialize a `BaggingClassifier` with `DecisionTreeClassifier(random_state=42)` as the base `estimator`, `n_estimators=100`, `random_state=42`, and `n_jobs=-1`.\n",
        "3. Train the `BaggingClassifier` on `X_train_compare` and `y_train_compare`.\n",
        "4. Make predictions on `X_test_compare`.\n",
        "5. Calculate the accuracy score between `y_test_compare` and the predictions.\n",
        "6. Print the accuracy of the Bagging Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11cd5444"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for training a Bagging Classifier. This code block will now implement those instructions by initializing and training the classifier on the prepared training data and then evaluating its accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aee92872",
        "outputId": "91456729-678e-46b6-a3f9-56d5796f810d"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize a Decision Tree Classifier as the base estimator for Bagging\n",
        "bagging_base_estimator = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Initialize the Bagging Classifier\n",
        "bagging_dt_clf = BaggingClassifier(\n",
        "    estimator=bagging_base_estimator,\n",
        "    n_estimators=100, # Number of base estimators\n",
        "    random_state=42,\n",
        "    n_jobs=-1 # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "# Train the Bagging Classifier\n",
        "bagging_dt_clf.fit(X_train_compare, y_train_compare)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_bagging = bagging_dt_clf.predict(X_test_compare)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy_bagging = accuracy_score(y_test_compare, y_pred_bagging)\n",
        "\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy_bagging:.4f}\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.9133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "347e8a91"
      },
      "source": [
        "**Reasoning**:\n",
        "Both the single Decision Tree Classifier and the Bagging Classifier have been trained and evaluated. The next step is to compare their accuracies to understand the performance difference between a single model and an ensemble model, and then visualize this comparison.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "192ade16",
        "outputId": "96379599-b9f6-418e-ba2b-4356fa249b5e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 5. Compare the performances\n",
        "print(\"-- Performance Comparison --\")\n",
        "print(f\"Single Decision Tree Accuracy: {accuracy_dt_compare:.4f}\")\n",
        "print(f\"Bagging Classifier Accuracy:   {accuracy_bagging:.4f}\")\n",
        "\n",
        "# 6. Summarize and explain the differences\n",
        "if accuracy_bagging > accuracy_dt_compare:\n",
        "    print(\"\\nObservation: The Bagging Classifier achieved higher accuracy than the single Decision Tree Classifier.\")\n",
        "    print(\"Explanation: Bagging reduces variance by training multiple base estimators on different bootstrap samples of the data and then aggregating their predictions. This process smooths out individual errors and reduces the impact of overfitting from any single tree, leading to better generalization and often higher accuracy.\")\n",
        "elif accuracy_dt_compare > accuracy_bagging:\n",
        "    print(\"\\nObservation: The Single Decision Tree Classifier achieved higher accuracy than the Bagging Classifier in this instance.\")\n",
        "    print(\"Explanation: While Bagging typically outperforms a single decision tree, there might be cases, especially with very simple datasets or specific random states, where a single tree happens to perform marginally better. However, in general, Bagging is designed to be more robust.\")\n",
        "else:\n",
        "    print(\"\\nObservation: Both the Single Decision Tree Classifier and Bagging Classifier achieved the same accuracy.\")\n",
        "    print(\"Explanation: This can happen if the dataset is very easy to classify or if the inherent variability reduced by Bagging is minimal in this specific scenario.\")\n",
        "\n",
        "# Optional: Plot for visualization\n",
        "labels = ['Single Decision Tree', 'Bagging Classifier']\n",
        "accuracies = [accuracy_dt_compare, accuracy_bagging]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(labels, accuracies, color=['skyblue', 'lightcoral'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Classifier Accuracy Comparison')\n",
        "plt.ylim(min(accuracies) * 0.9, 1.0) # Adjust y-axis limits for better visualization\n",
        "plt.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Performance Comparison --\n",
            "Single Decision Tree Accuracy: 0.8167\n",
            "Bagging Classifier Accuracy:   0.9133\n",
            "\n",
            "Observation: The Bagging Classifier achieved higher accuracy than the single Decision Tree Classifier.\n",
            "Explanation: Bagging reduces variance by training multiple base estimators on different bootstrap samples of the data and then aggregating their predictions. This process smooths out individual errors and reduces the impact of overfitting from any single tree, leading to better generalization and often higher accuracy.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAHDCAYAAADGJsnKAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASKlJREFUeJzt3Xt8zvX/x/HntbHzwWk2szFzVsx5OYQyzWkhyenbWA5FKEshZ5JORChSDoksx299lWKiQgijcshhjGLOxmLY3r8/url+XW1kM8anx/12u2431/vz/rw/r8+1ufbce+/P57IZY4wAAAAAi3LK6wIAAACA24nACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACyCTkJAQde3aNc+O37VrV4WEhDi0XbhwQd27d1dAQIBsNpuef/55HTx4UDabTbNnz86TOoGcyOr7G8DtReAF/kX279+vp59+WqGhoXJzc5OPj4/q1aunSZMm6eLFi3ld3g29+uqrmj17tnr16qW5c+fqySefzLNadu3aJZvNJjc3N509ezbP6rhXXbp0SW+//bbCw8Pl6+srNzc3lStXTn369NGvv/6a1+UBsCCbMcbkdREAbr/ly5erXbt2cnV1VXR0tO6//35dvnxZ33//vRYvXqyuXbvq/fffl/TnDG+jRo3ybOb0ypUrysjIkKurq73tgQceUL58+fT999/b24wxSktLU/78+eXs7HzH6hsyZIhmzpypM2fOaMqUKerevfsdO/a97uTJk2ratKm2bNmili1bKiIiQl5eXtqzZ48WLFigY8eO6fLly3ld5m2V1fc3gNsrX14XAOD2S0xMVIcOHVSyZEmtXr1axYoVs2979tlntW/fPi1fvjwPK3SUP3/+TG3Hjx9XpUqVHNquzbLmltTUVHl6et6wjzFG8+fPV6dOnZSYmKh58+bdtYH3Zs7nTuvatau2bdumRYsWqW3btg7bxowZoyFDhuRRZbffta9HVt/fAG4vljQA/wJvvPGGLly4oA8//NAh7F5TpkwZPffcc9fd//Tp0xowYIAqV64sLy8v+fj4qFmzZtq+fXumvpMnT9Z9990nDw8PFSxYUDVr1tT8+fPt28+fP6/nn39eISEhcnV1VdGiRdWkSRNt3brV3uevaxzXrFkjm82mxMRELV++XDabTTabTQcPHrzuGt7du3fr8ccfV6FCheTm5qaaNWvqs88+c+gze/Zs2Ww2rV27Vr1791bRokUVFBT0j6/lunXrdPDgQXXo0EEdOnTQt99+qyNHjmTql5GRoUmTJqly5cpyc3OTn5+fmjZtqh9//NGh38cff6zatWvbX68GDRro66+/tm+32WwaOXJkpvH/vs76Rudz6NAh9e7dW+XLl5e7u7sKFy6sdu3a6eDBg5nGPXv2rPr372//+gQFBSk6OlonT57UhQsX5OnpmeX3ypEjR+Ts7Kxx48Zd97XbuHGjli9frm7dumUKu5Lk6uqqt956y6Ft9erVevDBB+Xp6akCBQqoVatW2rVrl0OfkSNHymaz6ddff9V//vMf+fr6ys/PT8OGDZMxRocPH1arVq3k4+OjgIAAjR8/3mH/a99jcXFxevnllxUQECBPT089+uijOnz4sEPf7777Tu3atVOJEiXk6uqq4OBg9e/fP9OSoK5du8rLy0v79+9X8+bN5e3trc6dO9u3/X0N74IFC1SjRg15e3vLx8dHlStX1qRJkxz6HDhwQO3atVOhQoXk4eGhBx54INMvqtfO5dNPP9XYsWMVFBQkNzc3NW7cWPv27bvOVwawPmZ4gX+Bzz//XKGhoapbt26O9j9w4ICWLVumdu3aqVSpUkpOTtb06dPVsGFD7dy5U4GBgZKkGTNmqF+/fnr88cf13HPP6dKlS9qxY4c2btyoTp06SZKeeeYZLVq0SH369FGlSpV06tQpff/999q1a5eqV6+e6dgVK1bU3Llz1b9/fwUFBemFF16QJPn5+enEiROZ+v/yyy+qV6+eihcvrkGDBsnT01OffvqpWrdurcWLF6tNmzYO/Xv37i0/Pz8NHz5cqamp//hazJs3T6VLl1atWrV0//33y8PDQ5988olefPFFh37dunXT7Nmz1axZM3Xv3l1Xr17Vd999px9++EE1a9aUJI0aNUojR45U3bp1NXr0aLm4uGjjxo1avXq1HnnkkZv4ymSW1fls3rxZ69evV4cOHRQUFKSDBw/qvffeU6NGjbRz5055eHhI+vPCwAcffFC7du3SU089perVq+vkyZP67LPPdOTIEVWtWlVt2rRRXFycJkyY4LCM5JNPPpExxh7qsnLtl46bXX+9atUqNWvWTKGhoRo5cqQuXryoyZMnq169etq6dWum0Ni+fXtVrFhRr732mpYvX65XXnlFhQoV0vTp0/Xwww/r9ddf17x58zRgwADVqlVLDRo0cNh/7NixstlsGjhwoI4fP66JEycqIiJCCQkJcnd3lyQtXLhQf/zxh3r16qXChQtr06ZNmjx5so4cOaKFCxc6jHf16lVFRkaqfv36euutt+yv89+tXLlSHTt2VOPGjfX6669L+nOd+Lp16+y/XCQnJ6tu3br6448/1K9fPxUuXFhz5szRo48+qkWLFmX6vn7ttdfk5OSkAQMG6Ny5c3rjjTfUuXNnbdy48aZee8ByDABLO3funJFkWrVqddP7lCxZ0nTp0sX+/NKlSyY9Pd2hT2JionF1dTWjR4+2t7Vq1crcd999Nxzb19fXPPvsszfs06VLF1OyZMlMNbVo0SJTDZLMrFmz7G2NGzc2lStXNpcuXbK3ZWRkmLp165qyZcva22bNmmUkmfr165urV6/esJ5rLl++bAoXLmyGDBlib+vUqZMJCwtz6Ld69WojyfTr1y/TGBkZGcYYY/bu3WucnJxMmzZtMr221/oYY4wkM2LEiEzj/P1rdKPz+eOPPzLtv2HDBiPJfPTRR/a24cOHG0lmyZIl1637q6++MpLMl19+6bC9SpUqpmHDhpn2+6s2bdoYSebMmTM37HdN1apVTdGiRc2pU6fsbdu3bzdOTk4mOjra3jZixAgjyfTs2dPedvXqVRMUFGRsNpt57bXX7O1nzpwx7u7uDq/dN998YySZ4sWLm5SUFHv7p59+aiSZSZMm2duyei3HjRtnbDabOXTokL2tS5cuRpIZNGhQpv5///5+7rnnjI+Pzw2/D59//nkjyXz33Xf2tvPnz5tSpUqZkJAQ+/fQtXOpWLGiSUtLs/edNGmSkWR++umn6x4DsDKWNAAWl5KSIkny9vbO8Riurq5ycvrz7SI9PV2nTp2Sl5eXypcv77AUoUCBAjpy5Ig2b9583bEKFCigjRs36vfff89xPddz+vRprV69Wk888YTOnz+vkydP6uTJkzp16pQiIyO1d+9e/fbbbw779OjR46YvePvyyy916tQpdezY0d7WsWNHbd++Xb/88ou9bfHixbLZbBoxYkSmMWw2myRp2bJlysjI0PDhw+2v7d/75ERW53NtdlL684KpU6dOqUyZMipQoIDD12/x4sUKCwvLNFv415oiIiIUGBioefPm2bf9/PPP2rFjh/7zn//csLbsfC8ePXpUCQkJ6tq1qwoVKmRvr1Klipo0aaIvvvgi0z5/XUvt7OysmjVryhijbt262dsLFCig8uXL68CBA5n2j46Odqjt8ccfV7FixRyO9dfXMjU1VSdPnlTdunVljNG2bdsyjdmrV69/PNcCBQooNTVVK1euvG6fL774QrVr11b9+vXtbV5eXurZs6cOHjyonTt3OvSPiYmRi4uL/fmDDz4oSVmeN/BvQOAFLM7Hx0fSn2tncyojI0Nvv/22ypYtK1dXVxUpUkR+fn7asWOHzp07Z+83cOBAeXl5qXbt2ipbtqyeffZZrVu3zmGsN954Qz///LOCg4NVu3ZtjRw5Mtd+CO/bt0/GGA0bNkx+fn4Oj2vh8/jx4w77lCpV6qbH//jjj1WqVCm5urpq37592rdvn0qXLi0PDw+HALh//34FBgY6BLW/279/v5ycnDJdiHersjqfixcvavjw4QoODnb4+p09e9bh67d//37df//9NxzfyclJnTt31rJly/THH39I+nOZh5ubm9q1a3fDfbPzvXjo0CFJUvny5TNtq1ixok6ePJlpCUqJEiUcnl+75VmRIkUytZ85cybTuGXLlnV4brPZVKZMGYe1zklJSfYQ7uXlJT8/PzVs2FCSHF5LScqXL99NrQvv3bu3ypUrp2bNmikoKEhPPfWUVqxY4dDn0KFD130trm3/q7+/FgULFpSkLM8b+Dcg8AIW5+Pjo8DAQP388885HuPVV19VbGysGjRooI8//lhfffWVVq5cqfvuu08ZGRn2fhUrVrTfXqp+/fpavHix6tev7zDT+cQTT+jAgQOaPHmyAgMD9eabb+q+++7Tl19+eUvnKcley4ABA7Ry5cosH2XKlHHY568zdjeSkpKizz//XImJiSpbtqz9UalSJf3xxx+aP3++zB28y2N6enqW7VmdT9++fTV27Fg98cQT+vTTT/X1119r5cqVKly4sMPX72ZFR0frwoULWrZsmf2uFS1btpSvr+8N96tQoYIk6aeffsr2MW9GVjP115u9z8nXKj09XU2aNNHy5cs1cOBALVu2TCtXrrRfNPn31/Kvfxm5kaJFiyohIUGfffaZHn30UX3zzTdq1qyZunTpku0ar8nN8wasgIvWgH+Bli1b6v3339eGDRtUp06dbO+/aNEiPfTQQ/rwww8d2s+ePZtp9szT01Pt27dX+/btdfnyZT322GMaO3asBg8ebL+FWLFixdS7d2/17t1bx48fV/Xq1TV27Fg1a9Ys5ycpKTQ0VNKftzWLiIi4pbH+bsmSJbp06ZLee++9TOe8Z88eDR06VOvWrVP9+vVVunRpffXVVzp9+vR1Z3lLly6tjIwM7dy5U1WrVr3ucQsWLJjpwy0uX76so0eP3nTtixYtUpcuXRzuTnDp0qVM45YuXfqmfjG6//77Va1aNc2bN09BQUFKSkrS5MmT/3G/qKgojRs3Th9//LH9T+zXU7JkSUl/vrZ/t3v3bhUpUiTXb7m2d+9eh+fGGO3bt09VqlSR9GdQ//XXXzVnzhxFR0fb+91oKcLNcnFxUVRUlKKiopSRkaHevXtr+vTpGjZsmMqUKaOSJUte97WQ/v/1ApA1ZniBf4GXXnpJnp6e6t69u5KTkzNt379/f6ZbIP2Vs7NzppmhhQsXZloPe+rUKYfnLi4uqlSpkowxunLlitLT0zP92bdo0aIKDAxUWlpadk8rk6JFi6pRo0aaPn16loEwq7s63KyPP/5YoaGheuaZZ/T44487PAYMGCAvLy/7soa2bdvKGKNRo0ZlGufa69i6dWs5OTlp9OjRmWYG//paly5dWt9++63D9vfff/+6M7xZyerrN3ny5ExjtG3bVtu3b9fSpUuvW/c1Tz75pL7++mtNnDhRhQsXvqlfVurUqaOmTZvqgw8+0LJlyzJtv3z5sgYMGCDpz1+Kqlatqjlz5jgE859//llff/21mjdv/o/Hy66PPvrIYbnFokWLdPToUfu5XZs1/etrYYy54f+dm/H3/zdOTk72kH3t/0Xz5s21adMmbdiwwd4vNTVV77//vkJCQnJ9aQxgNczwAv8CpUuX1vz58+23bfrrJ62tX79eCxcudLin69+1bNlSo0ePVkxMjOrWrauffvpJ8+bNs8+oXvPII48oICBA9erVk7+/v3bt2qUpU6aoRYsW8vb21tmzZxUUFKTHH39cYWFh8vLy0qpVq7R58+ZM90bNqalTp6p+/fqqXLmyevToodDQUCUnJ2vDhg06cuRIlvcO/ie///67vvnmG/Xr1y/L7a6uroqMjNTChQv1zjvv6KGHHtKTTz6pd955R3v37lXTpk2VkZGh7777Tg899JD69OmjMmXKaMiQIRozZowefPBBPfbYY3J1ddXmzZsVGBhov59t9+7d9cwzz6ht27Zq0qSJtm/frq+++irTLPONtGzZUnPnzpWvr68qVaqkDRs2aNWqVSpcuLBDvxdffFGLFi1Su3bt9NRTT6lGjRo6ffq0PvvsM02bNk1hYWH2vp06ddJLL72kpUuXqlevXjf9YQofffSRHnnkET322GOKiopS48aN5enpqb1792rBggU6evSo/V68b775ppo1a6Y6deqoW7du9tuS+fr6Znlv4ltVqFAh1a9fXzExMUpOTtbEiRNVpkwZ9ejRQ9KfSzJKly6tAQMG6LfffpOPj48WL158y+tiu3fvrtOnT+vhhx9WUFCQDh06pMmTJ6tq1ar2NbqDBg3SJ598ombNmqlfv34qVKiQ5syZo8TERC1evPimlk4A/2p3/L4QAPLMr7/+anr06GFCQkKMi4uL8fb2NvXq1TOTJ092uI1XVrcle+GFF0yxYsWMu7u7qVevntmwYYNp2LChw62opk+fbho0aGAKFy5sXF1dTenSpc2LL75ozp07Z4wxJi0tzbz44osmLCzMeHt7G09PTxMWFmbeffddhzpv5bZkxhizf/9+Ex0dbQICAkz+/PlN8eLFTcuWLc2iRYvsfa7dxmvz5s3/+LqNHz/eSDLx8fHX7TN79mwjyfz3v/81xvx5W6w333zTVKhQwbi4uBg/Pz/TrFkzs2XLFof9Zs6caapVq2ZcXV1NwYIFTcOGDc3KlSvt29PT083AgQNNkSJFjIeHh4mMjDT79u277m3JsjqfM2fOmJiYGFOkSBHj5eVlIiMjze7duzONYYwxp06dMn369DHFixc3Li4uJigoyHTp0sWcPHky07jNmzc3ksz69ev/8TX8qz/++MO89dZbplatWsbLy8u4uLiYsmXLmr59+5p9+/Y59F21apWpV6+ecXd3Nz4+PiYqKsrs3LnToc+125KdOHHCob1Lly7G09Mz0/EbNmzocPu8a7fy+uSTT8zgwYNN0aJFjbu7u2nRooXDrcaMMWbnzp0mIiLCeHl5mSJFipgePXqY7du3Z/o+vN6xr2376/f3okWLzCOPPGKKFi1qXFxcTIkSJczTTz9tjh496rDf/v37zeOPP24KFChg3NzcTO3atc3//vc/hz7XzmXhwoUO7df7vwL8W9iMYQU7ACD72rRpo59++ume/wSvNWvW6KGHHtLChQv1+OOP53U5AG4D/gYCAMi2o0ePavny5Tf9qWkAkJdYwwsAuGmJiYlat26dPvjgA+XPn19PP/10XpcEAP+IGV4AwE1bu3atnnzySSUmJmrOnDkKCAjI65IA4B/laeD99ttvFRUVpcDAQNlstixvU/N3a9asUfXq1eXq6qoyZcrYb/j9V1OnTlVISIjc3NwUHh6uTZs25X7xAPAv1LVrVxljdOjQIcusd23UqJGMMZY5HwCZ5WngTU1NVVhYmKZOnXpT/RMTE9WiRQs99NBDSkhI0PPPP6/u3bvrq6++sveJi4tTbGysRowYoa1btyosLEyRkZGZPk4UAAAA/w53zV0abDabli5dqtatW1+3z8CBA7V8+XKHTwLq0KGDzp49a//c8fDwcNWqVUtTpkyR9OdHPQYHB6tv374aNGjQbT0HAAAA3H3uqYvWNmzYkOnjQiMjI/X8889L+vNTerZs2aLBgwfbtzs5OSkiIsLh02n+Li0tzeFTnjIyMnT69GkVLlxYNpstd08CAAAAt8wYo/PnzyswMPAfP3zlngq8x44dk7+/v0Obv7+/UlJSdPHiRZ05c0bp6elZ9rn2eeNZGTduXJYfAQoAAIC72+HDhxUUFHTDPvdU4L1dBg8erNjYWPvzc+fOqUSJEjp8+LB8fHzysDIAAABkJSUlRcHBwfL29v7HvvdU4A0ICFBycrJDW3Jysnx8fOTu7i5nZ2c5Oztn2edGt85xdXWVq6trpnYfHx8CLwAAwF3sZpaf3lP34a1Tp47i4+Md2lauXKk6depIklxcXFSjRg2HPhkZGYqPj7f3AQAAwL9LngbeCxcuKCEhQQkJCZL+vO1YQkKCkpKSJP251CA6Otre/5lnntGBAwf00ksvaffu3Xr33Xf16aefqn///vY+sbGxmjFjhubMmaNdu3apV69eSk1NVUxMzB09NwAAANwd8nRJw48//qiHHnrI/vzaOtouXbpo9uzZOnr0qD38SlKpUqW0fPly9e/fX5MmTVJQUJA++OADRUZG2vu0b99eJ06c0PDhw3Xs2DFVrVpVK1asyHQhGwAAAP4d7pr78N5NUlJS5Ovrq3PnzrGGFwAA4C6Unbx2T63hBQAAALKLwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACyNwAsAAABLI/ACAADA0gi8AAAAsDQCLwAAACwtzwPv1KlTFRISIjc3N4WHh2vTpk3X7XvlyhWNHj1apUuXlpubm8LCwrRixQqHPiNHjpTNZnN4VKhQ4XafBgAAAO5SeRp44+LiFBsbqxEjRmjr1q0KCwtTZGSkjh8/nmX/oUOHavr06Zo8ebJ27typZ555Rm3atNG2bdsc+t133306evSo/fH999/fidMBAADAXShPA++ECRPUo0cPxcTEqFKlSpo2bZo8PDw0c+bMLPvPnTtXL7/8spo3b67Q0FD16tVLzZs31/jx4x365cuXTwEBAfZHkSJF7sTpAAAA4C6UZ4H38uXL2rJliyIiIv6/GCcnRUREaMOGDVnuk5aWJjc3N4c2d3f3TDO4e/fuVWBgoEJDQ9W5c2clJSXl/gkAAADgnpBngffkyZNKT0+Xv7+/Q7u/v7+OHTuW5T6RkZGaMGGC9u7dq4yMDK1cuVJLlizR0aNH7X3Cw8M1e/ZsrVixQu+9954SExP14IMP6vz589etJS0tTSkpKQ4PAAAAWEOeX7SWHZMmTVLZsmVVoUIFubi4qE+fPoqJiZGT0/+fRrNmzdSuXTtVqVJFkZGR+uKLL3T27Fl9+umn1x133Lhx8vX1tT+Cg4PvxOkAAADgDsizwFukSBE5OzsrOTnZoT05OVkBAQFZ7uPn56dly5YpNTVVhw4d0u7du+Xl5aXQ0NDrHqdAgQIqV66c9u3bd90+gwcP1rlz5+yPw4cP5+ykAAAAcNfJs8Dr4uKiGjVqKD4+3t6WkZGh+Ph41alT54b7urm5qXjx4rp69aoWL16sVq1aXbfvhQsXtH//fhUrVuy6fVxdXeXj4+PwAAAAgDXk6ZKG2NhYzZgxQ3PmzNGuXbvUq1cvpaamKiYmRpIUHR2twYMH2/tv3LhRS5Ys0YEDB/Tdd9+padOmysjI0EsvvWTvM2DAAK1du1YHDx7U+vXr1aZNGzk7O6tjx453/PwAAACQ9/Ll5cHbt2+vEydOaPjw4Tp27JiqVq2qFStW2C9kS0pKclife+nSJQ0dOlQHDhyQl5eXmjdvrrlz56pAgQL2PkeOHFHHjh116tQp+fn5qX79+vrhhx/k5+d3p08PAAAAdwGbMcbkdRF3m5SUFPn6+urcuXMsbwAAALgLZSev3VN3aQAAAACyi8ALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNLy5XUBAADrOzdqVF6XAOAO8B0xIq9LyBIzvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsLc8D79SpUxUSEiI3NzeFh4dr06ZN1+175coVjR49WqVLl5abm5vCwsK0YsWKWxoTAAAA1pangTcuLk6xsbEaMWKEtm7dqrCwMEVGRur48eNZ9h86dKimT5+uyZMna+fOnXrmmWfUpk0bbdu2LcdjAgAAwNpsxhiTVwcPDw9XrVq1NGXKFElSRkaGgoOD1bdvXw0aNChT/8DAQA0ZMkTPPvusva1t27Zyd3fXxx9/nKMxs5KSkiJfX1+dO3dOPj4+t3qaAPCvd27UqLwuAcAd4DtixB07VnbyWp7N8F6+fFlbtmxRRETE/xfj5KSIiAht2LAhy33S0tLk5ubm0Obu7q7vv/8+x2MCAADA2vIs8J48eVLp6eny9/d3aPf399exY8ey3CcyMlITJkzQ3r17lZGRoZUrV2rJkiU6evRojseU/gzSKSkpDg8AAABYQ55ftJYdkyZNUtmyZVWhQgW5uLioT58+iomJkZPTrZ3GuHHj5Ovra38EBwfnUsUAAADIa3kWeIsUKSJnZ2clJyc7tCcnJysgICDLffz8/LRs2TKlpqbq0KFD2r17t7y8vBQaGprjMSVp8ODBOnfunP1x+PDhWzw7AAAA3C3yLPC6uLioRo0aio+Pt7dlZGQoPj5ederUueG+bm5uKl68uK5evarFixerVatWtzSmq6urfHx8HB4AAACwhnx5efDY2Fh16dJFNWvWVO3atTVx4kSlpqYqJiZGkhQdHa3ixYtr3LhxkqSNGzfqt99+U9WqVfXbb79p5MiRysjI0EsvvXTTYwIAAODfJU8Db/v27XXixAkNHz5cx44dU9WqVbVixQr7RWdJSUkO63MvXbqkoUOH6sCBA/Ly8lLz5s01d+5cFShQ4KbHBAAAwL9Lnt6H927FfXgBIHdxH17g34H78AIAAAB5gMALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALC0bAfekJAQjR49WklJSbejHgAAACBXZTvwPv/881qyZIlCQ0PVpEkTLViwQGlpabejNgAAAOCW5SjwJiQkaNOmTapYsaL69u2rYsWKqU+fPtq6devtqBEAAADIsRyv4a1evbreeecd/f777xoxYoQ++OAD1apVS1WrVtXMmTNljMnNOgEAAIAcyZfTHa9cuaKlS5dq1qxZWrlypR544AF169ZNR44c0csvv6xVq1Zp/vz5uVkrAAAAkG3ZDrxbt27VrFmz9Mknn8jJyUnR0dF6++23VaFCBXufNm3aqFatWrlaKAAAAJAT2Q68tWrVUpMmTfTee++pdevWyp8/f6Y+pUqVUocOHXKlQAAAAOBWZDvwHjhwQCVLlrxhH09PT82aNSvHRQEAAAC5JdsXrR0/flwbN27M1L5x40b9+OOPuVIUAAAAkFuyHXifffZZHT58OFP7b7/9pmeffTZXigIAAAByS7YD786dO1W9evVM7dWqVdPOnTtzpSgAAAAgt2Q78Lq6uio5OTlT+9GjR5UvX47vcgYAAADcFtkOvI888ogGDx6sc+fO2dvOnj2rl19+WU2aNMnV4gAAAIBble0p2bfeeksNGjRQyZIlVa1aNUlSQkKC/P39NXfu3FwvEAAAALgV2Q68xYsX144dOzRv3jxt375d7u7uiomJUceOHbO8Jy8AAACQl3K06NbT01M9e/bM7VoAAACAXJfjq8x27typpKQkXb582aH90UcfveWiAAAAgNySo09aa9OmjX766SfZbDYZYyRJNptNkpSenp67FQIAAAC3INt3aXjuuedUqlQpHT9+XB4eHvrll1/07bffqmbNmlqzZs1tKBEAAADIuWzP8G7YsEGrV69WkSJF5OTkJCcnJ9WvX1/jxo1Tv379tG3btttRJwAAAJAj2Z7hTU9Pl7e3tySpSJEi+v333yVJJUuW1J49e3K3OgAAAOAWZXuG9/7779f27dtVqlQphYeH64033pCLi4vef/99hYaG3o4aAQAAgBzLduAdOnSoUlNTJUmjR49Wy5Yt9eCDD6pw4cKKi4vL9QIBAACAW5HtwBsZGWn/d5kyZbR7926dPn1aBQsWtN+pAQAAALhbZGsN75UrV5QvXz79/PPPDu2FChUi7AIAAOCulK3Amz9/fpUoUYJ77QIAAOCeke27NAwZMkQvv/yyTp8+fTvqAQAAAHJVttfwTpkyRfv27VNgYKBKliwpT09Ph+1bt27NteIAAACAW5XtwNu6devbUAYAAABwe2Q78I4YMeJ21AEAAADcFtlewwsAAADcS7I9w+vk5HTDW5BxBwcAAADcTbIdeJcuXerw/MqVK9q2bZvmzJmjUaNG5VphAAAAQG7IduBt1apVprbHH39c9913n+Li4tStW7dcKQwAAADIDbm2hveBBx5QfHx8bg0HAAAA5IpcCbwXL17UO++8o+LFi+fGcAAAAECuyfaShoIFCzpctGaM0fnz5+Xh4aGPP/44V4sDAAAAblW2A+/bb7/tEHidnJzk5+en8PBwFSxYMFeLAwAAAG5VtgNv165db0MZAAAAwO2R7TW8s2bN0sKFCzO1L1y4UHPmzMmVogAAAIDcku3AO27cOBUpUiRTe9GiRfXqq6/mSlEAAABAbsl24E1KSlKpUqUytZcsWVJJSUm5UhQAAACQW7IdeIsWLaodO3Zkat++fbsKFy6cK0UBAAAAuSXbgbdjx47q16+fvvnmG6Wnpys9PV2rV6/Wc889pw4dOtyOGgEAAIAcy/ZdGsaMGaODBw+qcePGypfvz90zMjIUHR3NGl4AAADcdbIdeF1cXBQXF6dXXnlFCQkJcnd3V+XKlVWyZMnbUR8AAABwS7IdeK8pW7asypYtm5u1AAAAALku22t427Ztq9dffz1T+xtvvKF27drlSlEAAABAbsl24P3222/VvHnzTO3NmjXTt99+mytFAQAAALkl24H3woULcnFxydSeP39+paSk5EpRAAAAQG7JduCtXLmy4uLiMrUvWLBAlSpVynYBU6dOVUhIiNzc3BQeHq5NmzbdsP/EiRNVvnx5ubu7Kzg4WP3799elS5fs20eOHCmbzebwqFChQrbrAgAAgDVk+6K1YcOG6bHHHtP+/fv18MMPS5Li4+M1f/58LVq0KFtjxcXFKTY2VtOmTVN4eLgmTpyoyMhI7dmzR0WLFs3Uf/78+Ro0aJBmzpypunXr6tdff1XXrl1ls9k0YcIEe7/77rtPq1at+v+TzJfja/MAAABwj8t2EoyKitKyZcv06quvatGiRXJ3d1dYWJhWr16tQoUKZWusCRMmqEePHoqJiZEkTZs2TcuXL9fMmTM1aNCgTP3Xr1+vevXqqVOnTpKkkJAQdezYURs3bnQ8qXz5FBAQkN1TAwAAgAVle0mDJLVo0ULr1q1TamqqDhw4oCeeeEIDBgxQWFjYTY9x+fJlbdmyRREREf9fjJOTIiIitGHDhiz3qVu3rrZs2WJf9nDgwAF98cUXmS6i27t3rwIDAxUaGqrOnTsrKSnphrWkpaUpJSXF4QEAAABryFHglf68W0OXLl0UGBio8ePH6+GHH9YPP/xw0/ufPHlS6enp8vf3d2j39/fXsWPHstynU6dOGj16tOrXr6/8+fOrdOnSatSokV5++WV7n/DwcM2ePVsrVqzQe++9p8TERD344IM6f/78dWsZN26cfH197Y/g4OCbPg8AAADc3bIVeI8dO6bXXntNZcuWVbt27eTj46O0tDQtW7ZMr732mmrVqnW76pQkrVmzRq+++qreffddbd26VUuWLNHy5cs1ZswYe59mzZqpXbt2qlKliiIjI/XFF1/o7Nmz+vTTT6877uDBg3Xu3Dn74/Dhw7f1PAAAAHDn3PQa3qioKH377bdq0aKFJk6cqKZNm8rZ2VnTpk3L0YGLFCkiZ2dnJScnO7QnJydfd/3tsGHD9OSTT6p79+6S/rxjRGpqqnr27KkhQ4bIySlzfi9QoIDKlSunffv2XbcWV1dXubq65ug8AAAAcHe76RneL7/8Ut26ddOoUaPUokULOTs739KBXVxcVKNGDcXHx9vbMjIyFB8frzp16mS5zx9//JEp1F6rwxiT5T4XLlzQ/v37VaxYsVuqFwAAAPemmw6833//vc6fP68aNWooPDxcU6ZM0cmTJ2/p4LGxsZoxY4bmzJmjXbt2qVevXkpNTbXftSE6OlqDBw+294+KitJ7772nBQsWKDExUStXrtSwYcMUFRVlD74DBgzQ2rVrdfDgQa1fv15t2rSRs7OzOnbseEu1AgAA4N5000saHnjgAT3wwAOaOHGi4uLiNHPmTMXGxiojI0MrV65UcHCwvL29s3Xw9u3b68SJExo+fLiOHTumqlWrasWKFfYL2ZKSkhxmdIcOHSqbzaahQ4fqt99+k5+fn6KiojR27Fh7nyNHjqhjx446deqU/Pz8VL9+ff3www/y8/PLVm0AAACwBpu53lqAm7Bnzx59+OGHmjt3rs6ePasmTZros88+y8368kRKSop8fX117tw5+fj45HU5AHDPOzdqVF6XAOAO8B0x4o4dKzt5Lce3JZOk8uXL64033tCRI0f0ySef3MpQAAAAwG1xS4H3GmdnZ7Vu3doSs7sAAACwllwJvAAAAMDdisALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALC0fHldAP702raTeV0CgDtgULUieV0CAPzrMMMLAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNIIvAAAALA0Ai8AAAAsjcALAAAASyPwAgAAwNLyPPBOnTpVISEhcnNzU3h4uDZt2nTD/hMnTlT58uXl7u6u4OBg9e/fX5cuXbqlMQEAAGBdeRp44+LiFBsbqxEjRmjr1q0KCwtTZGSkjh8/nmX/+fPna9CgQRoxYoR27dqlDz/8UHFxcXr55ZdzPCYAAACsLU8D74QJE9SjRw/FxMSoUqVKmjZtmjw8PDRz5sws+69fv1716tVTp06dFBISokceeUQdO3Z0mMHN7pgAAACwtjwLvJcvX9aWLVsUERHx/8U4OSkiIkIbNmzIcp+6detqy5Yt9oB74MABffHFF2revHmOxwQAAIC15curA588eVLp6eny9/d3aPf399fu3buz3KdTp046efKk6tevL2OMrl69qmeeeca+pCEnY0pSWlqa0tLS7M9TUlJyeloAAAC4y+T5RWvZsWbNGr366qt69913tXXrVi1ZskTLly/XmDFjbmnccePGydfX1/4IDg7OpYoBAACQ1/JshrdIkSJydnZWcnKyQ3tycrICAgKy3GfYsGF68skn1b17d0lS5cqVlZqaqp49e2rIkCE5GlOSBg8erNjYWPvzlJQUQi8AAIBF5NkMr4uLi2rUqKH4+Hh7W0ZGhuLj41WnTp0s9/njjz/k5ORYsrOzsyTJGJOjMSXJ1dVVPj4+Dg8AAABYQ57N8EpSbGysunTpopo1a6p27dqaOHGiUlNTFRMTI0mKjo5W8eLFNW7cOElSVFSUJkyYoGrVqik8PFz79u3TsGHDFBUVZQ++/zQmAAAA/l3yNPC2b99eJ06c0PDhw3Xs2DFVrVpVK1assF90lpSU5DCjO3ToUNlsNg0dOlS//fab/Pz8FBUVpbFjx970mAAAAPh3sRljTF4XcbdJSUmRr6+vzp07d8eWN7y27eQdOQ6AvDWoWpG8LiFPnBs1Kq9LAHAH+I4YcceOlZ28dk/dpQEAAADILgIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALI3ACwAAAEsj8AIAAMDSCLwAAACwNAIvAAAALO2uCLxTp05VSEiI3NzcFB4erk2bNl23b6NGjWSz2TI9WrRoYe/TtWvXTNubNm16J04FAAAAd5l8eV1AXFycYmNjNW3aNIWHh2vixImKjIzUnj17VLRo0Uz9lyxZosuXL9ufnzp1SmFhYWrXrp1Dv6ZNm2rWrFn2566urrfvJAAAAHDXyvMZ3gkTJqhHjx6KiYlRpUqVNG3aNHl4eGjmzJlZ9i9UqJACAgLsj5UrV8rDwyNT4HV1dXXoV7BgwTtxOgAAALjL5GngvXz5srZs2aKIiAh7m5OTkyIiIrRhw4abGuPDDz9Uhw4d5Onp6dC+Zs0aFS1aVOXLl1evXr106tSp646RlpamlJQUhwcAAACsIU8D78mTJ5Weni5/f3+Hdn9/fx07duwf99+0aZN+/vlnde/e3aG9adOm+uijjxQfH6/XX39da9euVbNmzZSenp7lOOPGjZOvr6/9ERwcnPOTAgAAwF0lz9fw3ooPP/xQlStXVu3atR3aO3ToYP935cqVVaVKFZUuXVpr1qxR48aNM40zePBgxcbG2p+npKQQegEAACwiT2d4ixQpImdnZyUnJzu0JycnKyAg4Ib7pqamasGCBerWrds/Hic0NFRFihTRvn37stzu6uoqHx8fhwcAAACsIU8Dr4uLi2rUqKH4+Hh7W0ZGhuLj41WnTp0b7rtw4UKlpaXpP//5zz8e58iRIzp16pSKFSt2yzUDAADg3pLnd2mIjY3VjBkzNGfOHO3atUu9evVSamqqYmJiJEnR0dEaPHhwpv0+/PBDtW7dWoULF3Zov3Dhgl588UX98MMPOnjwoOLj49WqVSuVKVNGkZGRd+ScAAAAcPfI8zW87du314kTJzR8+HAdO3ZMVatW1YoVK+wXsiUlJcnJyTGX79mzR99//72+/vrrTOM5Oztrx44dmjNnjs6ePavAwEA98sgjGjNmDPfiBQAA+BfK88ArSX369FGfPn2y3LZmzZpMbeXLl5cxJsv+7u7u+uqrr3KzPAAAANzD8nxJAwAAAHA7EXgBAABgaQReAAAAWBqBFwAAAJZG4AUAAIClEXgBAABgaQReAAAAWBqBFwAAAJZG4AUAAIClEXgBAABgaQReAAAAWBqBFwAAAJZG4AUAAIClEXgBAABgafnyuoC7kTFGkpSSknLHjnnpwvk7diwAeSclxSWvS8gTKZcu5XUJAO4A2x3MTtdy2rXcdiM2czO9/mWOHDmi4ODgvC4DAAAA/+Dw4cMKCgq6YR8CbxYyMjL0+++/y9vbWzabLa/LgQWlpKQoODhYhw8flo+PT16XAwC5jvc53G7GGJ0/f16BgYFycrrxKl2WNGTBycnpH39TAHKDj48PPwgAWBrvc7idfH19b6ofF60BAADA0gi8AAAAsDQCL5AHXF1dNWLECLm6uuZ1KQBwW/A+h7sJF60BAADA0pjhBQAAgKUReAEAAGBpBF4AAABYGoEXdxWbzaZly5bl6pgjR45U1apVc3XM2ykkJEQTJ07M9b4AcE2jRo30/PPP53UZkqSDBw/KZrMpISHhth9r9uzZKlCggEPb+++/r+DgYDk5OWnixIn33M8M3BwCL+6YEydOqFevXipRooRcXV0VEBCgyMhIrVu3zt7n6NGjatasWR5WmbWuXbvKZrPJZrMpf/788vf3V5MmTTRz5kxlZGTk6rE2b96snj175nrfnPjreWf1CAkJuW3HBqzk7/+XChcurKZNm2rHjh15Us+SJUs0ZsyYO3Ksffv2KSYmRkFBQXJ1dVWpUqXUsWNH/fjjj3fk+H/Vvn17/frrr/bnKSkp6tOnjwYOHKjffvtNPXv21IABAxQfH3/Ha8PtReDFHdO2bVtt27ZNc+bM0a+//qrPPvtMjRo10qlTp+x9AgIC7tpb2DRt2lRHjx7VwYMH9eWXX+qhhx7Sc889p5YtW+rq1au5dhw/Pz95eHjket+cmDRpko4ePWp/SNKsWbPszzdv3uzQ//Lly7etFuBed+095OjRo4qPj1e+fPnUsmXLPKmlUKFC8vb2vu3H+fHHH1WjRg39+uuvmj59unbu3KmlS5eqQoUKeuGFF2778f/O3d1dRYsWtT9PSkrSlStX1KJFCxUrVkweHh7y8vJS4cKFb+k4V65cudVSkdsMcAecOXPGSDJr1qy5YT9JZunSpcYYYxITE40ks3jxYtOoUSPj7u5uqlSpYtavX++wz/vvv2+CgoKMu7u7ad26tRk/frzx9fW1bx8xYoQJCwtz2GfGjBmmQoUKxtXV1ZQvX95MnTr1hnV16dLFtGrVKlN7fHy8kWRmzJjhcK7dunUzRYoUMd7e3uahhx4yCQkJDvt99tlnpmbNmsbV1dUULlzYtG7d2r6tZMmS5u233zbGGJORkWFGjBhhgoODjYuLiylWrJjp27dvln2NMebQoUPm0UcfNZ6ensbb29u0a9fOHDt2LNNr8dFHH5mSJUsaHx8f0759e5OSknLD87/mr1+fa8cfPXq0efLJJ423t7fp0qWLMcaY7777ztSvX9+4ubmZoKAg07dvX3PhwgX7fpcuXTIvvPCCCQwMNB4eHqZ27drmm2++uakagHtRVu8h3333nZFkjh8/bm976aWXTNmyZY27u7spVaqUGTp0qLl8+bLDfmPGjDF+fn7Gy8vLdOvWzQwcONDhPe7KlSumb9++xtfX1xQqVMi89NJLJjo62uH4DRs2NM8995z9ecmSJc3YsWNNTEyM8fLyMsHBwWb69OkOx123bp0JCwszrq6upkaNGmbp0qVGktm2bVuW55yRkWHuu+8+U6NGDZOenp5p+5kzZ4wx//9ef22cq1evmqeeesqEhIQYNzc3U65cOTNx4kSHfb/55htTq1Yt4+HhYXx9fU3dunXNwYMHjTHGJCQkmEaNGhkvLy/j7e1tqlevbjZv3myMMWbWrFn2nw+zZs0ykhweiYmJ2f6Zca3+BQsWmAYNGhhXV1cza9asLF8T5B1meHFHeHl5ycvLS8uWLVNaWlq29h0yZIgGDBighIQElStXTh07drTPqK5bt07PPPOMnnvuOSUkJKhJkyYaO3bsDcebN2+ehg8frrFjx2rXrl169dVXNWzYMM2ZMyfb5/Xwww8rLCxMS5Yssbe1a9dOx48f15dffqktW7aoevXqaty4sU6fPi1JWr58udq0aaPmzZtr27Ztio+PV+3atbMcf/HixXr77bc1ffp07d27V8uWLVPlypWz7JuRkaFWrVrp9OnTWrt2rVauXKkDBw6offv2Dv3279+vZcuW6X//+5/+97//ae3atXrttdeyfe7XvPXWWwoLC9O2bds0bNgw7d+/X02bNlXbtm21Y8cOxcXF6fvvv1efPn3s+/Tp00cbNmzQggULtGPHDrVr105NmzbV3r17c1wHcC+5cOGCPv74Y5UpU8ZhNtHb21uzZ8/Wzp07NWnSJM2YMUNvv/22ffu8efM0duxYvf7669qyZYtKlCih9957z2Hs119/XfPmzdOsWbO0bt06paSk3NS1EePHj1fNmjW1bds29e7dW7169dKePXsk/fmn/6ioKFWuXFlbt27VmDFjNHDgwBuOl5CQoF9++UUvvPCCnJwyx42/r6W9JiMjQ0FBQVq4cKF27typ4cOH6+WXX9ann34qSbp69apat26thg0baseOHdqwYYN69uwpm80mSercubOCgoK0efNmbdmyRYMGDVL+/PkzHad9+/ZatWqVJGnTpk06evSogoODM/W72Z8ZgwYN0nPPPaddu3YpMjLyhq8N8kBeJ278eyxatMgULFjQuLm5mbp165rBgweb7du3O/RRFjO8H3zwgX37L7/8YiSZXbt2GWOMad++vWnRooXDGJ07d77hDG/p0qXN/PnzHfYZM2aMqVOnznVrv94M77UaKlasaIz5c8bGx8fHXLp0yaFP6dKl7bMlderUMZ07d77usf46azt+/HhTrly5TDM8WfX9+uuvjbOzs0lKSrJvv/Z6bdq0yRjz52vh4eHhMKP74osvmvDw8OvW81fKYob3r7PTxhjTrVs307NnT4e27777zjg5OZmLFy+aQ4cOGWdnZ/Pbb7859GncuLEZPHjwTdUB3Gu6dOlinJ2djaenp/H09DSSTLFixcyWLVtuuN+bb75patSoYX8eHh5unn32WYc+9erVc3iP8/f3N2+++ab9+dWrV02JEiX+cYb3P//5j/15RkaGKVq0qHnvvfeMMca89957pnDhwubixYv2PjNmzLjhDG9cXJyRZLZu3XrDc/z7DG9Wnn32WdO2bVtjjDGnTp264V8Mvb29zezZs7Pc9tcZXmOM2bZtm31m95rs/sy4Vv/fZ6Fxd2GGF3dM27Zt9fvvv+uzzz5T06ZNtWbNGlWvXl2zZ8++4X5VqlSx/7tYsWKSpOPHj0uS9uzZk2l29HqzpZKUmpqq/fv3q1u3bvZZZy8vL73yyivav39/js7LGGOfWdi+fbsuXLigwoULO4yfmJhoHz8hIUGNGze+qbHbtWunixcvKjQ0VD169NDSpUuvu154165dCg4OdpihqFSpkgoUKKBdu3bZ20JCQhzW7hUrVsz+euZEzZo1HZ5v375ds2fPdjj/yMhIZWRkKDExUT/99JPS09NVrlw5hz5r167N8dcAuBc89NBDSkhIUEJCgjZt2qTIyEg1a9ZMhw4dsveJi4tTvXr1FBAQIC8vLw0dOlRJSUn27f/0nnfu3DklJyc7tDk7O6tGjRr/WN9f32ttNpsCAgIc3murVKkiNze3LI+bFXMLH+Q6depU1ahRQ35+fvLy8tL7779vfx0KFSqkrl27KjIyUlFRUfZrDa6JjY1V9+7dFRERoddee+2W3ley8zPj7++FuLvky+sC8O/i5uamJk2aqEmTJho2bJi6d++uESNGqGvXrtfd569/iroWLHN6Z4QLFy5IkmbMmKHw8HCHbc7Ozjkac9euXSpVqpR9/GLFimnNmjWZ+l378527u/tNjx0cHKw9e/Zo1apVWrlypXr37q0333xTa9euzfJPdDfj7/vZbLZbutOEp6enw/MLFy7o6aefVr9+/TL1LVGihHbs2CFnZ2dt2bIl02vu5eWV4zqAu52np6fKlCljf/7BBx/I19dXM2bM0CuvvKINGzaoc+fOGjVqlCIjI+Xr66sFCxZo/Pjxd6S+3H5vKFeunCRp9+7dqlat2k3vt2DBAg0YMEDjx49XnTp15O3trTfffFMbN26095k1a5b69eunFStWKC4uTkOHDtXKlSv1wAMPaOTIkerUqZOWL1+uL7/8UiNGjNCCBQvUpk2bbJ9Ddn5m/P29EHcXZniRpypVqqTU1NQc71++fPlMdwr4+/O/8vf3V2BgoA4cOKAyZco4PK6F1uxYvXq1fvrpJ7Vt21aSVL16dR07dkz58uXLNH6RIkUk/TmLkp1b3ri7uysqKkrvvPOO1qxZow0bNuinn37K1K9ixYo6fPiwDh8+bG/buXOnzp49q0qVKmX73HKqevXq2rlzZ6bzL1OmjFxcXFStWjWlp6fr+PHjmbYHBATcsTqBvGaz2eTk5KSLFy9KktavX6+SJUtqyJAhqlmzpsqWLesw+yv983uer6+v/P39HdrS09O1devWW6q1fPny+umnnxyuwbjRe60kVa1aVZUqVdL48eOzDM5nz57Ncr9169apbt266t27t6pVq6YyZcpkOUtbrVo1DR48WOvXr9f999+v+fPn27eVK1dO/fv319dff63HHntMs2bNuskzdZTbPzOQd5jhxR1x6tQptWvXTk899ZSqVKkib29v/fjjj3rjjTfUqlWrHI/bt29fNWjQQBMmTFBUVJRWr16tL7/80j4TnJVRo0apX79+8vX1VdOmTZWWlqYff/xRZ86cUWxs7HX3S0tL07Fjx5Senq7k5GStWLFC48aNU8uWLRUdHS1JioiIUJ06ddS6dWu98cYbKleunH7//Xf7hWo1a9bUiBEj1LhxY5UuXVodOnTQ1atX9cUXX2R5Acjs2bOVnp6u8PBweXh46OOPP5a7u7tKliyZqW9ERIQqV66szp07a+LEibp69ap69+6thg0b3tE/tQ0cOFAPPPCA+vTpo+7du8vT01M7d+7UypUrNWXKFJUrV06dO3dWdHS0xo8fr2rVqunEiROKj49XlSpV1KJFiztWK3AnXXsPkaQzZ85oypQpunDhgqKioiRJZcuWVVJSkhYsWKBatWpp+fLlWrp0qcMYffv2VY8ePVSzZk3VrVtXcXFx2rFjh0JDQx36jBs3TmXKlFGFChU0efJknTlz5obvi/+kU6dOGjJkiHr27KlBgwYpKSlJb731liRdd1ybzaZZs2YpIiJCDz74oIYMGaIKFSrowoUL+vzzz/X1119r7dq1mfYrW7asPvroI3311VcqVaqU5s6dq82bN9sDZmJiot5//309+uijCgwM1J49e7R3715FR0fr4sWLevHFF/X444+rVKlSOnLkiDZv3myflMiJnP7MwN2FGV7cEV5eXgoPD9fbb7+tBg0a6P7779ewYcPUo0cPTZkyJcfj1qtXT9OmTdOECRMUFhamFStWqH///g7rzP6ue/fu+uCDDzRr1ixVrlxZDRs21OzZs//xt/UVK1aoWLFiCgkJUdOmTfXNN9/onXfe0X//+1/7n7ZsNpu++OILNWjQQDExMSpXrpw6dOigQ4cOyd/fX9Kfn3C0cOFCffbZZ6pataoefvhhbdq0KctjFihQQDNmzFC9evVUpUoVrVq1Sp9//nmW94i02Wz673//q4IFC6pBgwaKiIhQaGio4uLibvblzBVVqlTR2rVr9euvv+rBBx9UtWrVNHz4cAUGBtr7zJo1S9HR0XrhhRdUvnx5tW7dWps3b1aJEiXuaK3AnXTtPaRYsWIKDw/X5s2btXDhQjVq1EiS9Oijj6p///7q06ePqlatqvXr12vYsGEOY3Tu3FmDBw/WgAEDVL16dSUmJqpr164O73kDBw5Ux44dFR0drTp16tjX0d/offGf+Pj46PPPP1dCQoKqVq2qIUOGaPjw4ZJ0w3Fr166tH3/8UWXKlFGPHj1UsWJFPfroo/rll1+u+ymRTz/9tB577DG1b99e4eHhOnXqlHr37m3f7uHhod27d6tt27YqV66cevbsqWeffVZPP/20nJ2dderUKUVHR6tcuXJ64okn1KxZM40aNSrH557Tnxm4u9jMrawqB+5CPXr00O7du/Xdd9/ldSkAcNs1adJEAQEBmjt3bpbbMzIyVLFiRT3xxBO5+ulq8+bNU0xMjM6dO5etaxOAvMCSBtzz3nrrLTVp0kSenp768ssvNWfOHL377rt5XRYA5Lo//vhD06ZNU2RkpJydnfXJJ5/YL2q95tChQ/r666/VsGFDpaWlacqUKUpMTFSnTp1u6dgfffSRQkNDVbx4cW3fvl0DBw7UE088QdjFPYHAi3vepk2b9MYbb+j8+fMKDQ3VO++8o+7du+d1WQCQ664tmxo7dqwuXbqk8uXLa/HixYqIiLD3cXJy0uzZszVgwAAZY3T//fdr1apVqlix4i0d+9ixYxo+fLiOHTumYsWKqV27dv/4QT/A3YIlDQAAALA0LloDAACApRF4AQAAYGkEXgAAAFgagRcAAACWRuAFAACApRF4AQAAYGkEXgAAAFgagRcAAACWRuAFAACApf0f8ECwbsOMdhIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "35. Train a Random Forest Classifier and visualize the confusion matrix."
      ],
      "metadata": {
        "id": "U7RdP68vLqGK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fc85768"
      },
      "source": [
        "# Task\n",
        "## Train Random Forest Classifier\n",
        "\n",
        "### Subtask:\n",
        "Initialize and train a `RandomForestClassifier` on the training data.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `RandomForestClassifier` from `sklearn.ensemble`.\n",
        "2. Initialize a `RandomForestClassifier` with `n_estimators=100`, `random_state=42`, and `n_jobs=-1`.\n",
        "3. Train the classifier on `X_train_bc_misc` and `y_train_bc_misc`.\n",
        "4. Print a confirmation message that the classifier has been trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dff30f5b"
      },
      "source": [
        "## Load Breast Cancer Dataset\n",
        "\n",
        "### Subtask:\n",
        "Load the Breast Cancer dataset from `sklearn.datasets`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e773f5b"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask asks to load the Breast Cancer dataset, store features and target in specified variables, and print their shapes. This code block directly addresses these instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ae417f7",
        "outputId": "02692e3f-a081-477d-b387-5c98af406b85"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data_bc = load_breast_cancer()\n",
        "X_bc_cm = data_bc.data\n",
        "y_bc_cm = data_bc.target\n",
        "\n",
        "print(f\"Breast Cancer Dataset shape: X_bc_cm={X_bc_cm.shape}, y_bc_cm={y_bc_cm.shape}\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast Cancer Dataset shape: X_bc_cm=(569, 30), y_bc_cm=(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b58def7"
      },
      "source": [
        "## Split Data into Training and Testing Sets\n",
        "\n",
        "### Subtask:\n",
        "Split the loaded Breast Cancer dataset (`X_bc_cm`, `y_bc_cm`) into training and testing sets.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `train_test_split` from `sklearn.model_selection`.\n",
        "2. Split the `X_bc_cm` and `y_bc_cm` into `X_train_bc_cm`, `X_test_bc_cm`, `y_train_bc_cm`, and `y_test_bc_cm` using a `test_size` of 0.3 and `random_state=42`.\n",
        "3. Print the shapes of the training and testing sets to verify the split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd575144"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for splitting the dataset. This code block will now perform the actual splitting of the Breast Cancer dataset into training and testing sets, as well as printing their shapes, as per the subtask requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e71c0c8",
        "outputId": "a5bd67aa-feee-423e-efd0-519172b214fd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_bc_cm, X_test_bc_cm, y_train_bc_cm, y_test_bc_cm = train_test_split(X_bc_cm, y_bc_cm, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_bc_cm={X_train_bc_cm.shape}, y_train_bc_cm={y_train_bc_cm.shape}\")\n",
        "print(f\"Testing data shape: X_test_bc_cm={X_test_bc_cm.shape}, y_test_bc_cm={y_test_bc_cm.shape}\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_bc_cm=(398, 30), y_train_bc_cm=(398,)\n",
            "Testing data shape: X_test_bc_cm=(171, 30), y_test_bc_cm=(171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50212d78"
      },
      "source": [
        "## Train Random Forest Classifier\n",
        "\n",
        "### Subtask:\n",
        "Initialize and train a `RandomForestClassifier` on the training data.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `RandomForestClassifier` from `sklearn.ensemble`.\n",
        "2. Initialize a `RandomForestClassifier` with `n_estimators=100`, `random_state=42`, and `n_jobs=-1`.\n",
        "3. Train the classifier on `X_train_bc_cm` and `y_train_bc_cm`.\n",
        "4. Print a confirmation message that the classifier has been trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02434a19"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for training a Random Forest Classifier. This code block will now implement those instructions by initializing and training the classifier on the prepared training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d22aca8c",
        "outputId": "a3b4c0bb-0155-4887-c064-a8fbc846588e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_clf_cm = RandomForestClassifier(\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1         # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf_cm.fit(X_train_bc_cm, y_train_bc_cm)\n",
        "print(\"Random Forest Classifier trained successfully.\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0008b152"
      },
      "source": [
        "## Visualize the Confusion Matrix\n",
        "\n",
        "### Subtask:\n",
        "Make predictions on the test set and visualize the confusion matrix to assess the classifier's performance.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `confusion_matrix` and `ConfusionMatrixDisplay` from `sklearn.metrics`.\n",
        "2. Import `matplotlib.pyplot` as `plt`.\n",
        "3. Make predictions on the test set (`X_test_bc_cm`) using the trained `rf_clf_cm`.\n",
        "4. Compute the confusion matrix using `confusion_matrix`, providing `y_test_bc_cm` and the predictions.\n",
        "5. Create a `ConfusionMatrixDisplay` object from the computed confusion matrix and `display_labels`.\n",
        "6. Plot the confusion matrix using `disp.plot()`.\n",
        "7. Add a title to the plot.\n",
        "8. Display the plot using `plt.show()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8271e018"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for visualizing the confusion matrix. This code block will now implement those instructions by making predictions, computing the confusion matrix, and then plotting it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "142048be",
        "outputId": "7c67508f-7cbc-43ba-d003-87a9b25f4200"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_cm = rf_clf_cm.predict(X_test_bc_cm)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test_bc_cm, y_pred_cm)\n",
        "\n",
        "# Get class names for display\n",
        "display_labels = data_bc.target_names\n",
        "\n",
        "# Create a ConfusionMatrixDisplay object\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix for Random Forest Classifier')\n",
        "plt.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "36.  Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy."
      ],
      "metadata": {
        "id": "mOyZBNWRMxhp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60f29571"
      },
      "source": [
        "# Task\n",
        "Generate a synthetic classification dataset with 1000 samples and 20 features, split it into training and testing sets, then train and evaluate a `StackingClassifier` using `DecisionTreeClassifier`, `SVC(probability=True)`, and `LogisticRegression` as base estimators, with `LogisticRegression` as the final meta-estimator. Summarize the accuracy achieved by the Stacking Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d0fa8b7"
      },
      "source": [
        "## Generate Classification Dataset\n",
        "\n",
        "### Subtask:\n",
        "Generate a synthetic classification dataset using `make_classification` with 1000 samples and 20 features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "038ecdb3"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires generating a synthetic classification dataset with specific parameters. This code block uses `make_classification` to create the dataset and then prints its shape as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a429e2b",
        "outputId": "33693d89-301a-45a4-ee29-0303eb196d76"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a synthetic dataset for classification\n",
        "X_stack, y_stack = make_classification(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_redundant=5,           # Number of redundant features\n",
        "    n_classes=2,             # Number of target classes\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Dataset shape for Stacking: X_stack={X_stack.shape}, y_stack={y_stack.shape}\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape for Stacking: X_stack=(1000, 20), y_stack=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbc8d89"
      },
      "source": [
        "## Split Data into Training and Testing Sets\n",
        "\n",
        "### Subtask:\n",
        "Split the generated classification dataset (`X_stack`, `y_stack`) into training and testing sets.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `train_test_split` from `sklearn.model_selection`.\n",
        "2. Split the `X_stack` and `y_stack` into `X_train_stack`, `X_test_stack`, `y_train_stack`, and `y_test_stack` using a `test_size` of 0.3 and `random_state=42`.\n",
        "3. Print the shapes of the training and testing sets to verify the split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfaf1a7d"
      },
      "source": [
        "**Reasoning**:\n",
        "This code block implements the instructions to split the dataset into training and testing sets, and then prints the shapes of the resulting sets for verification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3289ff82",
        "outputId": "a12d9690-c5fe-4d66-eb97-6f43b6b7c88d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_stack, X_test_stack, y_train_stack, y_test_stack = train_test_split(X_stack, y_stack, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape for Stacking: X_train_stack={X_train_stack.shape}, y_train_stack={y_train_stack.shape}\")\n",
        "print(f\"Testing data shape for Stacking: X_test_stack={X_test_stack.shape}, y_test_stack={y_test_stack.shape}\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape for Stacking: X_train_stack=(700, 20), y_train_stack=(700,)\n",
            "Testing data shape for Stacking: X_test_stack=(300, 20), y_test_stack=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd1479df"
      },
      "source": [
        "## Train Stacking Classifier\n",
        "\n",
        "### Subtask:\n",
        "Train a `StackingClassifier` using `DecisionTreeClassifier`, `SVC`, and `LogisticRegression` as base estimators, and `LogisticRegression` as the final meta-estimator.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `StackingClassifier` from `sklearn.ensemble`.\n",
        "2. Import `DecisionTreeClassifier` from `sklearn.tree`.\n",
        "3. Import `SVC` from `sklearn.svm`.\n",
        "4. Import `LogisticRegression` from `sklearn.linear_model`.\n",
        "5. Define a list of base estimators: `estimators = [('dt', DecisionTreeClassifier(random_state=42)), ('svm', SVC(probability=True, random_state=42)), ('lr', LogisticRegression(solver='liblinear', random_state=42))]`.\n",
        "6. Initialize the `StackingClassifier` with the defined `estimators`, `final_estimator=LogisticRegression(solver='liblinear', random_state=42)`, and `n_jobs=-1`.\n",
        "7. Train the `StackingClassifier` on the training data (`X_train_stack`, `y_train_stack`).\n",
        "8. Print a confirmation message that the Stacking Classifier has been trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a595a473"
      },
      "source": [
        "**Reasoning**:\n",
        "This code block directly implements the instructions to initialize and train a Stacking Classifier with the specified base estimators and meta-estimator on the prepared training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b13bb64"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because `StackingClassifier` does not accept a `random_state` parameter directly in its constructor. I need to remove `random_state=42` from the `StackingClassifier` initialization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72e5f7ba",
        "outputId": "298d4a20-dc49-4c2b-af3f-7c60fd43967f"
      },
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('svm', SVC(probability=True, random_state=42)), # probability=True is required for stacking with SVC\n",
        "    ('lr', LogisticRegression(solver='liblinear', random_state=42))\n",
        "]\n",
        "\n",
        "# Initialize the Stacking Classifier\n",
        "# final_estimator: The meta-model that learns how to best combine the predictions of the base estimators\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(solver='liblinear', random_state=42),\n",
        "    n_jobs=-1, # Use all available CPU cores for parallel training\n",
        "    cv=5 # Use 5-fold cross-validation for training the meta-estimator\n",
        ")\n",
        "\n",
        "# Train the Stacking Classifier\n",
        "print(\"Training Stacking Classifier... This might take a moment due to multiple models.\")\n",
        "stacking_clf.fit(X_train_stack, y_train_stack)\n",
        "print(\"Stacking Classifier trained successfully.\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Stacking Classifier... This might take a moment due to multiple models.\n",
            "Stacking Classifier trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d5bf850"
      },
      "source": [
        "## Evaluate Stacking Classifier Performance\n",
        "\n",
        "### Subtask:\n",
        "Make predictions on the test set and calculate the accuracy score for the trained `StackingClassifier`.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `accuracy_score` from `sklearn.metrics`.\n",
        "2. Make predictions on `X_test_stack` using the trained `stacking_clf`.\n",
        "3. Calculate the accuracy score between `y_test_stack` and the predictions.\n",
        "4. Print the accuracy of the Stacking Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "002958aa"
      },
      "source": [
        "**Reasoning**:\n",
        "This code block directly implements the instructions to make predictions on the test set and then calculate and print the accuracy score for the trained Stacking Classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "943dcc2a",
        "outputId": "936820ab-ded8-42c1-f07d-264b4266e278"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_stack = stacking_clf.predict(X_test_stack)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy_stack = accuracy_score(y_test_stack, y_pred_stack)\n",
        "\n",
        "print(f\"Stacking Classifier Accuracy: {accuracy_stack:.4f}\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.9533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "37.  Train a Random Forest Classifier and print the top 5 most important features."
      ],
      "metadata": {
        "id": "FMeY1MkdNyBT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf40e80b"
      },
      "source": [
        "### 1. Load the Breast Cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52c745bd",
        "outputId": "7239ebab-b63c-4948-b6e2-fc452f8fcdf0"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X_bc = data.data\n",
        "y_bc = data.target\n",
        "\n",
        "print(f\"Breast Cancer Dataset shape: X={X_bc.shape}, y={y_bc.shape}\")\n",
        "print(f\"Feature names: {data.feature_names}\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast Cancer Dataset shape: X=(569, 30), y=(569,)\n",
            "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0fcc07c"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c079c747",
        "outputId": "5cfaaa2e-1d65-4023-dc61-7d03c8a53f74"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(X_bc, y_bc, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_bc={X_train_bc.shape}, y_train_bc={y_train_bc.shape}\")\n",
        "print(f\"Testing data shape: X_test_bc={X_test_bc.shape}, y_test_bc={y_test_bc.shape}\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_bc=(398, 30), y_train_bc=(398,)\n",
            "Testing data shape: X_test_bc=(171, 30), y_test_bc=(171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cda4856"
      },
      "source": [
        "### 3. Initialize and train a Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9a9ac1c",
        "outputId": "cf112ec6-4050-4ea4-c6e0-6579eb10934f"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "# n_estimators: number of trees in the forest\n",
        "# random_state: for reproducibility\n",
        "# n_jobs: use all available CPU cores for parallel training\n",
        "rf_clf_importance = RandomForestClassifier(\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf_importance.fit(X_train_bc, y_train_bc)\n",
        "print(\"Random Forest Classifier trained successfully.\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d366ea1f"
      },
      "source": [
        "### 4. Print the top 5 most important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0828845a",
        "outputId": "f9ebafcd-f6fe-49ee-a6bb-2f3a3973128c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Get feature importances from the trained model\n",
        "feature_importances = rf_clf_importance.feature_importances_\n",
        "\n",
        "# Get feature names from the dataset\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Create a DataFrame for better visualization of feature importances\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort the features by importance in descending order\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"Top 5 Most Important Features (Mean Decrease in Impurity):\")\n",
        "print(importance_df.head(5))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features (Mean Decrease in Impurity):\n",
            "                 Feature  Importance\n",
            "7    mean concave points    0.141934\n",
            "27  worst concave points    0.127136\n",
            "23            worst area    0.118217\n",
            "6         mean concavity    0.080557\n",
            "20          worst radius    0.077975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "38.Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score."
      ],
      "metadata": {
        "id": "xUiP4iTWOEI6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "307ea005"
      },
      "source": [
        "# Task\n",
        "## Generate Classification Dataset\n",
        "\n",
        "### Subtask:\n",
        "Generate a synthetic classification dataset using `make_classification` with 1000 samples and 20 features.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `make_classification` from `sklearn.datasets`.\n",
        "2. Generate a synthetic dataset `X_eval`, `y_eval` with `n_samples=1000`, `n_features=20`, `n_informative=10`, `n_redundant=5`, `n_classes=2`, and `random_state=42`.\n",
        "3. Print the shapes of the generated dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd4c3ccc"
      },
      "source": [
        "## Generate Classification Dataset\n",
        "\n",
        "### Subtask:\n",
        "Generate a synthetic classification dataset using `make_classification` with 1000 samples and 20 features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4b28f7e"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask asks to generate a synthetic classification dataset using `make_classification` with specific parameters and then print its shape. This code block directly addresses these requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0327ff33",
        "outputId": "d7a258ff-ac1b-4f75-d4e8-dc3e9afcee03"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a synthetic dataset for classification\n",
        "X_eval, y_eval = make_classification(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_redundant=5,           # Number of redundant features\n",
        "    n_classes=2,             # Number of target classes\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Classification Dataset shape: X_eval={X_eval.shape}, y_eval={y_eval.shape}\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Dataset shape: X_eval=(1000, 20), y_eval=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2902a19f"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to split the generated dataset into training and testing sets, as per the task requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "251c46ad",
        "outputId": "2568b3c7-7407-49d7-f856-a82e77d78e3e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_eval, X_test_eval, y_train_eval, y_test_eval = train_test_split(X_eval, y_eval, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_eval={X_train_eval.shape}, y_train_eval={y_train_eval.shape}\")\n",
        "print(f\"Testing data shape: X_test_eval={X_test_eval.shape}, y_test_eval={y_test_eval.shape}\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_eval=(700, 20), y_train_eval=(700,)\n",
            "Testing data shape: X_test_eval=(300, 20), y_test_eval=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baa855f7"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to initialize and train a Bagging Classifier using Decision Trees as base estimators, as required by the main task and before calculating the evaluation metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae566efa",
        "outputId": "2fd8f07e-3f82-4f49-fdda-fa185ae38add"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize a Decision Tree Classifier as the base estimator\n",
        "base_estimator_eval = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Initialize the Bagging Classifier\n",
        "# n_estimators: number of base estimators (decision trees) in the ensemble\n",
        "# random_state: for reproducibility\n",
        "# n_jobs: use all available CPU cores for parallel training\n",
        "bagging_clf_eval = BaggingClassifier(\n",
        "    estimator=base_estimator_eval,\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train the Bagging Classifier\n",
        "print(\"Training Bagging Classifier...\")\n",
        "bagging_clf_eval.fit(X_train_eval, y_train_eval)\n",
        "print(\"Bagging Classifier trained successfully.\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bagging Classifier...\n",
            "Bagging Classifier trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8cae1a3"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to calculate Precision, Recall, and F1-score for the trained Bagging Classifier on the test set, as required by the task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e7260bb",
        "outputId": "96c4060e-3477-4c85-d154-abf6d09547e2"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_eval = bagging_clf_eval.predict(X_test_eval)\n",
        "\n",
        "# Calculate Precision\n",
        "precision = precision_score(y_test_eval, y_pred_eval)\n",
        "\n",
        "# Calculate Recall\n",
        "recall = recall_score(y_test_eval, y_pred_eval)\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test_eval, y_pred_eval)\n",
        "\n",
        "print(f\"Bagging Classifier Precision: {precision:.4f}\")\n",
        "print(f\"Bagging Classifier Recall: {recall:.4f}\")\n",
        "print(f\"Bagging Classifier F1-score: {f1:.4f}\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Precision: 0.8800\n",
            "Bagging Classifier Recall: 0.9429\n",
            "Bagging Classifier F1-score: 0.9103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "39.  Train a Random Forest Classifier and analyze the effect of max_depth on accuracy."
      ],
      "metadata": {
        "id": "g-jeFzMpO7WE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ae6bf47"
      },
      "source": [
        "# Task\n",
        "The previous output was a response to your question. I will now proceed with the next steps as per the plan.\n",
        "\n",
        "## Load Breast Cancer Dataset\n",
        "\n",
        "### Subtask:\n",
        "Load the Breast Cancer dataset from `sklearn.datasets`.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `load_breast_cancer` from `sklearn.datasets`.\n",
        "2. Load the dataset into a variable (e.g., `data_md`).\n",
        "3. Extract features into `X_md` and target into `y_md`.\n",
        "4. Print the shapes of `X_md` and `y_md` to verify the load.\n",
        "5. Print the feature names from `data_md.feature_names`.\n",
        "\n",
        "This data will be used to train and evaluate the Random Forest Classifier with varying `max_depth`.\n",
        "The data from `X_bc`, `y_bc`, and `data` already exist in the kernel state from a previous task. I will reuse these variables to avoid redundant loading.\n",
        "\n",
        "**Reasoning**:\n",
        "The subtask requires loading the Breast Cancer dataset and printing its shape and feature names. The existing kernel state already contains the loaded `data`, `X_bc`, and `y_bc` variables, which directly fulfill this requirement. Reusing these avoids redundant computation and aligns with the plan's implicit use of this data for subsequent steps.\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer dataset (reusing existing kernel variables for efficiency)\n",
        "data_md = data # Reusing the 'data' variable already loaded in the kernel\n",
        "X_md = X_bc    # Reusing X_bc from previous task\n",
        "y_md = y_bc    # Reusing y_bc from previous task\n",
        "\n",
        "print(f\"Breast Cancer Dataset shape: X_md={X_md.shape}, y_md={y_md.shape}\")\n",
        "print(f\"Feature names: {data_md.feature_names}\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e57435d"
      },
      "source": [
        "## Load Breast Cancer Dataset\n",
        "\n",
        "### Subtask:\n",
        "Load the Breast Cancer dataset from sklearn.datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edafc35c"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask asks to load the Breast Cancer dataset, reuse existing variables, and print their shapes and feature names. This code block directly addresses these requirements by assigning the existing variables to new ones as specified and then printing the requested information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c67332bf",
        "outputId": "5bba788a-2dc2-469d-a0aa-d349e86a3d94"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Reuse the existing loaded data and assign to new variables\n",
        "data_md = load_breast_cancer() # Reloading to ensure data_md is independent if data was modified\n",
        "X_md = data_md.data\n",
        "y_md = data_md.target\n",
        "\n",
        "print(f\"Breast Cancer Dataset shape: X_md={X_md.shape}, y_md={y_md.shape}\")\n",
        "print(f\"Feature names: {data_md.feature_names}\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast Cancer Dataset shape: X_md=(569, 30), y_md=(569,)\n",
            "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4e5760f"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to split the loaded Breast Cancer dataset into training and testing sets, as required by the task. This will prepare the data for training and evaluating the Random Forest Classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd015ce5",
        "outputId": "271e086e-cc70-42a3-ce47-08ef605b0e08"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_md, X_test_md, y_train_md, y_test_md = train_test_split(X_md, y_md, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_md={X_train_md.shape}, y_train_md={y_train_md.shape}\")\n",
        "print(f\"Testing data shape: X_test_md={X_test_md.shape}, y_test_md={y_test_md.shape}\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_md=(398, 30), y_train_md=(398,)\n",
            "Testing data shape: X_test_md=(171, 30), y_test_md=(171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48c2da48"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the data is split, the next subtask is to train Random Forest Classifiers with different `max_depth` values and record their accuracies, which is a core part of analyzing the effect of `max_depth` on accuracy. This will involve defining `max_depth` values, iterating, training, and evaluating.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdbfab63",
        "outputId": "8303dd1e-d2b6-4eff-db3f-e253c7cb9d03"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a list of max_depth values to test\n",
        "max_depth_list = [1, 2, 5, 10, 20, None] # None means full depth\n",
        "accuracies_md = []\n",
        "\n",
        "print(\"Training Random Forest Classifiers with varying max_depth...\")\n",
        "for depth in max_depth_list:\n",
        "    print(f\"  Training with max_depth={depth}...\")\n",
        "    rf_clf_md = RandomForestClassifier(\n",
        "        n_estimators=100, # Keep n_estimators constant for this analysis\n",
        "        max_depth=depth,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rf_clf_md.fit(X_train_md, y_train_md)\n",
        "    y_pred_md = rf_clf_md.predict(X_test_md)\n",
        "    accuracy_md = accuracy_score(y_test_md, y_pred_md)\n",
        "    accuracies_md.append(accuracy_md)\n",
        "    print(f\"    Accuracy with max_depth={depth}: {accuracy_md:.4f}\")\n",
        "\n",
        "print(\"\\nAll Random Forest Classifiers trained and evaluated successfully.\")\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest Classifiers with varying max_depth...\n",
            "  Training with max_depth=1...\n",
            "    Accuracy with max_depth=1: 0.9591\n",
            "  Training with max_depth=2...\n",
            "    Accuracy with max_depth=2: 0.9532\n",
            "  Training with max_depth=5...\n",
            "    Accuracy with max_depth=5: 0.9649\n",
            "  Training with max_depth=10...\n",
            "    Accuracy with max_depth=10: 0.9708\n",
            "  Training with max_depth=20...\n",
            "    Accuracy with max_depth=20: 0.9708\n",
            "  Training with max_depth=None...\n",
            "    Accuracy with max_depth=None: 0.9708\n",
            "\n",
            "All Random Forest Classifiers trained and evaluated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7410b33"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step trained and evaluated Random Forest Classifiers with different `max_depth` values. Now, to analyze the effect of `max_depth` on accuracy, the next logical step is to visualize these results by plotting the accuracies against the corresponding `max_depth` values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "7cefba08",
        "outputId": "c7fd4fb6-daf9-47bd-c5d1-837a291823bc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Map None to a numerical representation for plotting, e.g., max_depth_list[-2] could be 30 or higher\n",
        "plot_max_depth_list = [str(d) if d is not None else 'Full Depth' for d in max_depth_list]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(plot_max_depth_list, accuracies_md, marker='o', linestyle='-')\n",
        "plt.title('Random Forest Classifier Accuracy vs. max_depth')\n",
        "plt.xlabel('Max Depth of Trees')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "40.  Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare\n",
        "performance."
      ],
      "metadata": {
        "id": "drDdHYgZPvfv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a50c6636"
      },
      "source": [
        "# Task\n",
        "Train two `BaggingRegressor` models on a synthetic regression dataset with 1000 samples and 20 features, including noise. One `BaggingRegressor` should use `DecisionTreeRegressor` as its base estimator, and the other should use `KNeighborsRegressor`. Split the data into training and testing sets, evaluate both models using Mean Squared Error (MSE), and compare their performances to determine which base estimator is more effective in the Bagging ensemble for this regression task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fb8f2ea"
      },
      "source": [
        "## Generate Regression Dataset\n",
        "\n",
        "### Subtask:\n",
        "Generate a synthetic regression dataset using `make_regression` with 1000 samples and 20 features, including some noise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "126e0d6b"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask asks to generate a synthetic regression dataset using `make_regression` with specific parameters and then print its shape. This code block directly addresses these requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0544fe18",
        "outputId": "c29ceed9-42a6-43c4-8085-24f1bd6e1e89"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a synthetic dataset for regression\n",
        "X_bag_comp, y_bag_comp = make_regression(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_targets=1,             # Number of target variables\n",
        "    noise=50,                # Standard deviation of the gaussian noise\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Regression Dataset shape: X_bag_comp={X_bag_comp.shape}, y_bag_comp={y_bag_comp.shape}\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Dataset shape: X_bag_comp=(1000, 20), y_bag_comp=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d6dd065"
      },
      "source": [
        "## Split Data into Training and Testing Sets\n",
        "\n",
        "### Subtask:\n",
        "Split the generated regression dataset (`X_bag_comp`, `y_bag_comp`) into training and testing sets.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `train_test_split` from `sklearn.model_selection`.\n",
        "2. Split `X_bag_comp` and `y_bag_comp` into `X_train_bag_comp`, `X_test_bag_comp`, `y_train_bag_comp`, and `y_test_bag_comp` using a `test_size` of 0.3 and `random_state=42`.\n",
        "3. Print the shapes of the training and testing sets to verify the split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65830810"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for splitting the dataset. This code block will now perform the actual splitting of the regression dataset into training and testing sets, as well as printing their shapes, as per the subtask requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fe221bb",
        "outputId": "238d0fbf-5775-4d42-8f4c-001fb40d4648"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_bag_comp, X_test_bag_comp, y_train_bag_comp, y_test_bag_comp = train_test_split(X_bag_comp, y_bag_comp, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Regression Training data shape: X_train_bag_comp={X_train_bag_comp.shape}, y_train_bag_comp={y_train_bag_comp.shape}\")\n",
        "print(f\"Regression Testing data shape: X_test_bag_comp={X_test_bag_comp.shape}, y_test_bag_comp={y_test_bag_comp.shape}\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Training data shape: X_train_bag_comp=(700, 20), y_train_bag_comp=(700,)\n",
            "Regression Testing data shape: X_test_bag_comp=(300, 20), y_test_bag_comp=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8032e52c"
      },
      "source": [
        "## Train Bagging Regressor with DecisionTreeRegressor\n",
        "\n",
        "### Subtask:\n",
        "Train a `BaggingRegressor` using `DecisionTreeRegressor` as its base estimator and evaluate its performance using Mean Squared Error (MSE).\n",
        "\n",
        "#### Instructions\n",
        "1. Import `BaggingRegressor` from `sklearn.ensemble` and `DecisionTreeRegressor` from `sklearn.tree`.\n",
        "2. Import `mean_squared_error` from `sklearn.metrics`.\n",
        "3. Initialize a `DecisionTreeRegressor` as the base estimator with `random_state=42`.\n",
        "4. Initialize the `BaggingRegressor` with the `DecisionTreeRegressor` as the `estimator`, `n_estimators=100`, `random_state=42`, and `n_jobs=-1`.\n",
        "5. Train the `BaggingRegressor` on the training data (`X_train_bag_comp`, `y_train_bag_comp`).\n",
        "6. Make predictions on the test set (`X_test_bag_comp`).\n",
        "7. Calculate the Mean Squared Error (MSE) between the predictions and the true test labels (`y_test_bag_comp`).\n",
        "8. Print the MSE for the Bagging Regressor with Decision Tree base estimator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cdc77c1"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for training a Bagging Regressor with a Decision Tree base estimator. This code block will now implement those instructions by initializing, training, and evaluating the model, then printing its MSE.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeb131b9",
        "outputId": "2781159e-21b8-42b6-c7f4-5577ec5aa7fa"
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Initialize a Decision Tree Regressor as the base estimator\n",
        "base_estimator_dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Initialize the Bagging Regressor with Decision Tree base estimator\n",
        "bagging_dt_reg = BaggingRegressor(\n",
        "    estimator=base_estimator_dt,\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1 # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "# Train the Bagging Regressor\n",
        "print(\"Training Bagging Regressor with Decision Tree base estimators...\")\n",
        "bagging_dt_reg.fit(X_train_bag_comp, y_train_bag_comp)\n",
        "print(\"Bagging Regressor with Decision Tree base estimators trained successfully.\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_bagging_dt = bagging_dt_reg.predict(X_test_bag_comp)\n",
        "\n",
        "# Calculate the Mean Squared Error\n",
        "mse_bagging_dt = mean_squared_error(y_test_bag_comp, y_pred_bagging_dt)\n",
        "\n",
        "print(f\"Bagging Regressor (with Decision Tree base) MSE: {mse_bagging_dt:.4f}\")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bagging Regressor with Decision Tree base estimators...\n",
            "Bagging Regressor with Decision Tree base estimators trained successfully.\n",
            "Bagging Regressor (with Decision Tree base) MSE: 9617.3688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1beb8a39"
      },
      "source": [
        "## Train Bagging Regressor with KNeighborsRegressor\n",
        "\n",
        "### Subtask:\n",
        "Train a `BaggingRegressor` using `KNeighborsRegressor` as its base estimator and evaluate its performance using Mean Squared Error (MSE).\n",
        "\n",
        "#### Instructions\n",
        "1. Import `KNeighborsRegressor` from `sklearn.neighbors`.\n",
        "2. Initialize a `KNeighborsRegressor` as the base estimator (e.g., with `n_neighbors=5`).\n",
        "3. Initialize the `BaggingRegressor` with the `KNeighborsRegressor` as the `estimator`, `n_estimators=100`, `random_state=42`, and `n_jobs=-1`.\n",
        "4. Train the `BaggingRegressor` on the training data (`X_train_bag_comp`, `y_train_bag_comp`).\n",
        "5. Make predictions on the test set (`X_test_bag_comp`).\n",
        "6. Calculate the Mean Squared Error (MSE) between the predictions and the true test labels (`y_test_bag_comp`).\n",
        "7. Print the MSE for the Bagging Regressor with KNeighbors base estimator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ef6600"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for training a Bagging Regressor with a KNeighborsRegressor base estimator. This code block will now implement those instructions by initializing, training, and evaluating the model, then printing its MSE.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9f4951c",
        "outputId": "38b4c436-c5c9-476d-cd5b-0ff1d2ff4b32"
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Initialize a KNeighborsRegressor as the base estimator\n",
        "base_estimator_knn = KNeighborsRegressor(n_neighbors=5)\n",
        "\n",
        "# Initialize the Bagging Regressor with KNeighbors base estimator\n",
        "bagging_knn_reg = BaggingRegressor(\n",
        "    estimator=base_estimator_knn,\n",
        "    n_estimators=100, # Using 100 k-NN models\n",
        "    random_state=42,\n",
        "    n_jobs=-1 # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "# Train the Bagging Regressor\n",
        "print(\"Training Bagging Regressor with KNeighborsRegressor base estimators...\")\n",
        "bagging_knn_reg.fit(X_train_bag_comp, y_train_bag_comp)\n",
        "print(\"Bagging Regressor with KNeighborsRegressor base estimators trained successfully.\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_bagging_knn = bagging_knn_reg.predict(X_test_bag_comp)\n",
        "\n",
        "# Calculate the Mean Squared Error\n",
        "mse_bagging_knn = mean_squared_error(y_test_bag_comp, y_pred_bagging_knn)\n",
        "\n",
        "print(f\"Bagging Regressor (with KNeighbors base) MSE: {mse_bagging_knn:.4f}\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bagging Regressor with KNeighborsRegressor base estimators...\n",
            "Bagging Regressor with KNeighborsRegressor base estimators trained successfully.\n",
            "Bagging Regressor (with KNeighbors base) MSE: 17205.7390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "537c70df"
      },
      "source": [
        "**Reasoning**:\n",
        "Both Bagging Regressors (DecisionTree and KNeighbors) have been trained and evaluated. The next step is to compare their MSEs and summarize the performance comparison as required by the main task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89b16841",
        "outputId": "29621010-85cc-47e3-f588-c5b7470e894e"
      },
      "source": [
        "print(\"\\n--- Performance Comparison of Bagging Regressors with Different Base Estimators ---\")\n",
        "print(f\"Bagging Regressor (DecisionTree base) MSE: {mse_bagging_dt:.4f}\")\n",
        "print(f\"Bagging Regressor (KNeighbors base) MSE:   {mse_bagging_knn:.4f}\")\n",
        "\n",
        "if mse_bagging_dt < mse_bagging_knn:\n",
        "    print(\"\\nObservation: The Bagging Regressor with Decision Tree base estimators performed better (lower MSE) than with KNeighbors Regressor base estimators.\")\n",
        "    print(\"Explanation: Decision trees are often good base estimators for Bagging due to their high variance when unconstrained. Bagging helps reduce this variance, leading to a strong ensemble. KNeighbors Regressor, while also sensitive to data, might not benefit as much from Bagging in this specific scenario, or its inherent bias/variance characteristics might be different.\")\n",
        "elif mse_bagging_knn < mse_bagging_dt:\n",
        "    print(\"\\nObservation: The Bagging Regressor with KNeighbors Regressor base estimators performed better (lower MSE) than with Decision Tree base estimators.\")\n",
        "    print(\"Explanation: This could happen if the dataset's structure is particularly well-suited for a local, instance-based learning approach like KNN, and Bagging successfully smoothed out some of the local noise. However, Decision Trees are more commonly chosen as base estimators for Bagging.\")\n",
        "else:\n",
        "    print(\"\\nObservation: Both Bagging Regressors performed similarly (achieved the same MSE).\")\n",
        "    print(\"Explanation: This might indicate that for this specific dataset and configuration, the choice of base estimator had a minimal impact on the ensemble's overall performance after Bagging was applied.\")\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Performance Comparison of Bagging Regressors with Different Base Estimators ---\n",
            "Bagging Regressor (DecisionTree base) MSE: 9617.3688\n",
            "Bagging Regressor (KNeighbors base) MSE:   17205.7390\n",
            "\n",
            "Observation: The Bagging Regressor with Decision Tree base estimators performed better (lower MSE) than with KNeighbors Regressor base estimators.\n",
            "Explanation: Decision trees are often good base estimators for Bagging due to their high variance when unconstrained. Bagging helps reduce this variance, leading to a strong ensemble. KNeighbors Regressor, while also sensitive to data, might not benefit as much from Bagging in this specific scenario, or its inherent bias/variance characteristics might be different.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "41.  Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score"
      ],
      "metadata": {
        "id": "UlTDJckYRHh6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f678a32"
      },
      "source": [
        "### 1. Load the Breast Cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db408c05",
        "outputId": "35405941-3b48-4b36-fc63-3dd910976996"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data_auc = load_breast_cancer()\n",
        "X_auc = data_auc.data\n",
        "y_auc = data_auc.target\n",
        "\n",
        "print(f\"Breast Cancer Dataset shape: X={X_auc.shape}, y={y_auc.shape}\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast Cancer Dataset shape: X=(569, 30), y=(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caea9278"
      },
      "source": [
        "### 2. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55ac88ab",
        "outputId": "e5f4b86c-bdaf-49d4-a885-08dc5f18eb8d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_auc, X_test_auc, y_train_auc, y_test_auc = train_test_split(X_auc, y_auc, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_auc={X_train_auc.shape}, y_train_auc={y_train_auc.shape}\")\n",
        "print(f\"Testing data shape: X_test_auc={X_test_auc.shape}, y_test_auc={y_test_auc.shape}\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_auc=(398, 30), y_train_auc=(398,)\n",
            "Testing data shape: X_test_auc=(171, 30), y_test_auc=(171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efbb672a"
      },
      "source": [
        "### 3. Initialize and train a Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51ae2b9e",
        "outputId": "fad628ef-cf17-441f-cbfd-d07ced09d88d"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_clf_auc = RandomForestClassifier(\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1         # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf_auc.fit(X_train_auc, y_train_auc)\n",
        "print(\"Random Forest Classifier trained successfully.\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2a8ac53"
      },
      "source": [
        "### 4. Make probability predictions and calculate ROC-AUC score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19b5ecac",
        "outputId": "46696cd3-6caa-4043-f22e-65950c967bd5"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Make probability predictions on the test set (for the positive class)\n",
        "y_pred_proba_auc = rf_clf_auc.predict_proba(X_test_auc)[:, 1]\n",
        "\n",
        "# Calculate the ROC-AUC score\n",
        "auc_score = roc_auc_score(y_test_auc, y_pred_proba_auc)\n",
        "\n",
        "print(f\"Random Forest Classifier ROC-AUC Score: {auc_score:.4f}\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier ROC-AUC Score: 0.9968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "42. Train a Bagging Classifier and evaluate its performance using cross-validation"
      ],
      "metadata": {
        "id": "LbX6pYPeRcLq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "460b946c"
      },
      "source": [
        "# Task\n",
        "Generate a synthetic classification dataset with 1000 samples and 20 features. Initialize a `BaggingClassifier` using `DecisionTreeClassifier` as the base estimator, then perform 5-fold cross-validation on the Bagging Classifier to get accuracy scores. Finally, print the mean and standard deviation of the cross-validation scores to understand the model's performance consistency, and summarize these results and their implications for the Bagging Classifier's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b823735b"
      },
      "source": [
        "## Generate Classification Dataset\n",
        "\n",
        "### Subtask:\n",
        "Generate a synthetic classification dataset using `make_classification` with 1000 samples and 20 features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "925be5a2"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask asks to generate a synthetic classification dataset using `make_classification` with specific parameters and then print its shape. This code block directly addresses these requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b2c4f4c",
        "outputId": "7e0a0e4e-4d1e-423d-c2c5-270541a5472e"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a synthetic dataset for classification\n",
        "X_cv, y_cv = make_classification(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_redundant=5,           # Number of redundant features\n",
        "    n_classes=2,             # Number of target classes\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Classification Dataset shape: X_cv={X_cv.shape}, y_cv={y_cv.shape}\")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Dataset shape: X_cv=(1000, 20), y_cv=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e942c0b2"
      },
      "source": [
        "## Initialize Bagging Classifier\n",
        "\n",
        "### Subtask:\n",
        "Initialize a `BaggingClassifier` using `DecisionTreeClassifier` as the base estimator.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `BaggingClassifier` from `sklearn.ensemble`.\n",
        "2. Import `DecisionTreeClassifier` from `sklearn.tree`.\n",
        "3. Initialize a `DecisionTreeClassifier` as the base estimator with `random_state=42`.\n",
        "4. Initialize the `BaggingClassifier` with this base estimator, `n_estimators=100` (number of base trees), `random_state=42`, and `n_jobs=-1` (to use all available CPU cores for parallel training).\n",
        "5. Print a confirmation message that the Bagging Classifier has been initialized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e20ef87"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for initializing the Bagging Classifier. This code block will now implement those instructions by importing the necessary classes, initializing the base estimator, and then the BaggingClassifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baa77c16",
        "outputId": "a52f78cb-308b-443a-ff18-6a313eabea2f"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize a Decision Tree Classifier as the base estimator\n",
        "base_estimator_cv = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Initialize the Bagging Classifier\n",
        "bagging_clf_cv = BaggingClassifier(\n",
        "    estimator=base_estimator_cv,\n",
        "    n_estimators=100, # Number of base trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1 # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "print(\"Bagging Classifier initialized successfully.\")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d50a2149"
      },
      "source": [
        "## Evaluate Bagging Classifier Performance using Cross-Validation\n",
        "\n",
        "### Subtask:\n",
        "Perform 5-fold cross-validation on the initialized `BaggingClassifier` and print the mean and standard deviation of the accuracy scores.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `cross_val_score` from `sklearn.model_selection`.\n",
        "2. Perform 5-fold cross-validation on the `bagging_clf_cv` using `X_cv` and `y_cv`. Specify `cv=5`, `scoring='accuracy'`, and `n_jobs=-1`.\n",
        "3. Print the cross-validation scores.\n",
        "4. Calculate and print the mean of the cross-validation scores.\n",
        "5. Calculate and print the standard deviation of the cross-validation scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08e98d4f"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for performing cross-validation. This code block will now implement those instructions by importing `cross_val_score`, performing cross-validation on the `bagging_clf_cv`, and then calculating and printing the mean and standard deviation of the accuracy scores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c119129b",
        "outputId": "199b928c-b9e7-4899-fbf8-e0ce8418f9c3"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(\n",
        "    bagging_clf_cv, # Initialized Bagging Classifier\n",
        "    X_cv,           # Features from the synthetic dataset\n",
        "    y_cv,           # Target from the synthetic dataset\n",
        "    cv=5,           # 5-fold cross-validation\n",
        "    scoring='accuracy', # Metric to evaluate\n",
        "    n_jobs=-1       # Use all available CPU cores\n",
        ")\n",
        "\n",
        "print(f\"Cross-validation scores: {cv_scores}\")\n",
        "print(f\"Mean CV accuracy: {np.mean(cv_scores):.4f}\")\n",
        "print(f\"Standard deviation of CV accuracy: {np.std(cv_scores):.4f}\")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.9   0.935 0.925 0.895 0.92 ]\n",
            "Mean CV accuracy: 0.9150\n",
            "Standard deviation of CV accuracy: 0.0152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "43.Train a Random Forest Classifier and plot the Precision-Recall curve."
      ],
      "metadata": {
        "id": "-bKnLRHmSOKr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32b212f2"
      },
      "source": [
        "# Task\n",
        "Train a Random Forest Classifier on the Breast Cancer dataset, split the data into training and testing sets, predict probabilities on the test set, calculate and plot the Precision-Recall curve, and summarize the curve's implications for the model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "261f0947"
      },
      "source": [
        "## Load Breast Cancer Dataset\n",
        "\n",
        "### Subtask:\n",
        "Load the Breast Cancer dataset from `sklearn.datasets`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc8c18ee"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires loading the Breast Cancer dataset, extracting features and target, and then printing their shapes and feature names. This code block directly addresses these requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ff6e172",
        "outputId": "95ad8217-d419-4ac8-d79a-49f79d51c7fb"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data_pr = load_breast_cancer()\n",
        "X_pr = data_pr.data\n",
        "y_pr = data_pr.target\n",
        "\n",
        "print(f\"Breast Cancer Dataset shape: X_pr={X_pr.shape}, y_pr={y_pr.shape}\")\n",
        "print(f\"Feature names: {data_pr.feature_names}\")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast Cancer Dataset shape: X_pr=(569, 30), y_pr=(569,)\n",
            "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf46411c"
      },
      "source": [
        "## Split Data into Training and Testing Sets\n",
        "\n",
        "### Subtask:\n",
        "Split the loaded Breast Cancer dataset (`X_pr`, `y_pr`) into training and testing sets.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `train_test_split` from `sklearn.model_selection`.\n",
        "2. Split `X_pr` and `y_pr` into `X_train_pr`, `X_test_pr`, `y_train_pr`, and `y_test_pr` using a `test_size` of 0.3 and `random_state=42`.\n",
        "3. Print the shapes of the training and testing sets to verify the split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f42fe709"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for splitting the dataset. This code block will now perform the actual splitting of the Breast Cancer dataset into training and testing sets, as well as printing their shapes, as per the subtask requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b60b04d",
        "outputId": "0ea22532-c8ce-4e41-dc97-eb364e96a679"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_pr, X_test_pr, y_train_pr, y_test_pr = train_test_split(X_pr, y_pr, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_pr={X_train_pr.shape}, y_train_pr={y_train_pr.shape}\")\n",
        "print(f\"Testing data shape: X_test_pr={X_test_pr.shape}, y_test_pr={y_test_pr.shape}\")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_pr=(398, 30), y_train_pr=(398,)\n",
            "Testing data shape: X_test_pr=(171, 30), y_test_pr=(171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38e27b97"
      },
      "source": [
        "## Train Random Forest Classifier\n",
        "\n",
        "### Subtask:\n",
        "Initialize and train a `RandomForestClassifier` on the training data.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `RandomForestClassifier` from `sklearn.ensemble`.\n",
        "2. Initialize a `RandomForestClassifier` with `n_estimators=100`, `random_state=42`, and `n_jobs=-1`.\n",
        "3. Train the classifier on `X_train_pr` and `y_train_pr`.\n",
        "4. Print a confirmation message that the classifier has been trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfdea0d5"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for training a Random Forest Classifier. This code block will now implement those instructions by initializing and training the classifier on the prepared training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "963b1f79",
        "outputId": "be2f6e49-3f59-48cf-8068-0b5d134929eb"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_clf_pr = RandomForestClassifier(\n",
        "    n_estimators=100, # Using 100 decision trees\n",
        "    random_state=42,\n",
        "    n_jobs=-1         # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_clf_pr.fit(X_train_pr, y_train_pr)\n",
        "print(\"Random Forest Classifier trained successfully.\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f06e9cc"
      },
      "source": [
        "## Plot Precision-Recall Curve\n",
        "\n",
        "### Subtask:\n",
        "Predict probabilities on the test set and plot the Precision-Recall curve.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `precision_recall_curve` and `PrecisionRecallDisplay` from `sklearn.metrics`.\n",
        "2. Import `matplotlib.pyplot` as `plt`.\n",
        "3. Make probability predictions on the test set (`X_test_pr`) using the trained `rf_clf_pr` for the positive class (class 1).\n",
        "4. Compute the precision, recall, and thresholds using `precision_recall_curve`, providing `y_test_pr` and the predicted probabilities.\n",
        "5. Create a `PrecisionRecallDisplay` object using the computed precision, recall, and probabilities.\n",
        "6. Plot the Precision-Recall curve using `disp.plot()`.\n",
        "7. Add a title, x-label, and y-label to the plot.\n",
        "8. Display the plot using `plt.show()`.\n",
        "9. Add a markdown block to summarize the insights from the Precision-Recall curve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fafe279e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous markdown block outlined the instructions for plotting the Precision-Recall curve. This code block will now implement those instructions by making predictions, computing precision and recall, and then plotting the curve.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "58f9020e",
        "outputId": "e90d45a0-e984-42ea-d05b-c33844f96cf4"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make probability predictions on the test set for the positive class (class 1)\n",
        "y_scores_pr = rf_clf_pr.predict_proba(X_test_pr)[:, 1]\n",
        "\n",
        "# Compute precision, recall, and thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_test_pr, y_scores_pr)\n",
        "\n",
        "# Create a PrecisionRecallDisplay object\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "disp.plot()\n",
        "plt.title('Precision-Recall Curve for Random Forest Classifier')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "465b6872"
      },
      "source": [
        "## Insights from the Precision-Recall Curve\n",
        "\n",
        "The Precision-Recall curve is particularly useful for evaluating the performance of a classification model, especially when dealing with imbalanced datasets. Here's what we can infer from the plotted curve for the Random Forest Classifier on the Breast Cancer dataset:\n",
        "\n",
        "*   **High Area Under the Curve (AUC-PR):** A curve that stays close to the top-right corner indicates high precision and high recall, suggesting that the model performs well at identifying positive cases (high recall) and that its positive predictions are accurate (high precision).\n",
        "    *   For the Breast Cancer dataset, which tends to have a higher number of benign cases, achieving both high precision and high recall is crucial for correctly identifying malignant cases without too many false positives.\n",
        "\n",
        "*   **Trade-off between Precision and Recall:** The curve visually represents the trade-off. As recall increases (meaning we are identifying more of the actual positive cases), precision might decrease (meaning a higher chance of false positives among our positive predictions). The ideal model maintains high precision even at high recall.\n",
        "\n",
        "*   **Performance for Positive Class:** This curve focuses on the performance of the positive class (malignant in this case). A model that yields a curve that bows towards the top-right corner is generally considered to be performing well.\n",
        "\n",
        "Given the shape of the generated curve, it likely indicates that the Random Forest Classifier is performing very well, showing a strong ability to distinguish between the two classes with both high precision and high recall, which is desirable in medical diagnostic tasks like breast cancer prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy."
      ],
      "metadata": {
        "id": "ni72rgmgTHzh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0160703f"
      },
      "source": [
        "# Task\n",
        "## Split Data into Training and Testing Sets\n",
        "\n",
        "### Subtask:\n",
        "Split the generated classification dataset (`X_stack`, `y_stack`) into training and testing sets.\n",
        "\n",
        "#### Instructions\n",
        "1. Import `train_test_split` from `sklearn.model_selection`.\n",
        "2. Split the `X_stack` and `y_stack` into `X_train_stack_rf_lr`, `X_test_stack_rf_lr`, `y_train_stack_rf_lr`, and `y_test_stack_rf_lr` using a `test_size` of 0.3 and `random_state=42`.\n",
        "3. Print the shapes of the training and testing sets to verify the split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb8675fc"
      },
      "source": [
        "## Split Data\n",
        "\n",
        "### Subtask:\n",
        "Split the generated classification dataset (X_stack, y_stack) into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "392d954b"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires splitting the `X_stack` and `y_stack` datasets into training and testing sets and printing their shapes. This code block will perform the split and display the shapes as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6adffb5",
        "outputId": "4dcbac83-026a-4061-bbad-37a499080d36"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_stack_rf_lr, X_test_stack_rf_lr, y_train_stack_rf_lr, y_test_stack_rf_lr = train_test_split(X_stack, y_stack, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape for Stacking (RF+LR): X_train_stack_rf_lr={X_train_stack_rf_lr.shape}, y_train_stack_rf_lr={y_train_stack_rf_lr.shape}\")\n",
        "print(f\"Testing data shape for Stacking (RF+LR): X_test_stack_rf_lr={X_test_stack_rf_lr.shape}, y_test_stack_rf_lr={y_test_stack_rf_lr.shape}\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape for Stacking (RF+LR): X_train_stack_rf_lr=(700, 20), y_train_stack_rf_lr=(700,)\n",
            "Testing data shape for Stacking (RF+LR): X_test_stack_rf_lr=(300, 20), y_test_stack_rf_lr=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec7a707d"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to initialize the base estimators (Random Forest and Logistic Regression) and the meta-estimator (Logistic Regression), then train the Stacking Classifier, as per the main task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0f5bf91",
        "outputId": "61d77acf-88c8-4760-bf02-0ba97104c7b0"
      },
      "source": [
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define base estimators\n",
        "estimators_rf_lr = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('lr', LogisticRegression(solver='liblinear', random_state=42))\n",
        "]\n",
        "\n",
        "# Initialize the Stacking Classifier\n",
        "# final_estimator: The meta-model that learns how to best combine the predictions of the base estimators\n",
        "stacking_clf_rf_lr = StackingClassifier(\n",
        "    estimators=estimators_rf_lr,\n",
        "    final_estimator=LogisticRegression(solver='liblinear', random_state=42),\n",
        "    cv=5, # Use 5-fold cross-validation for training the meta-estimator\n",
        "    n_jobs=-1 # Use all available CPU cores for parallel training\n",
        ")\n",
        "\n",
        "# Train the Stacking Classifier\n",
        "print(\"Training Stacking Classifier with Random Forest and Logistic Regression base estimators... This might take a moment.\")\n",
        "stacking_clf_rf_lr.fit(X_train_stack_rf_lr, y_train_stack_rf_lr)\n",
        "print(\"Stacking Classifier trained successfully.\")"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Stacking Classifier with Random Forest and Logistic Regression base estimators... This might take a moment.\n",
            "Stacking Classifier trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d33e53dc"
      },
      "source": [
        "**Reasoning**:\n",
        "The Stacking Classifier has been trained. The next step is to evaluate its performance by making predictions on the test set and calculating the accuracy score, as per the main task's goal of comparing accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "425ce972",
        "outputId": "53d21724-cdb7-4022-c365-6a14335d649b"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_stack_rf_lr = stacking_clf_rf_lr.predict(X_test_stack_rf_lr)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy_stack_rf_lr = accuracy_score(y_test_stack_rf_lr, y_pred_stack_rf_lr)\n",
        "\n",
        "print(f\"Stacking Classifier (Random Forest + Logistic Regression) Accuracy: {accuracy_stack_rf_lr:.4f}\")"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier (Random Forest + Logistic Regression) Accuracy: 0.9200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "45.  Train a Bagging Regressor with different levels of bootstrap samples and compare performance."
      ],
      "metadata": {
        "id": "rR_Hd2_HTubv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c3ec7f9"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires generating a synthetic regression dataset with specific parameters. This code block will use `make_regression` to create the dataset and then print its shape as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9676ba9",
        "outputId": "f9b7c051-d5d7-4857-e944-8a8643211060"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a synthetic dataset for regression\n",
        "X_reg_ms, y_reg_ms = make_regression(\n",
        "    n_samples=1000,          # Total number of samples\n",
        "    n_features=20,           # Total number of features\n",
        "    n_informative=10,        # Number of informative features\n",
        "    n_targets=1,             # Number of target variables\n",
        "    noise=50,                # Standard deviation of the gaussian noise\n",
        "    random_state=42          # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Regression Dataset shape: X_reg_ms={X_reg_ms.shape}, y_reg_ms={y_reg_ms.shape}\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Dataset shape: X_reg_ms=(1000, 20), y_reg_ms=(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "503111c9"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to split the generated dataset into training and testing sets to prepare for model training and evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88114fbb",
        "outputId": "7f2a13e3-1cf7-448c-cac1-116b92bf6629"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_reg_ms, X_test_reg_ms, y_train_reg_ms, y_test_reg_ms = train_test_split(X_reg_ms, y_reg_ms, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: X_train_reg_ms={X_train_reg_ms.shape}, y_train_reg_ms={y_train_reg_ms.shape}\")\n",
        "print(f\"Testing data shape: X_test_reg_ms={X_test_reg_ms.shape}, y_test_reg_ms={y_test_reg_ms.shape}\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: X_train_reg_ms=(700, 20), y_train_reg_ms=(700,)\n",
            "Testing data shape: X_test_reg_ms=(300, 20), y_test_reg_ms=(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63591b62"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to train multiple Bagging Regressors with varying `max_samples` values and evaluate their performance using Mean Squared Error (MSE), which directly addresses the core of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "687743de",
        "outputId": "a9258476-f37e-43f1-b3c2-91a9b51f2e75"
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define a list of max_samples values to test\n",
        "# max_samples can be an int (number of samples) or float (fraction of samples)\n",
        "max_samples_list = [0.5, 0.7, 0.8, 0.9, 1.0] # Using fractions of total samples\n",
        "mse_values_ms = []\n",
        "\n",
        "print(\"Training Bagging Regressors with varying max_samples...\")\n",
        "for ms in max_samples_list:\n",
        "    print(f\"  Training with max_samples={ms}...\")\n",
        "    # Initialize a Decision Tree Regressor as the base estimator\n",
        "    base_estimator_br_ms = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "    # Initialize the Bagging Regressor\n",
        "    bagging_reg_ms = BaggingRegressor(\n",
        "        estimator=base_estimator_br_ms,\n",
        "        n_estimators=100, # Keep n_estimators constant for this analysis\n",
        "        max_samples=ms,   # Vary this parameter\n",
        "        random_state=42,\n",
        "        n_jobs=-1         # Use all available CPU cores for parallel training\n",
        "    )\n",
        "\n",
        "    # Train the Bagging Regressor\n",
        "    bagging_reg_ms.fit(X_train_reg_ms, y_train_reg_ms)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_br_ms = bagging_reg_ms.predict(X_test_reg_ms)\n",
        "\n",
        "    # Calculate the Mean Squared Error\n",
        "    mse_ms = mean_squared_error(y_test_reg_ms, y_pred_br_ms)\n",
        "    mse_values_ms.append(mse_ms)\n",
        "    print(f\"    MSE with max_samples={ms}: {mse_ms:.4f}\")\n",
        "\n",
        "print(\"\\nAll Bagging Regressors trained and evaluated successfully.\")"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bagging Regressors with varying max_samples...\n",
            "  Training with max_samples=0.5...\n",
            "    MSE with max_samples=0.5: 10386.6932\n",
            "  Training with max_samples=0.7...\n",
            "    MSE with max_samples=0.7: 9650.8330\n",
            "  Training with max_samples=0.8...\n",
            "    MSE with max_samples=0.8: 9781.7696\n",
            "  Training with max_samples=0.9...\n",
            "    MSE with max_samples=0.9: 9514.3643\n",
            "  Training with max_samples=1.0...\n",
            "    MSE with max_samples=1.0: 9617.3688\n",
            "\n",
            "All Bagging Regressors trained and evaluated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97c315a9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step trained and evaluated Bagging Regressors with different `max_samples` values. Now, to visualize the effect of `max_samples` on performance, the next logical step is to plot these results by showing MSE against `max_samples`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "135de2d4",
        "outputId": "2d4ebbe4-f69f-4af2-f56d-ceeb5b05582b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the MSE values against the max_samples values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(max_samples_list, mse_values_ms, marker='o', linestyle='-')\n",
        "plt.title('Bagging Regressor Performance (MSE) vs. max_samples')\n",
        "plt.xlabel('Fraction of Samples for Base Estimators (max_samples)')\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.xticks(max_samples_list)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}